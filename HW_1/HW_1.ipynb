{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "63afcc37e680477994be0ab498310dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_52d32806dd6c446c951fe59891cec469",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3bcbabc50c734dd3903f0701db9ddcf3",
              "IPY_MODEL_7f7c74f046d64e3c9edd4555124bdaa8"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "52d32806dd6c446c951fe59891cec469": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "3bcbabc50c734dd3903f0701db9ddcf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ee4479e5cebf4ebda87429dac6eea061",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_78d22de5c0be4763a00a20472cf1f3a8"
          },
          "model_module_version": "1.5.0"
        },
        "7f7c74f046d64e3c9edd4555124bdaa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8ed2683137c24e39894b012ea0e34359",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 400000/? [00:46&lt;00:00, 8590.47it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e5bcf7275d3747a7bababceeaccca7c9"
          },
          "model_module_version": "1.5.0"
        },
        "ee4479e5cebf4ebda87429dac6eea061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "78d22de5c0be4763a00a20472cf1f3a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "8ed2683137c24e39894b012ea0e34359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "e5bcf7275d3747a7bababceeaccca7c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "b79ae765ec4e45c090474599dd39cf11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bf42849c258748dabfe79f082e1ac978",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_557eddd8d6db40e495d0d80688932ece",
              "IPY_MODEL_66d519043c334ce5895ec689c86c29c6"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "bf42849c258748dabfe79f082e1ac978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "557eddd8d6db40e495d0d80688932ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1c147ddef56640528d17aa6181506fcd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_862fefebe17642a78d95e716b89da128"
          },
          "model_module_version": "1.5.0"
        },
        "66d519043c334ce5895ec689c86c29c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3a4863806db543608797d3b7888726d3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8000/? [04:29&lt;00:00, 29.66it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2746411984d44e51924ed491a7fef5ff"
          },
          "model_module_version": "1.5.0"
        },
        "1c147ddef56640528d17aa6181506fcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "862fefebe17642a78d95e716b89da128": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "3a4863806db543608797d3b7888726d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "2746411984d44e51924ed491a7fef5ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "ebda42baabf346d0acb7d5833347e05f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_48b40e87b1ac49829cffc4c5a71b07c2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5094654e707b4df8b023a45869a04811",
              "IPY_MODEL_969a26ddb94d4134bc6dc2499da2188c"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "48b40e87b1ac49829cffc4c5a71b07c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "5094654e707b4df8b023a45869a04811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ac54140cde464d239f14a393a53ed01a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_44b68ee1637d43e092e9b805e921d04b"
          },
          "model_module_version": "1.5.0"
        },
        "969a26ddb94d4134bc6dc2499da2188c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5eef9f47a0974e18a28bbf8cc8380bcb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1000/? [00:00&lt;00:00, 3403.75it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ca30e76c2aa419dbb5c11a1431c799b"
          },
          "model_module_version": "1.5.0"
        },
        "ac54140cde464d239f14a393a53ed01a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "44b68ee1637d43e092e9b805e921d04b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "5eef9f47a0974e18a28bbf8cc8380bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "1ca30e76c2aa419dbb5c11a1431c799b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "6d7b64dbfca848f8b40a7546b6a9bd61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6fae63fbe05a4ec5878428819ea162f5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2614b2d0484b4b189e0a896d73b46c72",
              "IPY_MODEL_86b3d04109b6489eb5edb192e27d2287"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "6fae63fbe05a4ec5878428819ea162f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "2614b2d0484b4b189e0a896d73b46c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0d0186eec4da4610abd8f8ffc1336a13",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_54995a4ec8f14b8b94870d57bd56c43a"
          },
          "model_module_version": "1.5.0"
        },
        "86b3d04109b6489eb5edb192e27d2287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0ddbe68625f348b3baf8b6ee525273de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8000/? [00:12&lt;00:00, 628.82it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9da84c05d993449aa980216e078730c0"
          },
          "model_module_version": "1.5.0"
        },
        "0d0186eec4da4610abd8f8ffc1336a13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "54995a4ec8f14b8b94870d57bd56c43a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "0ddbe68625f348b3baf8b6ee525273de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "9da84c05d993449aa980216e078730c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "40c9c8da83b44e07847aa1a048eb0dd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5552775cc5164808a082c7e1fa43b576",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a600821bc2fc4358919c35fe55bca1fa",
              "IPY_MODEL_d243ea5ea42f45e1af8c55ab0307e5e5"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "5552775cc5164808a082c7e1fa43b576": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "a600821bc2fc4358919c35fe55bca1fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7fa7870a0b3e441b8ee958ab7144c357",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5572f1eee13046ea8d2d8d2f38c78638"
          },
          "model_module_version": "1.5.0"
        },
        "d243ea5ea42f45e1af8c55ab0307e5e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d4e923ed96584c4fb7876ddb70cee68f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1000/? [00:00&lt;00:00, 3409.83it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67ad9b72d8894c8088d777a2c8e0c2a9"
          },
          "model_module_version": "1.5.0"
        },
        "7fa7870a0b3e441b8ee958ab7144c357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "5572f1eee13046ea8d2d8d2f38c78638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "d4e923ed96584c4fb7876ddb70cee68f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "67ad9b72d8894c8088d777a2c8e0c2a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "bff849e78798425580e8bf36ea327b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9770691e8d1b4e2ba4f91ed683fae855",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5d228d49cc5746ff888b885618a85ba8",
              "IPY_MODEL_4065f4fed41c4918b2a28d059c6690a7"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "9770691e8d1b4e2ba4f91ed683fae855": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "5d228d49cc5746ff888b885618a85ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2e3ae5a61f4441ba877c877739127f54",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6baf876ea25043f7a35afb16be7c5a87"
          },
          "model_module_version": "1.5.0"
        },
        "4065f4fed41c4918b2a28d059c6690a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_28465b399309486ca1749ce720091839",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8000/? [00:02&lt;00:00, 3457.03it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fce98e861fe04e78b5635fecd8189dab"
          },
          "model_module_version": "1.5.0"
        },
        "2e3ae5a61f4441ba877c877739127f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "6baf876ea25043f7a35afb16be7c5a87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "28465b399309486ca1749ce720091839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "fce98e861fe04e78b5635fecd8189dab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "05be0ea1e11f44d3afe78c625c129f7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e0794d4f720142af99132cd66a0e71ed",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7b17a6e27ce649aabf3c31450f99b50b",
              "IPY_MODEL_910f133f46ca4025ba41904fa5ab37b2"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "e0794d4f720142af99132cd66a0e71ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "7b17a6e27ce649aabf3c31450f99b50b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b79cf63f788a4753b2ebde93aab6a79b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_240a97063f3544508c56ed0121610e9a"
          },
          "model_module_version": "1.5.0"
        },
        "910f133f46ca4025ba41904fa5ab37b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7f71032ccb184eb394a443e8ea6e39a4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1000/? [00:00&lt;00:00, 3544.63it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6dd0c0e81f724caaa8e9cb796f4fe803"
          },
          "model_module_version": "1.5.0"
        },
        "b79cf63f788a4753b2ebde93aab6a79b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "240a97063f3544508c56ed0121610e9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "7f71032ccb184eb394a443e8ea6e39a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "6dd0c0e81f724caaa8e9cb796f4fe803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD2BttEJsehb"
      },
      "source": [
        "# Beginning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwr3x2UgyIi3",
        "outputId": "2f14d793-c617-42de-a2e0-fcf87169a7fe"
      },
      "source": [
        "!rm -R nlp2021-hw1\n",
        "!git clone https://github.com/SapienzaNLP/nlp2021-hw1\n",
        "!mv nlp2021-hw1/data data\n",
        "!rm -R nlp2021-hw1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'nlp2021-hw1': No such file or directory\n",
            "Cloning into 'nlp2021-hw1'...\n",
            "remote: Enumerating objects: 40, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 40 (delta 11), reused 18 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (40/40), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N73BBZE4IwWd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37ca212e-dce5-41fb-c48f-16e7a2930e3e"
      },
      "source": [
        "import json, re\n",
        "import random\n",
        "import copy\n",
        "from typing import *\n",
        "from tqdm.notebook import tqdm\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "sb.set()\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "class DeviceObject(object):\n",
        "    device='cuda'\n",
        "\n",
        "    def __init__(self):\n",
        "        self.to(self.device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rmB9mDuIqOj"
      },
      "source": [
        "# GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xS_ozZ_ILMe",
        "outputId": "ced1c393-041b-4d57-c24a-db933af8bb18"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "!rm glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-02 08:13:16--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-05-02 08:13:16--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-05-02 08:13:17--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.19MB/s    in 2m 42s  \n",
            "\n",
            "2021-05-02 08:15:58 (5.09 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO22MiO6etMu"
      },
      "source": [
        "# Class for loading embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "63afcc37e680477994be0ab498310dfa",
            "52d32806dd6c446c951fe59891cec469",
            "3bcbabc50c734dd3903f0701db9ddcf3",
            "7f7c74f046d64e3c9edd4555124bdaa8",
            "ee4479e5cebf4ebda87429dac6eea061",
            "78d22de5c0be4763a00a20472cf1f3a8",
            "8ed2683137c24e39894b012ea0e34359",
            "e5bcf7275d3747a7bababceeaccca7c9"
          ]
        },
        "id": "k_pTxCLiIunA",
        "outputId": "31b27663-bad3-462f-8212-df16bdcb9113"
      },
      "source": [
        "class VectorsWithSpecials(DeviceObject):\n",
        "    '''\n",
        "    Class for loading embeddings from a file\n",
        "    '''\n",
        "    def __init__(self, file_name):\n",
        "        self.__load_data(file_name)\n",
        "        self.length = len(self.itos)\n",
        "\n",
        "        self.add_unk_and_pad_token()\n",
        "    \n",
        "    def __load_data(self, file_name: str):\n",
        "        # Initialization for 3 main objects of this class\n",
        "        self.stoi = {} # Dictionary of Token name -> Token id \n",
        "        self.itos = [] # List of Token id -> Token name\n",
        "        self.vectors = [] # List with embeddings\n",
        "        \n",
        "        with open(file_name, 'r') as file:\n",
        "            lines = file.readlines()\n",
        "            for i, line in tqdm(enumerate(lines)):\n",
        "                values = line.split(' ')\n",
        "                token_str = values[0]\n",
        "                self.stoi[token_str] = i\n",
        "                self.itos.append(token_str)\n",
        "                self.vectors.append(list(map(float, values[1:])))\n",
        "\n",
        "        self.vectors = torch.tensor(self.vectors, device=self.device)\n",
        "\n",
        "    def __getitem__(self, token):\n",
        "        if type(token) == int:\n",
        "            return self.vectors[token]\n",
        "        else:\n",
        "            return self.vectors[self.stoi[token]]\n",
        "\n",
        "    def add_special(self, token: str, vec: torch.Tensor):\n",
        "        '''\n",
        "        Adding special tokens to our data\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        token : str\n",
        "            name of token like '<unk>'\n",
        "        vec : torch.Tensor\n",
        "            embedding vector\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        None.\n",
        "\n",
        "        '''\n",
        "        self.stoi[token] = self.length\n",
        "        self.itos.append(token)\n",
        "        self.vectors = torch.cat((self.vectors, vec.reshape(1, -1)))\n",
        "        \n",
        "        self.length += 1\n",
        "\n",
        "    \n",
        "    def get_id(self, token: str):\n",
        "        '''\n",
        "        Returns id of token by its name\n",
        "\n",
        "        '''\n",
        "        if token not in self.stoi:\n",
        "            return self.stoi['<unk>']\n",
        "        else:\n",
        "            return self.stoi[token]\n",
        "\n",
        "\n",
        "    def add_unk_and_pad_token(self, num_of_ave: int=50000):\n",
        "        '''\n",
        "        Idea for averaging vectors for <unk> representation is taken from:\n",
        "        https://stackoverflow.com/questions/49239941/what-is-unk-in-the-pretrained-glove-vector-files-e-g-glove-6b-50d-txt\n",
        "        '''\n",
        "        vectors = self\n",
        "        vec = torch.zeros(vectors[0].shape, device=self.device)\n",
        "        for i in range(num_of_ave):\n",
        "            vec += vectors[vectors.itos[i]] / num_of_ave\n",
        "\n",
        "        # Adding special tokens\n",
        "        vectors.add_special('<unk>', vec)\n",
        "        vectors.add_special('<pad>', vectors[0])\n",
        "        vectors.add_special('<sep>', torch.rand(vectors[0].shape, device=self.device))\n",
        "        # Masked token is used for Context Encoder (language model)\n",
        "        vectors.add_special('<masked>', torch.rand(vectors[0].shape, device=self.device))\n",
        "\n",
        "\n",
        "vectors = VectorsWithSpecials(\"glove.6B.300d.txt\")\n",
        "vectors_50 = VectorsWithSpecials(\"glove.6B.50d.txt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63afcc37e680477994be0ab498310dfa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmVziD007ky1"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "b79ae765ec4e45c090474599dd39cf11",
            "bf42849c258748dabfe79f082e1ac978",
            "557eddd8d6db40e495d0d80688932ece",
            "66d519043c334ce5895ec689c86c29c6",
            "1c147ddef56640528d17aa6181506fcd",
            "862fefebe17642a78d95e716b89da128",
            "3a4863806db543608797d3b7888726d3",
            "2746411984d44e51924ed491a7fef5ff",
            "ebda42baabf346d0acb7d5833347e05f",
            "48b40e87b1ac49829cffc4c5a71b07c2",
            "5094654e707b4df8b023a45869a04811",
            "969a26ddb94d4134bc6dc2499da2188c",
            "ac54140cde464d239f14a393a53ed01a",
            "44b68ee1637d43e092e9b805e921d04b",
            "5eef9f47a0974e18a28bbf8cc8380bcb",
            "1ca30e76c2aa419dbb5c11a1431c799b"
          ]
        },
        "id": "zeD8cdpBjgoF",
        "outputId": "8132a37b-2c99-491b-f240-84f6d6239e7f"
      },
      "source": [
        "class WiCDataset(Dataset, DeviceObject):\n",
        "    # POS tags in original dataset\n",
        "    pos_to_id = {'ADJ': 0, 'ADV': 1, 'NOUN': 2, 'VERB': 3, 'UNK' : 4}\n",
        "    # NLTK POS tags\n",
        "    nltk_pos_tags = {name:i for i, name in enumerate(['IN', 'DT', 'NN', 'CC', 'VBZ', 'JJ', 'VBD', 'RB', 'VBN', 'CD', 'NNS', 'WRB', 'PRP', 'WP', 'VBP', 'TO', 'VB', 'VBG', 'PRP$', 'MD', 'NNP', 'JJR', 'WDT', 'RBS', 'EX', 'RP', 'PDT', 'RBR', 'JJS', 'WP$', 'FW', '$', 'NNPS', 'POS', 'SYM', 'UH'])}\n",
        "    num_pos_classes = len(nltk_pos_tags.keys())\n",
        "    \n",
        "    def __init__(self, file_path_or_list, # OR List with sentences \n",
        "                 vocab: VectorsWithSpecials,\n",
        "                 wrong_label_prob=0, # An option to have some noise among labels with specified probability\n",
        "                 swap_sequences=False,\n",
        "                 swap_tokens=None,\n",
        "                 rand_replace=None,  # Threshold in percentages of replaced tokens\n",
        "                 rand_replace_mode='sample_words', # OR 'unk_tokens'\n",
        "                 max_length=None,\n",
        "                 mask_word_mode=False,\n",
        "                 remove_stop_words=False,\n",
        "                 lemmatization=False,\n",
        "                 with_pos_tags = False, # Used for extra model with POS tags\n",
        "                 ):\n",
        "        self.vocab = vocab\n",
        "        counter_names = ['label', 'lemma', 'pos', 'token', 'sen_length', 'masked_word', 'unk_tokens', 'tags']\n",
        "        self.counter = {field_name: defaultdict(int) for field_name in counter_names}\n",
        "        self.augmented_db = {'True': defaultdict(set), 'False': []}\n",
        "        self.wrong_label_prob = wrong_label_prob\n",
        "        self.swap_sequences = swap_sequences\n",
        "        self.swap_tokens = swap_tokens\n",
        "        self.max_length = max_length\n",
        "        self.rand_replace = rand_replace\n",
        "        self.get_counter = 0\n",
        "        self.mask_word_mode = mask_word_mode\n",
        "        self.remove_stop_words = remove_stop_words\n",
        "        self.stopwords = stopwords.words('english')\n",
        "        self.stopwords_indecies = {vocab.stoi[s] for s in self.stopwords if s in vocab.stoi}\n",
        "        self.replacement_function = getattr(self, rand_replace_mode)\n",
        "        self.with_pos_tags = with_pos_tags\n",
        "        \n",
        "        self.lemmatyzer = WordNetLemmatizer() if lemmatization else None\n",
        "\n",
        "        self.load_data(file_path_or_list)\n",
        "        # Inititalization of array with words to be sampled for replacement or negative sampling\n",
        "        self.init_arr_for_sampling()\n",
        "\n",
        "        self.max_length = max(self.counter['sen_length'].keys())   \n",
        "\n",
        "    def __len__(self):\n",
        "        if self.mask_word_mode:\n",
        "            return len(self.sentences)\n",
        "        else:\n",
        "            return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        '''\n",
        "        The function works in two modes: \n",
        "            1) Masking mode - randomly choose one sentence from data \n",
        "            and replace randomly one word with <masked> token\n",
        "            2) Original mode - randomly choose an item from original data \n",
        "            with 2 sentences. Returns tokens for sentences and positions of lemma\n",
        "\n",
        "        '''\n",
        "        if self.mask_word_mode:\n",
        "            tokens = copy.deepcopy(self.sentences[idx])\n",
        "            # Choosing which word to replace\n",
        "            rand_idx = torch.randint(len(tokens), (1,)).item()\n",
        "            token_id = tokens[rand_idx].item()\n",
        "            tokens[rand_idx] = self.vocab.get_id('<masked>')\n",
        "            # Gathering masked tokens statistics\n",
        "            self.counter['masked_word'][token_id] += 1\n",
        "\n",
        "            # Toss a coin\n",
        "            if torch.rand(1).item() >= 0.5:\n",
        "                # Negative sample\n",
        "                token_id = self.sample_words(1).item()\n",
        "                label = 0\n",
        "            else:\n",
        "                # Keeping original word\n",
        "                label = 1\n",
        "\n",
        "            # Data augmentation\n",
        "            if self.rand_replace is not None:\n",
        "                tokens = self.replace_rand_words(tokens, [rand_idx])\n",
        "            if self.swap_tokens is not None:\n",
        "                tokens = self.swap_rand_tokens(tokens, [rand_idx])\n",
        "            \n",
        "            item = {'tokens' : tokens, 'unk_position': rand_idx, \n",
        "                    'token_id': token_id, 'seq_length': len(tokens), \n",
        "                     'label': label}\n",
        "\n",
        "            if self.with_pos_tags:\n",
        "                item['tags'] = self.all_tags[idx]\n",
        "            \n",
        "            return item\n",
        "        else:\n",
        "            data = copy.deepcopy(self.data[idx])\n",
        "            # If wrong label probability is set, we add noise in labels. \n",
        "            # It might be used to reduce overfitting\n",
        "            if self.wrong_label_prob > 0 and torch.rand(1)[0].item() < self.wrong_label_prob:\n",
        "                data['label'] = 1.0 - data['label']\n",
        "            \n",
        "            # Data augmentation\n",
        "            if self.rand_replace is not None:\n",
        "                for i in range(1, 3):\n",
        "                    data['tokens' + str(i)] = self.replace_rand_words(data['tokens' + str(i)], [data['where_lemma' + str(i)]])\n",
        "            if self.swap_tokens is not None:\n",
        "                for i in range(1, 3):\n",
        "                    data['tokens' + str(i)] = self.swap_rand_tokens(data['tokens' + str(i)], [data['where_lemma' + str(i)]])\n",
        "            \n",
        "            return data\n",
        "\n",
        "    def init_arr_for_sampling(self):\n",
        "        '''\n",
        "        Array for sampling from is constructed by simply appending in \n",
        "        a list a token id as maby time as it appears in corpus\n",
        "\n",
        "        '''\n",
        "        arr_for_sampling = []\n",
        "        for token, freq in sorted(self.counter['token'].items(), key=lambda x: -x[1]):\n",
        "            # Excluding stopwords from samples\n",
        "            if token not in self.stopwords:\n",
        "                arr_for_sampling += [token] * freq\n",
        "\n",
        "        self.arr_for_sampling = torch.tensor(arr_for_sampling, device=self.device)\n",
        "\n",
        "    def sample_words(self, num: int):\n",
        "        '''\n",
        "        Since we have a big list filled with token ids occured as many times as in corpus,\n",
        "        we just generate random numbers and used them as ids\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        num : number of samples\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Tensor with tokens ids\n",
        "\n",
        "        '''\n",
        "        return self.arr_for_sampling[torch.randint(len(self.arr_for_sampling), (num,), device=self.device)]\n",
        "\n",
        "    def unk_tokens(self, num):\n",
        "        '''\n",
        "        Generates tensor filled with <unk> token\n",
        "\n",
        "        '''\n",
        "        return torch.tensor([self.vocab.get_id('<unk>')] * num, dtype=torch.int64, device=self.device)\n",
        "\n",
        "    def replace_rand_words(self, tokens, exclude):\n",
        "        '''\n",
        "        Data augmentation with random replacement of words\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        tokens : tensor with tokens ids\n",
        "        exclude : list of positions to excluded from replacement. For example, id of masked token\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        tokens : modified tokens tensor\n",
        "\n",
        "        '''\n",
        "        # Maximum number of changes that can be done: sentence length multiplied by specified percentage \n",
        "        num = int(len(tokens) * self.rand_replace) + 1\n",
        "        # Exact number of changes to be made\n",
        "        num = torch.randint(num, (1,)).item()\n",
        "        if num > 0:\n",
        "            # Randomly permuted tokens cut with 'num' size and converted to set, then excluded set is substracted.\n",
        "            rand_idx = torch.tensor(list(set(torch.randperm(len(tokens))[:num].tolist()) - set(exclude)), \n",
        "                                    dtype=torch.int64,\n",
        "                                    device=self.device)\n",
        "            # Replacement function either 'sample_tokens' or 'unk_tokens' - replace chosen tokens with <unk>\n",
        "            tokens[rand_idx] = self.replacement_function(len(rand_idx))\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def swap_rand_tokens(self, tokens, exclude):\n",
        "         # Maximum number of changes that can be done: sentence length multiplied by specified percentage \n",
        "        num = int(len(tokens) * self.swap_tokens) + 1\n",
        "        # Exact number of changes to be made\n",
        "        num = torch.randint(num, (1,)).item()\n",
        "        if num > 0:\n",
        "            # Randomly permuted tokens cut with 'num' size and converted to set, then excluded set is substracted.\n",
        "            rand_idx = torch.tensor(list(set(torch.randperm(len(tokens))[:num].tolist()) - set(exclude)), \n",
        "                                    dtype=torch.int64,\n",
        "                                    device=self.device)\n",
        "            \n",
        "            # Make chosen list of ids to be even size\n",
        "            size = (len(rand_idx) // 2) * 2\n",
        "            rand_idx = rand_idx[:size]\n",
        "            # Swap tokens\n",
        "            tokens[rand_idx[:size // 2]] = tokens[rand_idx[size // 2:]]\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def pre_process(self, token):\n",
        "        '''\n",
        "        This is function for optional lemmatization using external library like NLTK\n",
        "        '''\n",
        "        if self.lemmatyzer:\n",
        "            token = self.lemmatyzer.lemmatize(token)\n",
        "        \n",
        "        return token\n",
        "\n",
        "    def load_data(self, file_path_or_list: str):\n",
        "        '''\n",
        "        Data loading is performed in two modes:\n",
        "        1) If file name is set in 'file_path_or_list' field, then we parse file\n",
        "        2) If a list is set then we parse a list\n",
        "        '''\n",
        "        if type(file_path_or_list) == str:\n",
        "            # The file block\n",
        "            file_path = file_path_or_list\n",
        "            with open(file_path, 'r') as file:\n",
        "                self.__init_data(file.readlines())\n",
        "        else:\n",
        "            # The list block\n",
        "            lines = file_path_or_list\n",
        "            self.__init_data(lines, is_json=False)\n",
        "        \n",
        "\n",
        "    def __init_data(self, lines, is_json=True):\n",
        "        '''\n",
        "        Transforms original dataset format in one that is useful for training models,\n",
        "        in particular:  splitting text to tokens, converting labels from string to numbers,\n",
        "        collecting pos tags if the flag is set. \n",
        "        '''\n",
        "        data = []\n",
        "        sentences = []\n",
        "        all_tags = []\n",
        "        \n",
        "        for i, line in tqdm(enumerate(lines)):\n",
        "            # Parsing json\n",
        "            obj = json.loads(line) if is_json else line\n",
        "\n",
        "            row = { \n",
        "                # If POS tags is not in our dictionary we set it to UNK\n",
        "                'pos': self.pos_to_id[obj['pos']] if obj['pos'] in self.pos_to_id else self.pos_to_id['UNK']\n",
        "            }\n",
        "\n",
        "            if 'label' in obj:\n",
        "                # Converting label to number\n",
        "                row['label'] = (obj['label'] == 'True') * 1.0\n",
        "                # Collecting labels statistics\n",
        "                self.counter['label'][obj['label']] += 1\n",
        "\n",
        "            # Collecting some statistics of POSs and lemmas\n",
        "            self.counter['pos'][obj['pos']] += 1\n",
        "            self.counter['lemma'][(obj['lemma'], obj['pos'])] += 1\n",
        "\n",
        "            continue_flag = False\n",
        "\n",
        "            for k in [1, 2]:   \n",
        "                k = str(k)\n",
        "                pos = int(obj['start' + k])\n",
        "                # Inserting ** symbols to distinguish word of interest\n",
        "                mod_sentence = obj['sentence' + k] = obj['sentence' + k][:pos] + '**' + obj['sentence' + k][pos:]\n",
        "                \n",
        "                # Transforming text to token ids and getting position of lemma\n",
        "                tokens_ids, where_lemma = self.text_to_token_ids(mod_sentence)\n",
        "                \n",
        "                row['tokens' + k] = tokens_ids\n",
        "                row['where_lemma' + k] = where_lemma\n",
        "                \n",
        "                if self.with_pos_tags:\n",
        "                    row['tags' + k] = tags = self.pos_tags(obj['sentence' + k])\n",
        "                    all_tags.append(tags)\n",
        "                \n",
        "                # There is an option to limit length of sentences\n",
        "                if self.max_length is not None and len(tokens_ids) > self.max_length:\n",
        "                    continue_flag = True\n",
        "                    continue \n",
        "\n",
        "                self.counter['sen_length'][len(tokens_ids)] += 1\n",
        "                sentences.append(tokens_ids)\n",
        "\n",
        "            if continue_flag:\n",
        "                continue\n",
        "            \n",
        "            data.append(row)\n",
        "            \n",
        "            # Swap indecies \n",
        "            if self.swap_sequences:\n",
        "                swapped_row = row.copy()\n",
        "                swapped_row['tokens1'], swapped_row['tokens2'] = swapped_row['tokens2'], swapped_row['tokens1']\n",
        "                swapped_row['where_lemma1'], swapped_row['where_lemma2'] = swapped_row['where_lemma2'], swapped_row['where_lemma1']\n",
        "\n",
        "                data.append(swapped_row)     \n",
        "        \n",
        "        # Storing collected data\n",
        "        self.data = data\n",
        "        self.sentences = sentences\n",
        "        self.all_tags = all_tags\n",
        "\n",
        "\n",
        "    def tokenize(self, text: str) -> List:\n",
        "        '''\n",
        "        Performs splitting text into strings tokens\n",
        "        '''\n",
        "        return re.split('[^\\w\\*]', text.lower())\n",
        "\n",
        "    def pos_tags(self, text: str) -> List:\n",
        "        '''\n",
        "        Takes sentence text and returns POS tags of each word\n",
        "        '''\n",
        "        tokens = [t for t in self.tokenize(text) if t]\n",
        "\n",
        "        _tags = nltk.pos_tag(tokens)\n",
        "        tags = []\n",
        "\n",
        "        for _, tag in _tags:\n",
        "            self.counter['tags'][tag] += 1\n",
        "            tags.append(self.nltk_pos_tags[tag])\n",
        "        \n",
        "        return tags\n",
        "\n",
        "    def text_to_token_ids(self, text: str) -> List:\n",
        "        '''\n",
        "        Converts text to list of tokens ids from embeddings vocaulary\n",
        "        '''\n",
        "        # Splitting by regular expression\n",
        "        tokens = re.split('[^\\w\\*]', text.lower())\n",
        "        where_lemma = -1\n",
        "        tokens_ids = []\n",
        "        # Excluding empty string and stopwords if required,  and adding tokens to the list. \n",
        "        tokens = [self.pre_process(t) for t in tokens if t != '' and not (self.remove_stop_words and t in self.stopwords)]\n",
        "\n",
        "        for i in range(len(tokens)):\n",
        "            t = tokens[i]\n",
        "            # If a word contain ** at the beggining, then this is our lemma of intereset\n",
        "            if t[:2] == '**':\n",
        "                where_lemma = i\n",
        "                t = t.replace('**', '')\n",
        "\n",
        "            tokens_ids.append(self.vocab.get_id(t))\n",
        "            # Collection statistics of tokens\n",
        "            self.counter['token'][tokens_ids[-1]] += 1\n",
        "            \n",
        "            if tokens_ids[-1] == self.vocab.get_id('<unk>'):\n",
        "                self.counter['unk_tokens'][t] += 1\n",
        "\n",
        "        assert where_lemma != -1\n",
        "\n",
        "        return torch.tensor(tokens_ids).to(self.device), where_lemma\n",
        "\n",
        "    def get_used_tokens(self, remove_stop_words=False):\n",
        "        '''\n",
        "        Return tokens that are in corpus\n",
        "        '''\n",
        "        tokens = set(train_dataset_context.counter['token'].keys())\n",
        "        if remove_stop_words:\n",
        "            tokens -= self.stopwords_indecies\n",
        "\n",
        "        return tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b79ae765ec4e45c090474599dd39cf11",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ebda42baabf346d0acb7d5833347e05f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nkocu1QwUZn"
      },
      "source": [
        "# Train - Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aIgW19cwWZO"
      },
      "source": [
        "def binary_accuracy(preds, targets, treshold=0.5):\n",
        "    return torch.mean(((preds >= treshold)*1.0 == targets) * 1.0)\n",
        "\n",
        "def first_approach_train_step(model, batch):\n",
        "    sen_token_1, sen_token_2, label = batch\n",
        "    preds, loss = model(sen_token_1, sen_token_2, label)\n",
        "    \n",
        "    return {'loss': loss, 'batch_accuracy': binary_accuracy(preds, label)}\n",
        "\n",
        "def first_approach_eval_step(model, batch):\n",
        "    sen_token_1, sen_token_2, label = batch\n",
        "    preds, loss = model(sen_token_1, sen_token_2, label)\n",
        "\n",
        "    return loss, binary_accuracy(preds, label)\n",
        "\n",
        "def train(train_data_loader, valid_data_loader, model, optimizer, \n",
        "          train_step, eval_step, epochs, \n",
        "          best_model={}, best_model_mode='valid_loss', hist={}, scheduler=None):\n",
        "    '''\n",
        "    Main function for training.\n",
        "    train_step - function for executing one batch step\n",
        "    eval_step - function for evaluation of one batch\n",
        "    best_model - stores best model\n",
        "    best_model_mode - either 'valid_loss' or 'accuracy'\n",
        "    hist - stores history of losses and validation accuracy\n",
        "    '''\n",
        "    best_score = -np.inf\n",
        "    hist['train_loss'], hist['valid_loss'], hist['valid_accuracy'] = [], [], []\n",
        "    \n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_hist = defaultdict(list)\n",
        "        losses = []\n",
        "        model.train()\n",
        "\n",
        "        for i, batch in enumerate(train_data_loader):\n",
        "            model.zero_grad()\n",
        "            \n",
        "            res = train_step(model, batch)\n",
        "            loss = res['loss']\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if 'batch_accuracy' in res:\n",
        "                epoch_hist['batch_accuracy'].append(res['batch_accuracy'])\n",
        "\n",
        "        mean_loss = sum(losses) / len(losses)\n",
        "        valid_mean_loss, valid_batch_accuracy = evaluate(valid_data_loader, model, eval_step)\n",
        "        print(f'Epoch {epoch}: Loss: {mean_loss:0.6f} \\t\\t Validation loss: {valid_mean_loss:0.6f}')\n",
        "\n",
        "        # If score of interes is validation loss we make it with negative sign to keep comparison the same for both cases\n",
        "        score_to_compare = -valid_mean_loss if best_model_mode == 'valid_loss' else valid_batch_accuracy\n",
        "        if score_to_compare > best_score:\n",
        "            # Storing the best model so far\n",
        "            best_score = score_to_compare\n",
        "            best_model['best_score'] = abs(score_to_compare)\n",
        "            best_model['state_dict'] = copy.deepcopy(model.state_dict())\n",
        "            print('BEST SCORE:', best_model['best_score'])\n",
        "\n",
        "        if 'batch_accuracy' in epoch_hist:\n",
        "            train_accuracy = sum(epoch_hist['batch_accuracy']) / len(epoch_hist['batch_accuracy'])\n",
        "            print(f'Training average batch accuracy: {train_accuracy:0.6f}')\n",
        "\n",
        "        # Storing history\n",
        "        hist['train_loss'].append(mean_loss)\n",
        "        hist['valid_loss'].append(valid_mean_loss)\n",
        "        hist['valid_accuracy'].append(valid_batch_accuracy.item())\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step(valid_mean_loss)\n",
        "\n",
        "        print(f'Validation average batch accuracy: {valid_batch_accuracy:0.6f}')\\\n",
        "    \n",
        "    return best_model, model\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, eval_step):\n",
        "    ''' \n",
        "    Model evaluation function\n",
        "    eval_step - function to be executed for each batch\n",
        "    '''\n",
        "    model.eval()\n",
        "    results = []\n",
        "    losses = []\n",
        "\n",
        "    for i, batch in enumerate(data_loader):\n",
        "        loss, metric = eval_step(model, batch)\n",
        "        losses.append(loss.item())\n",
        "        results.append(metric)\n",
        "\n",
        "    return sum(losses) / len(losses), sum(results) / len(results)\n",
        "\n",
        "def plot_hist(hist, window=10):\n",
        "    '''\n",
        "    Plots moving averages of loses and accuracy\n",
        "    hist - dictionary containing training history\n",
        "    window - window size of moving average\n",
        "    '''\n",
        "    df = pd.DataFrame(list(zip(hist['train_loss'], hist['valid_loss'])), columns=['train_loss', 'valid_loss'])\n",
        "    df.rolling(window).mean().plot()\n",
        "\n",
        "    pd.DataFrame(hist['valid_accuracy'], columns=['valid_accuracy']).rolling(window).mean().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBw8OaplV4KO"
      },
      "source": [
        "# First approcah model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16P3QYPTV5tc"
      },
      "source": [
        "# For GloVe 50\n",
        "class HypParams:\n",
        "    hidden_size = 100\n",
        "    dropout=0.6\n",
        "\n",
        "\n",
        "class FirstApproachModel(nn.Module):\n",
        "    '''\n",
        "    The model averages separetly embeddings for each sentence concatenate them and feed to MLP.\n",
        "    There is also option to transform them and check cosine similiarity.\n",
        "    '''\n",
        "    def __init__(self, params, \n",
        "                 embeddings, \n",
        "                 cosine_mode=False \n",
        "                 ):\n",
        "        super().__init__()\n",
        "        # If cosine mode is set we do not concatentae vectors but compare via cosine similiarity\n",
        "        self.cosine_mode = cosine_mode\n",
        "        input_size = embeddings[0].shape[0]\n",
        "        \n",
        "        # Loading pre-trained embedding from our vocabulary\n",
        "        self.word_embeddings = nn.Embedding.from_pretrained(embeddings)\n",
        "  \n",
        "        if cosine_mode:\n",
        "            # For cosine mode we should get vectors to compare so output size if multi-dimensional\n",
        "            output_size = params.hidden_size\n",
        "        else:\n",
        "            # For classification output is of dimension 1 \n",
        "            input_size = input_size * 2\n",
        "            output_size = 1\n",
        "\n",
        "        # MLP sequence\n",
        "        self.sequence = nn.Sequential(\n",
        "            nn.Linear(input_size, params.hidden_size),\n",
        "            nn.BatchNorm1d(params.hidden_size),\n",
        "            nn.ReLU(params.hidden_size),\n",
        "            nn.Dropout(p=params.dropout),\n",
        "\n",
        "            nn.Linear(params.hidden_size, output_size),\n",
        "        )\n",
        "\n",
        "        self.cosine = nn.CosineSimilarity()\n",
        "        self.loss = nn.BCELoss()\n",
        "\n",
        "    def forward(self, tokens_1, tokens_2, y=None):\n",
        "        emb_1 = torch.mean(self.word_embeddings(tokens_1), dim=1)\n",
        "        emb_2 = torch.mean(self.word_embeddings(tokens_2), dim=1)\n",
        "\n",
        "        if self.cosine_mode:\n",
        "            results = []\n",
        "            for emb in [emb_1, emb_2]:\n",
        "                results.append(self.sequence(emb))\n",
        "\n",
        "            # Transformation of cosine similiaity so we have value in interval of [0, 1]\n",
        "            res = (self.cosine(results[0], results[1]) + 1) / 2\n",
        "        else:\n",
        "            # Concatenation of vectors and feeding them to classifier\n",
        "            res = self.sequence(torch.cat((emb_1, emb_2), dim=-1))\n",
        "            res = torch.sigmoid(res).squeeze()\n",
        "\n",
        "        loss = self.loss(res, y) if y is not None else None\n",
        "            \n",
        "        return res, loss\n",
        "\n",
        "\n",
        "class PadCollator(DeviceObject):\n",
        "    '''\n",
        "    Collator for loader which produces padded tensors\n",
        "    '''\n",
        "\n",
        "    def __init__(self, pad_token_id):\n",
        "        self.pad_token_id = pad_token_id\n",
        "    \n",
        "    def __call__(self, batch):\n",
        "        sen_token_1 = [b['tokens1'] for b in batch]\n",
        "        sen_token_2 = [b['tokens2'] for b in batch]\n",
        "        label = [b['label'] for b in batch]\n",
        "\n",
        "        sen_token_1 = torch.nn.utils.rnn.pad_sequence(sen_token_1, batch_first=True, padding_value=self.pad_token_id)\n",
        "        sen_token_2 = torch.nn.utils.rnn.pad_sequence(sen_token_2, batch_first=True, padding_value=self.pad_token_id)\n",
        "        \n",
        "        return sen_token_1.to(self.device), sen_token_2.to(self.device), torch.tensor(label).to(self.device)\n",
        "    \n",
        "\n",
        "train_dataset = WiCDataset('data/train.jsonl', vectors_50, \n",
        "                           rand_replace=0.2, \n",
        "                           #rand_replace_mode='unk_tokens',\n",
        "                           remove_stop_words=True, \n",
        "                           wrong_label_prob=0)\n",
        "\n",
        "valid_dataset = WiCDataset('data/dev.jsonl', vectors_50, remove_stop_words=True,)\n",
        "\n",
        "collate_obj = PadCollator(vectors_50.get_id('<pad>'))\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, collate_fn=collate_obj)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, collate_fn=collate_obj)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFPry4td9ROP",
        "outputId": "852460ee-d55f-4427-f457-aa836219b439"
      },
      "source": [
        "model = FirstApproachModel(HypParams(), vectors_50.vectors).to('cuda')\n",
        "optim = torch.optim.Adam(model.parameters())\n",
        "hist = {}\n",
        "\n",
        "_ = train(train_loader, \n",
        "      valid_loader, \n",
        "      model, optim, \n",
        "      first_approach_train_step, \n",
        "      first_approach_eval_step,\n",
        "      60, hist=hist, best_model_mode='accuracy',)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss: 0.710733 \t\t Validation loss: 0.675715\n",
            "BEST SCORE: tensor(0.5781, device='cuda:0')\n",
            "Training average batch accuracy: 0.513750\n",
            "Validation average batch accuracy: 0.578125\n",
            "Epoch 1: Loss: 0.687916 \t\t Validation loss: 0.659783\n",
            "BEST SCORE: tensor(0.6348, device='cuda:0')\n",
            "Training average batch accuracy: 0.551125\n",
            "Validation average batch accuracy: 0.634766\n",
            "Epoch 2: Loss: 0.677728 \t\t Validation loss: 0.658229\n",
            "Training average batch accuracy: 0.577500\n",
            "Validation average batch accuracy: 0.607227\n",
            "Epoch 3: Loss: 0.670584 \t\t Validation loss: 0.644648\n",
            "BEST SCORE: tensor(0.6438, device='cuda:0')\n",
            "Training average batch accuracy: 0.581250\n",
            "Validation average batch accuracy: 0.643750\n",
            "Epoch 4: Loss: 0.664976 \t\t Validation loss: 0.642426\n",
            "BEST SCORE: tensor(0.6496, device='cuda:0')\n",
            "Training average batch accuracy: 0.595500\n",
            "Validation average batch accuracy: 0.649609\n",
            "Epoch 5: Loss: 0.657962 \t\t Validation loss: 0.638389\n",
            "Training average batch accuracy: 0.605125\n",
            "Validation average batch accuracy: 0.638672\n",
            "Epoch 6: Loss: 0.655594 \t\t Validation loss: 0.628871\n",
            "BEST SCORE: tensor(0.6664, device='cuda:0')\n",
            "Training average batch accuracy: 0.608000\n",
            "Validation average batch accuracy: 0.666406\n",
            "Epoch 7: Loss: 0.658496 \t\t Validation loss: 0.639666\n",
            "Training average batch accuracy: 0.602875\n",
            "Validation average batch accuracy: 0.631641\n",
            "Epoch 8: Loss: 0.648921 \t\t Validation loss: 0.615597\n",
            "BEST SCORE: tensor(0.6730, device='cuda:0')\n",
            "Training average batch accuracy: 0.615125\n",
            "Validation average batch accuracy: 0.673047\n",
            "Epoch 9: Loss: 0.644340 \t\t Validation loss: 0.611823\n",
            "BEST SCORE: tensor(0.6830, device='cuda:0')\n",
            "Training average batch accuracy: 0.620250\n",
            "Validation average batch accuracy: 0.683008\n",
            "Epoch 10: Loss: 0.641805 \t\t Validation loss: 0.606988\n",
            "Training average batch accuracy: 0.630250\n",
            "Validation average batch accuracy: 0.682422\n",
            "Epoch 11: Loss: 0.644905 \t\t Validation loss: 0.610942\n",
            "Training average batch accuracy: 0.616750\n",
            "Validation average batch accuracy: 0.664062\n",
            "Epoch 12: Loss: 0.642597 \t\t Validation loss: 0.613415\n",
            "Training average batch accuracy: 0.624250\n",
            "Validation average batch accuracy: 0.648828\n",
            "Epoch 13: Loss: 0.644365 \t\t Validation loss: 0.606266\n",
            "BEST SCORE: tensor(0.6900, device='cuda:0')\n",
            "Training average batch accuracy: 0.625500\n",
            "Validation average batch accuracy: 0.690039\n",
            "Epoch 14: Loss: 0.634707 \t\t Validation loss: 0.615428\n",
            "Training average batch accuracy: 0.636750\n",
            "Validation average batch accuracy: 0.640234\n",
            "Epoch 15: Loss: 0.630896 \t\t Validation loss: 0.603891\n",
            "Training average batch accuracy: 0.640250\n",
            "Validation average batch accuracy: 0.664648\n",
            "Epoch 16: Loss: 0.634432 \t\t Validation loss: 0.608444\n",
            "Training average batch accuracy: 0.633125\n",
            "Validation average batch accuracy: 0.668750\n",
            "Epoch 17: Loss: 0.625836 \t\t Validation loss: 0.600860\n",
            "Training average batch accuracy: 0.651375\n",
            "Validation average batch accuracy: 0.679297\n",
            "Epoch 18: Loss: 0.630810 \t\t Validation loss: 0.596329\n",
            "Training average batch accuracy: 0.632750\n",
            "Validation average batch accuracy: 0.687500\n",
            "Epoch 19: Loss: 0.627444 \t\t Validation loss: 0.595659\n",
            "Training average batch accuracy: 0.647875\n",
            "Validation average batch accuracy: 0.689453\n",
            "Epoch 20: Loss: 0.626954 \t\t Validation loss: 0.596985\n",
            "BEST SCORE: tensor(0.6912, device='cuda:0')\n",
            "Training average batch accuracy: 0.649500\n",
            "Validation average batch accuracy: 0.691211\n",
            "Epoch 21: Loss: 0.625419 \t\t Validation loss: 0.598218\n",
            "Training average batch accuracy: 0.645750\n",
            "Validation average batch accuracy: 0.686719\n",
            "Epoch 22: Loss: 0.619616 \t\t Validation loss: 0.594136\n",
            "BEST SCORE: tensor(0.6938, device='cuda:0')\n",
            "Training average batch accuracy: 0.654500\n",
            "Validation average batch accuracy: 0.693750\n",
            "Epoch 23: Loss: 0.619479 \t\t Validation loss: 0.592671\n",
            "BEST SCORE: tensor(0.7008, device='cuda:0')\n",
            "Training average batch accuracy: 0.658000\n",
            "Validation average batch accuracy: 0.700781\n",
            "Epoch 24: Loss: 0.622372 \t\t Validation loss: 0.592491\n",
            "Training average batch accuracy: 0.649750\n",
            "Validation average batch accuracy: 0.689062\n",
            "Epoch 25: Loss: 0.619583 \t\t Validation loss: 0.603957\n",
            "Training average batch accuracy: 0.654125\n",
            "Validation average batch accuracy: 0.646875\n",
            "Epoch 26: Loss: 0.616307 \t\t Validation loss: 0.589806\n",
            "BEST SCORE: tensor(0.7033, device='cuda:0')\n",
            "Training average batch accuracy: 0.651750\n",
            "Validation average batch accuracy: 0.703320\n",
            "Epoch 27: Loss: 0.618669 \t\t Validation loss: 0.613744\n",
            "Training average batch accuracy: 0.651625\n",
            "Validation average batch accuracy: 0.619141\n",
            "Epoch 28: Loss: 0.614570 \t\t Validation loss: 0.604563\n",
            "Training average batch accuracy: 0.657125\n",
            "Validation average batch accuracy: 0.638672\n",
            "Epoch 29: Loss: 0.611113 \t\t Validation loss: 0.596649\n",
            "Training average batch accuracy: 0.655750\n",
            "Validation average batch accuracy: 0.687305\n",
            "Epoch 30: Loss: 0.612237 \t\t Validation loss: 0.591307\n",
            "Training average batch accuracy: 0.656875\n",
            "Validation average batch accuracy: 0.677148\n",
            "Epoch 31: Loss: 0.615677 \t\t Validation loss: 0.594969\n",
            "Training average batch accuracy: 0.657375\n",
            "Validation average batch accuracy: 0.668945\n",
            "Epoch 32: Loss: 0.608495 \t\t Validation loss: 0.594236\n",
            "Training average batch accuracy: 0.666250\n",
            "Validation average batch accuracy: 0.681055\n",
            "Epoch 33: Loss: 0.613321 \t\t Validation loss: 0.591091\n",
            "Training average batch accuracy: 0.662750\n",
            "Validation average batch accuracy: 0.689648\n",
            "Epoch 34: Loss: 0.610318 \t\t Validation loss: 0.589901\n",
            "Training average batch accuracy: 0.665750\n",
            "Validation average batch accuracy: 0.674219\n",
            "Epoch 35: Loss: 0.608384 \t\t Validation loss: 0.587854\n",
            "Training average batch accuracy: 0.673250\n",
            "Validation average batch accuracy: 0.676172\n",
            "Epoch 36: Loss: 0.607901 \t\t Validation loss: 0.588640\n",
            "Training average batch accuracy: 0.669750\n",
            "Validation average batch accuracy: 0.701953\n",
            "Epoch 37: Loss: 0.607378 \t\t Validation loss: 0.586124\n",
            "Training average batch accuracy: 0.669250\n",
            "Validation average batch accuracy: 0.680664\n",
            "Epoch 38: Loss: 0.599954 \t\t Validation loss: 0.586391\n",
            "Training average batch accuracy: 0.672875\n",
            "Validation average batch accuracy: 0.685938\n",
            "Epoch 39: Loss: 0.604209 \t\t Validation loss: 0.587344\n",
            "Training average batch accuracy: 0.669750\n",
            "Validation average batch accuracy: 0.677148\n",
            "Epoch 40: Loss: 0.605333 \t\t Validation loss: 0.585618\n",
            "Training average batch accuracy: 0.664750\n",
            "Validation average batch accuracy: 0.685938\n",
            "Epoch 41: Loss: 0.597582 \t\t Validation loss: 0.587961\n",
            "Training average batch accuracy: 0.682625\n",
            "Validation average batch accuracy: 0.683984\n",
            "Epoch 42: Loss: 0.597699 \t\t Validation loss: 0.585528\n",
            "Training average batch accuracy: 0.682625\n",
            "Validation average batch accuracy: 0.684961\n",
            "Epoch 43: Loss: 0.600814 \t\t Validation loss: 0.583630\n",
            "Training average batch accuracy: 0.674250\n",
            "Validation average batch accuracy: 0.697461\n",
            "Epoch 44: Loss: 0.605129 \t\t Validation loss: 0.588174\n",
            "Training average batch accuracy: 0.664625\n",
            "Validation average batch accuracy: 0.685156\n",
            "Epoch 45: Loss: 0.600800 \t\t Validation loss: 0.589410\n",
            "Training average batch accuracy: 0.672125\n",
            "Validation average batch accuracy: 0.668945\n",
            "Epoch 46: Loss: 0.593682 \t\t Validation loss: 0.589509\n",
            "Training average batch accuracy: 0.683875\n",
            "Validation average batch accuracy: 0.681250\n",
            "Epoch 47: Loss: 0.599122 \t\t Validation loss: 0.592039\n",
            "Training average batch accuracy: 0.672000\n",
            "Validation average batch accuracy: 0.672266\n",
            "Epoch 48: Loss: 0.599800 \t\t Validation loss: 0.591900\n",
            "Training average batch accuracy: 0.675125\n",
            "Validation average batch accuracy: 0.683008\n",
            "Epoch 49: Loss: 0.594844 \t\t Validation loss: 0.589270\n",
            "Training average batch accuracy: 0.675750\n",
            "Validation average batch accuracy: 0.693359\n",
            "Epoch 50: Loss: 0.589091 \t\t Validation loss: 0.591767\n",
            "Training average batch accuracy: 0.686875\n",
            "Validation average batch accuracy: 0.665625\n",
            "Epoch 51: Loss: 0.590883 \t\t Validation loss: 0.592729\n",
            "Training average batch accuracy: 0.688375\n",
            "Validation average batch accuracy: 0.662500\n",
            "Epoch 52: Loss: 0.593469 \t\t Validation loss: 0.586473\n",
            "Training average batch accuracy: 0.679375\n",
            "Validation average batch accuracy: 0.690820\n",
            "Epoch 53: Loss: 0.592983 \t\t Validation loss: 0.590642\n",
            "Training average batch accuracy: 0.679875\n",
            "Validation average batch accuracy: 0.669336\n",
            "Epoch 54: Loss: 0.587066 \t\t Validation loss: 0.584819\n",
            "Training average batch accuracy: 0.694000\n",
            "Validation average batch accuracy: 0.696094\n",
            "Epoch 55: Loss: 0.592444 \t\t Validation loss: 0.589792\n",
            "Training average batch accuracy: 0.682625\n",
            "Validation average batch accuracy: 0.688477\n",
            "Epoch 56: Loss: 0.589000 \t\t Validation loss: 0.584166\n",
            "Training average batch accuracy: 0.685875\n",
            "Validation average batch accuracy: 0.685352\n",
            "Epoch 57: Loss: 0.587267 \t\t Validation loss: 0.589400\n",
            "Training average batch accuracy: 0.682625\n",
            "Validation average batch accuracy: 0.668164\n",
            "Epoch 58: Loss: 0.589416 \t\t Validation loss: 0.587395\n",
            "Training average batch accuracy: 0.684000\n",
            "Validation average batch accuracy: 0.683008\n",
            "Epoch 59: Loss: 0.587185 \t\t Validation loss: 0.583562\n",
            "Training average batch accuracy: 0.686750\n",
            "Validation average batch accuracy: 0.686328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SRlb4YxZ2sP",
        "outputId": "8f141908-5b92-45b5-8ad8-e7cc3ed86876"
      },
      "source": [
        "# Percenatage of <unk> \n",
        "sum(train_dataset.counter['unk_tokens'].values()) / sum(list(train_dataset.counter['token'].values())) * 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7770800627943485"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jPOQjslF142"
      },
      "source": [
        "## Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn04nSAZ-SKM"
      },
      "source": [
        "### Ratio of all words in corpus to OOV words\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "r-m8SCJvbERw",
        "outputId": "21a12cc2-c405-4547-933e-6b3f24e57a69"
      },
      "source": [
        "pd.DataFrame({'Number of words': [sum(list(train_dataset.counter['token'].values())), \n",
        "                                 sum(train_dataset.counter['unk_tokens'].values())], \n",
        "              'lab': ['All words', 'Unknown']}).plot.bar(x='lab', rot=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fde62ed9bd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjVF0EPm-dUq"
      },
      "source": [
        "### Comparison of training procedure with random replacement and without"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "MLI28NrUC__C",
        "outputId": "ff7ac654-79b6-43cc-93e1-5b4d358f5e47"
      },
      "source": [
        "plot_hist(hist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "7cbDJAHfF3jz",
        "outputId": "e8fb1f68-5120-4979-f325-c864fcc60be3"
      },
      "source": [
        "# dropout 0.6  rand_replace=0.2\n",
        "plot_hist(hist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGWG9C4hIR0G"
      },
      "source": [
        "# Context encoder (CE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfYefKPRl2Ja"
      },
      "source": [
        "## Dataloader for dataset for language model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "6d7b64dbfca848f8b40a7546b6a9bd61",
            "6fae63fbe05a4ec5878428819ea162f5",
            "2614b2d0484b4b189e0a896d73b46c72",
            "86b3d04109b6489eb5edb192e27d2287",
            "0d0186eec4da4610abd8f8ffc1336a13",
            "54995a4ec8f14b8b94870d57bd56c43a",
            "0ddbe68625f348b3baf8b6ee525273de",
            "9da84c05d993449aa980216e078730c0",
            "40c9c8da83b44e07847aa1a048eb0dd7",
            "5552775cc5164808a082c7e1fa43b576",
            "a600821bc2fc4358919c35fe55bca1fa",
            "d243ea5ea42f45e1af8c55ab0307e5e5",
            "7fa7870a0b3e441b8ee958ab7144c357",
            "5572f1eee13046ea8d2d8d2f38c78638",
            "d4e923ed96584c4fb7876ddb70cee68f",
            "67ad9b72d8894c8088d777a2c8e0c2a9"
          ]
        },
        "id": "9-FbNWiIJwXq",
        "outputId": "71810a85-4072-4540-9e33-63f08609894f"
      },
      "source": [
        "def context_train_step(model, batch):\n",
        "    loss, _ = model(*list(batch))\n",
        "    return {'loss': loss}\n",
        "\n",
        "def context_eval_step(model, batch):\n",
        "    loss, _ = model(*list(batch))\n",
        "    return {'loss': loss}\n",
        "\n",
        "\n",
        "class PadCollator_2(DeviceObject):\n",
        "    '''\n",
        "    Collator for dataloader for Context Encoder part: consider one sentence at the time; \n",
        "    makes paddings in sentences and in tags; include tags if include_pos_tags is set\n",
        "    '''\n",
        "    def __init__(self, pad_token_id, include_pos_tags=False, pad_tag_id=None):\n",
        "        self.pad_token_id = pad_token_id\n",
        "        self.pad_tag_id = pad_tag_id\n",
        "        self.include_pos_tags = include_pos_tags\n",
        "    \n",
        "    def __call__(self, batch):\n",
        "        seq_length = torch.tensor([b['seq_length'] for b in batch], device=self.device)\n",
        "        tokens = [b['tokens'] for b in batch]\n",
        "        masked_id = torch.tensor([b['token_id'] for b in batch], device=self.device)\n",
        "        labels = torch.tensor([b['label'] for b in batch], dtype=torch.float, device=self.device)\n",
        "        \n",
        "        # Padding of sentences\n",
        "        tokens = torch.nn.utils.rnn.pad_sequence(tokens, batch_first=True, padding_value=self.pad_token_id).to(self.device)\n",
        "        shape = tokens.shape\n",
        "\n",
        "        unk_position = torch.tensor([b['unk_position'] for b in batch], device=self.device).unsqueeze(1)\n",
        "        # Making one hot encoding representation of position of masked token\n",
        "        unk_position = torch.zeros(shape[0], shape[1], dtype=torch.int, device=self.device).scatter(1, unk_position, 1)\n",
        "        \n",
        "        if self.include_pos_tags:\n",
        "            tags = [torch.tensor(b['tags']) for b in batch]\n",
        "            # Padding of tags\n",
        "            tags = torch.nn.utils.rnn.pad_sequence(tags, batch_first=True, padding_value=self.pad_tag_id).to(self.device)\n",
        "            tags[unk_position == 1] = self.pad_tag_id\n",
        "            \n",
        "            return  tokens, unk_position, tags, masked_id, labels\n",
        "\n",
        "        return  tokens, unk_position, masked_id, labels\n",
        "\n",
        "MAX_LENGTH = None\n",
        "include_pos_tags = False\n",
        "train_dataset_context = WiCDataset('data/train.jsonl', vectors, mask_word_mode=True,\n",
        "                                   rand_replace=0.1,\n",
        "                                   swap_tokens=0.3,\n",
        "                                   with_pos_tags=include_pos_tags,\n",
        "                                   #rand_replace_mode='unk_tokens',\n",
        "                                   #lemmatization=True,\n",
        "                                   remove_stop_words=not include_pos_tags, # If we include tags we do not remove stopwords\n",
        "                                   max_length=MAX_LENGTH)\n",
        "valid_dataset_context = WiCDataset('data/dev.jsonl', vectors, \n",
        "                                   #lemmatization=True,\n",
        "                                   with_pos_tags=include_pos_tags,\n",
        "                                   mask_word_mode=True, \n",
        "                                   remove_stop_words=not include_pos_tags,\n",
        "                                   )\n",
        "\n",
        "collate_obj = PadCollator_2(vectors.get_id('<pad>'), \n",
        "                            include_pos_tags=include_pos_tags, pad_tag_id=train_dataset_context.num_pos_classes)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader_context = DataLoader(train_dataset_context, \n",
        "                                  shuffle=True, batch_size=batch_size, collate_fn=collate_obj)\n",
        "valid_loader_context = DataLoader(valid_dataset_context, \n",
        "                                  batch_size=batch_size, collate_fn=collate_obj)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d7b64dbfca848f8b40a7546b6a9bd61",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40c9c8da83b44e07847aa1a048eb0dd7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wArqUr6XFgN1"
      },
      "source": [
        "## Model CE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_Ze2SgIFj7b"
      },
      "source": [
        "class ContextParams:\n",
        "    dropout = 0.7\n",
        "    bidirectional = True\n",
        "    num_layers = 2\n",
        "    attention_dropout=0.7\n",
        "    max_length=train_dataset_context.max_length\n",
        "\n",
        "    # POS Mode\n",
        "    pos_classes = WiCDataset.num_pos_classes\n",
        "    pos_embed_dim = 100\n",
        "\n",
        "class ContextEncoder(nn.Module, DeviceObject):\n",
        "    '''\n",
        "    Language model that mask a word and it is trained to predict if a given word fit to context.\n",
        "    We use negative sampling so we concatenate output from LSTM with either word embedding of real token \n",
        "    or token sampled randomly from corpus with probability to occur as it is present in the corpus.\n",
        "    '''\n",
        "    def __init__(self, params, vocab, \n",
        "                 cosine_mode=False, # In cosine mode we \n",
        "                 with_pos_tags=False, # Include POS tags from NLTK library\n",
        "                 multi_learn=False # This option was not fully implemented\n",
        "                 ): \n",
        "        super().__init__()\n",
        "        self.with_pos_tags = with_pos_tags\n",
        "        self.vocab = vocab\n",
        "        self.cosine_mode = cosine_mode\n",
        "        self.multi_learn = multi_learn\n",
        "\n",
        "        embeddings = vocab.vectors\n",
        "        input_size = embeddings[0].shape[0]\n",
        "        self.word_embeddings = nn.Embedding.from_pretrained(embeddings)\n",
        "\n",
        "        rnn_out_size = input_size * 2\n",
        "        self.rnn = nn.LSTM(input_size + (params.pos_embed_dim if with_pos_tags and not multi_learn else 0), rnn_out_size, \n",
        "                            bidirectional=params.bidirectional,\n",
        "                            num_layers=params.num_layers, \n",
        "                            dropout=params.dropout,\n",
        "                            batch_first=True)\n",
        "        \n",
        "        self.rnn_2 = nn.LSTM(rnn_out_size * 2, rnn_out_size, \n",
        "                            bidirectional=params.bidirectional,\n",
        "                            num_layers=params.num_layers, \n",
        "                            dropout=params.dropout,\n",
        "                            batch_first=True)\n",
        "        \n",
        "        # There was attention before so var name is left :) - it is size of hidden layer in classifier\n",
        "        attn_input_dim = rnn_out_size * (2 if params.bidirectional else 1)\n",
        "        \n",
        "        self.vocab_size = len(vocab.itos)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(input_size*5, attn_input_dim * 4),\n",
        "            nn.BatchNorm1d(attn_input_dim * 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=params.attention_dropout),\n",
        "\n",
        "            nn.Linear(attn_input_dim * 4, 1)\n",
        "        )\n",
        "        if cosine_mode:\n",
        "            # Transformation MLP\n",
        "            self.transform = nn.Sequential(\n",
        "                nn.Linear(input_size*4, input_size*4),\n",
        "                nn.BatchNorm1d(input_size*4),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(p=params.attention_dropout),\n",
        "\n",
        "                nn.Linear(input_size*4, input_size)\n",
        "            )\n",
        "            self.cosine = nn.CosineSimilarity()\n",
        "        \n",
        "        self.loss = nn.BCELoss()\n",
        "\n",
        "        if with_pos_tags:\n",
        "            if multi_learn:\n",
        "                self.pos_classier = nn.Sequential(\n",
        "                    nn.Linear(input_size*4, input_size*2),\n",
        "                    nn.BatchNorm1d(input_size*2),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Dropout(p=params.attention_dropout),\n",
        "\n",
        "                    nn.Linear(input_size*2, params.pos_classes + 1)\n",
        "                )\n",
        "                self.pos_loss = nn.CrossEntropyLoss()\n",
        "            else:\n",
        "                self.pos_embeddings = nn.Embedding(params.pos_classes + 1, params.pos_embed_dim,)\n",
        "            \n",
        "        self.to(self.device)\n",
        "    \n",
        "    def forward(self, *args):\n",
        "        # Forward function depends on whether we use POS tags or not\n",
        "        if self.with_pos_tags:\n",
        "            return self.pos_tag_forward(*args)\n",
        "        else:\n",
        "            return self.main_forward(*args)\n",
        "\n",
        "    def main_forward(self, tokens, unk_position, token_id=None, target=None, tags=None):\n",
        "        seq_embeds = self.word_embeddings(tokens)\n",
        "        input_shape = seq_embeds.shape\n",
        "\n",
        "        if tags is not None:\n",
        "            if not self.multi_learn:\n",
        "                tags_embeds = self.pos_embeddings(tags)\n",
        "                seq_embeds = torch.cat((seq_embeds, tags_embeds), dim=-1)\n",
        "\n",
        "        # Staking two Bi-LSTMs\n",
        "        rnn_out, (h, c) = self.rnn(seq_embeds)\n",
        "        rnn_out, (h, c) = self.rnn_2(rnn_out)\n",
        "\n",
        "        # Taking RNN output only in position of masking token\n",
        "        unk_context = rnn_out[unk_position == 1]\n",
        "\n",
        "        out_for_loss, loss,  = None, None\n",
        "        # Transformation in case of cosine mode\n",
        "        trans_vector = self.transform(unk_context) if self.cosine_mode else None\n",
        "        \n",
        "        # Training part\n",
        "        if token_id is not None:\n",
        "            if len(token_id.shape) == 2:\n",
        "                word_embeddings = token_id\n",
        "            else:\n",
        "                word_embeddings = self.word_embeddings(token_id)\n",
        "            \n",
        "            if self.cosine_mode:\n",
        "                # Transforming so value is in [0, 1]\n",
        "                out_for_loss = (self.cosine(word_embeddings, trans_vector) + 1)/2\n",
        "            else:\n",
        "                # Normal mode part\n",
        "                to_classify = torch.cat((\n",
        "                    word_embeddings, \n",
        "                    unk_context,\n",
        "                    ), dim=-1)\n",
        "\n",
        "                out_for_loss = self.classifier(to_classify)\n",
        "                out_for_loss = torch.sigmoid(out_for_loss).squeeze()\n",
        "\n",
        "            # Multi-task learning block\n",
        "            extra_loss = 0\n",
        "            if self.multi_learn:\n",
        "                tag_target = tags[unk_position == 1]\n",
        "                extra_loss = self.pos_loss(self.pos_classier(unk_context), tag_target)\n",
        "            \n",
        "            # Caclulating overall loss\n",
        "            loss = self.loss(out_for_loss, target) + extra_loss\n",
        "\n",
        "        return (unk_context, trans_vector), out_for_loss, loss\n",
        "\n",
        "    def pos_tag_forward(self, *args):\n",
        "        '''\n",
        "        Different from main_forward in sequence of parameters that we should place to forward \n",
        "        '''\n",
        "        if len(args) == 3:\n",
        "            token_id, target, tags = [None] * 3\n",
        "            tokens, unk_position, tags = args\n",
        "        else:\n",
        "            tokens, unk_position, tags, token_id, target = args\n",
        "        \n",
        "        return self.main_forward(tokens, unk_position, token_id, target, tags)\n",
        "        #raise 'No pos tagging yet!!! Gotcha ;)'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oQ4NTEFrLbBn",
        "outputId": "834a059e-b4db-434d-c7fd-041558591a2e"
      },
      "source": [
        "def context_train_step_2(model, batch):\n",
        "    (unk_context, rnn_context), preds, loss = model(*list(batch))\n",
        "    return {'loss': loss, 'batch_accuracy': binary_accuracy(preds, batch[-1])}\n",
        "\n",
        "def context_eval_step_2(model, batch):\n",
        "    (unk_context, rnn_context), preds, loss = model(*list(batch))\n",
        "    return loss, binary_accuracy(preds, batch[-1])\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, eval_step):\n",
        "    '''\n",
        "    Since validation loss is noisy because of presence of negative samples,\n",
        "    we average N times it to see kind of real value \n",
        "    '''\n",
        "    model.eval()\n",
        "    results = []\n",
        "    losses = []\n",
        "    \n",
        "    for k in range(10):\n",
        "        for i, batch in enumerate(data_loader):\n",
        "            loss, metric = eval_step(model, batch)\n",
        "            losses.append(loss.item())\n",
        "            results.append(metric)\n",
        "\n",
        "    return sum(losses) / len(losses), sum(results) / len(results)\n",
        "\n",
        "\n",
        "\n",
        "model_context = ContextEncoder(ContextParams(), vectors, \n",
        "                               #cosine_mode=True,\n",
        "                               with_pos_tags=False,\n",
        "                               multi_learn=False\n",
        "                               )\n",
        "optim_context = torch.optim.Adam(model_context.parameters(), lr=0.0001)\n",
        "\n",
        "# We didn't see any effect of scheduler in this problem, but we kept it\n",
        "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim_context, factor=0.9, verbose=True)\n",
        "scheduler=None\n",
        "\n",
        "best_model = {}\n",
        "hist = {}\n",
        "\n",
        "best_state_dict, _ = train(train_loader_context, valid_loader_context, \n",
        "      model_context, optim_context, \n",
        "      context_train_step_2, \n",
        "      context_eval_step_2,\n",
        "      300, best_model, \n",
        "      best_model_mode='accuracy', \n",
        "      hist=hist,\n",
        "      scheduler=scheduler)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss: 1.800756 \t\t Validation loss: 0.793206\n",
            "BEST SCORE: tensor(0.5082, device='cuda:0')\n",
            "Training average batch accuracy: 0.507250\n",
            "Validation average batch accuracy: 0.508154\n",
            "Epoch 1: Loss: 0.785910 \t\t Validation loss: 0.723286\n",
            "BEST SCORE: tensor(0.5151, device='cuda:0')\n",
            "Training average batch accuracy: 0.504000\n",
            "Validation average batch accuracy: 0.515137\n",
            "Epoch 2: Loss: 0.743544 \t\t Validation loss: 0.711034\n",
            "BEST SCORE: tensor(0.5170, device='cuda:0')\n",
            "Training average batch accuracy: 0.506000\n",
            "Validation average batch accuracy: 0.517041\n",
            "Epoch 3: Loss: 0.730676 \t\t Validation loss: 0.698701\n",
            "BEST SCORE: tensor(0.5195, device='cuda:0')\n",
            "Training average batch accuracy: 0.508625\n",
            "Validation average batch accuracy: 0.519482\n",
            "Epoch 4: Loss: 0.723566 \t\t Validation loss: 0.697059\n",
            "Training average batch accuracy: 0.502937\n",
            "Validation average batch accuracy: 0.514111\n",
            "Epoch 5: Loss: 0.718267 \t\t Validation loss: 0.693283\n",
            "BEST SCORE: tensor(0.5236, device='cuda:0')\n",
            "Training average batch accuracy: 0.505000\n",
            "Validation average batch accuracy: 0.523633\n",
            "Epoch 6: Loss: 0.713834 \t\t Validation loss: 0.693346\n",
            "Training average batch accuracy: 0.510500\n",
            "Validation average batch accuracy: 0.521875\n",
            "Epoch 7: Loss: 0.712074 \t\t Validation loss: 0.709486\n",
            "Training average batch accuracy: 0.510750\n",
            "Validation average batch accuracy: 0.511475\n",
            "Epoch 8: Loss: 0.712025 \t\t Validation loss: 0.695714\n",
            "Training average batch accuracy: 0.503938\n",
            "Validation average batch accuracy: 0.518359\n",
            "Epoch 9: Loss: 0.707795 \t\t Validation loss: 0.692904\n",
            "BEST SCORE: tensor(0.5269, device='cuda:0')\n",
            "Training average batch accuracy: 0.511125\n",
            "Validation average batch accuracy: 0.526855\n",
            "Epoch 10: Loss: 0.706805 \t\t Validation loss: 0.701095\n",
            "Training average batch accuracy: 0.512250\n",
            "Validation average batch accuracy: 0.507617\n",
            "Epoch 11: Loss: 0.706545 \t\t Validation loss: 0.698203\n",
            "Training average batch accuracy: 0.513000\n",
            "Validation average batch accuracy: 0.512061\n",
            "Epoch 12: Loss: 0.706579 \t\t Validation loss: 0.691241\n",
            "BEST SCORE: tensor(0.5284, device='cuda:0')\n",
            "Training average batch accuracy: 0.508375\n",
            "Validation average batch accuracy: 0.528369\n",
            "Epoch 13: Loss: 0.704796 \t\t Validation loss: 0.697593\n",
            "Training average batch accuracy: 0.511625\n",
            "Validation average batch accuracy: 0.511963\n",
            "Epoch 14: Loss: 0.702316 \t\t Validation loss: 0.689599\n",
            "BEST SCORE: tensor(0.5299, device='cuda:0')\n",
            "Training average batch accuracy: 0.513125\n",
            "Validation average batch accuracy: 0.529932\n",
            "Epoch 15: Loss: 0.701096 \t\t Validation loss: 0.688158\n",
            "BEST SCORE: tensor(0.5447, device='cuda:0')\n",
            "Training average batch accuracy: 0.519188\n",
            "Validation average batch accuracy: 0.544678\n",
            "Epoch 16: Loss: 0.698875 \t\t Validation loss: 0.690529\n",
            "Training average batch accuracy: 0.519500\n",
            "Validation average batch accuracy: 0.521387\n",
            "Epoch 17: Loss: 0.694872 \t\t Validation loss: 0.681773\n",
            "BEST SCORE: tensor(0.5513, device='cuda:0')\n",
            "Training average batch accuracy: 0.533688\n",
            "Validation average batch accuracy: 0.551318\n",
            "Epoch 18: Loss: 0.691451 \t\t Validation loss: 0.680316\n",
            "BEST SCORE: tensor(0.5624, device='cuda:0')\n",
            "Training average batch accuracy: 0.540188\n",
            "Validation average batch accuracy: 0.562354\n",
            "Epoch 19: Loss: 0.686599 \t\t Validation loss: 0.695550\n",
            "Training average batch accuracy: 0.548875\n",
            "Validation average batch accuracy: 0.546191\n",
            "Epoch 20: Loss: 0.680043 \t\t Validation loss: 0.673261\n",
            "BEST SCORE: tensor(0.5716, device='cuda:0')\n",
            "Training average batch accuracy: 0.564438\n",
            "Validation average batch accuracy: 0.571631\n",
            "Epoch 21: Loss: 0.675610 \t\t Validation loss: 0.671577\n",
            "Training average batch accuracy: 0.571313\n",
            "Validation average batch accuracy: 0.570996\n",
            "Epoch 22: Loss: 0.674681 \t\t Validation loss: 0.668721\n",
            "BEST SCORE: tensor(0.5805, device='cuda:0')\n",
            "Training average batch accuracy: 0.580688\n",
            "Validation average batch accuracy: 0.580518\n",
            "Epoch 23: Loss: 0.669223 \t\t Validation loss: 0.656536\n",
            "BEST SCORE: tensor(0.5961, device='cuda:0')\n",
            "Training average batch accuracy: 0.582313\n",
            "Validation average batch accuracy: 0.596094\n",
            "Epoch 24: Loss: 0.664896 \t\t Validation loss: 0.661713\n",
            "Training average batch accuracy: 0.589438\n",
            "Validation average batch accuracy: 0.589795\n",
            "Epoch 25: Loss: 0.662453 \t\t Validation loss: 0.653961\n",
            "BEST SCORE: tensor(0.6012, device='cuda:0')\n",
            "Training average batch accuracy: 0.594500\n",
            "Validation average batch accuracy: 0.601221\n",
            "Epoch 26: Loss: 0.661768 \t\t Validation loss: 0.658547\n",
            "Training average batch accuracy: 0.598750\n",
            "Validation average batch accuracy: 0.592822\n",
            "Epoch 27: Loss: 0.659303 \t\t Validation loss: 0.656465\n",
            "Training average batch accuracy: 0.598438\n",
            "Validation average batch accuracy: 0.599316\n",
            "Epoch 28: Loss: 0.653840 \t\t Validation loss: 0.649430\n",
            "BEST SCORE: tensor(0.6110, device='cuda:0')\n",
            "Training average batch accuracy: 0.604313\n",
            "Validation average batch accuracy: 0.610986\n",
            "Epoch 29: Loss: 0.653489 \t\t Validation loss: 0.649990\n",
            "BEST SCORE: tensor(0.6146, device='cuda:0')\n",
            "Training average batch accuracy: 0.607188\n",
            "Validation average batch accuracy: 0.614600\n",
            "Epoch 30: Loss: 0.651881 \t\t Validation loss: 0.633420\n",
            "BEST SCORE: tensor(0.6318, device='cuda:0')\n",
            "Training average batch accuracy: 0.607938\n",
            "Validation average batch accuracy: 0.631787\n",
            "Epoch 31: Loss: 0.645475 \t\t Validation loss: 0.633183\n",
            "BEST SCORE: tensor(0.6333, device='cuda:0')\n",
            "Training average batch accuracy: 0.624563\n",
            "Validation average batch accuracy: 0.633301\n",
            "Epoch 32: Loss: 0.644668 \t\t Validation loss: 0.628291\n",
            "BEST SCORE: tensor(0.6333, device='cuda:0')\n",
            "Training average batch accuracy: 0.627188\n",
            "Validation average batch accuracy: 0.633350\n",
            "Epoch 33: Loss: 0.643163 \t\t Validation loss: 0.630088\n",
            "BEST SCORE: tensor(0.6348, device='cuda:0')\n",
            "Training average batch accuracy: 0.620625\n",
            "Validation average batch accuracy: 0.634814\n",
            "Epoch 34: Loss: 0.635035 \t\t Validation loss: 0.625652\n",
            "BEST SCORE: tensor(0.6431, device='cuda:0')\n",
            "Training average batch accuracy: 0.632125\n",
            "Validation average batch accuracy: 0.643115\n",
            "Epoch 35: Loss: 0.637734 \t\t Validation loss: 0.623014\n",
            "BEST SCORE: tensor(0.6480, device='cuda:0')\n",
            "Training average batch accuracy: 0.627688\n",
            "Validation average batch accuracy: 0.647998\n",
            "Epoch 36: Loss: 0.635346 \t\t Validation loss: 0.616956\n",
            "BEST SCORE: tensor(0.6499, device='cuda:0')\n",
            "Training average batch accuracy: 0.631938\n",
            "Validation average batch accuracy: 0.649902\n",
            "Epoch 37: Loss: 0.629024 \t\t Validation loss: 0.617235\n",
            "BEST SCORE: tensor(0.6507, device='cuda:0')\n",
            "Training average batch accuracy: 0.641938\n",
            "Validation average batch accuracy: 0.650732\n",
            "Epoch 38: Loss: 0.633259 \t\t Validation loss: 0.608447\n",
            "BEST SCORE: tensor(0.6604, device='cuda:0')\n",
            "Training average batch accuracy: 0.634500\n",
            "Validation average batch accuracy: 0.660352\n",
            "Epoch 39: Loss: 0.627734 \t\t Validation loss: 0.613872\n",
            "Training average batch accuracy: 0.641438\n",
            "Validation average batch accuracy: 0.655176\n",
            "Epoch 40: Loss: 0.623448 \t\t Validation loss: 0.602751\n",
            "BEST SCORE: tensor(0.6733, device='cuda:0')\n",
            "Training average batch accuracy: 0.649063\n",
            "Validation average batch accuracy: 0.673340\n",
            "Epoch 41: Loss: 0.623892 \t\t Validation loss: 0.601823\n",
            "Training average batch accuracy: 0.648938\n",
            "Validation average batch accuracy: 0.667041\n",
            "Epoch 42: Loss: 0.623199 \t\t Validation loss: 0.598570\n",
            "BEST SCORE: tensor(0.6767, device='cuda:0')\n",
            "Training average batch accuracy: 0.649188\n",
            "Validation average batch accuracy: 0.676660\n",
            "Epoch 43: Loss: 0.613922 \t\t Validation loss: 0.593190\n",
            "BEST SCORE: tensor(0.6844, device='cuda:0')\n",
            "Training average batch accuracy: 0.654188\n",
            "Validation average batch accuracy: 0.684424\n",
            "Epoch 44: Loss: 0.613426 \t\t Validation loss: 0.584901\n",
            "BEST SCORE: tensor(0.6946, device='cuda:0')\n",
            "Training average batch accuracy: 0.664500\n",
            "Validation average batch accuracy: 0.694580\n",
            "Epoch 45: Loss: 0.609116 \t\t Validation loss: 0.583567\n",
            "Training average batch accuracy: 0.668813\n",
            "Validation average batch accuracy: 0.692676\n",
            "Epoch 46: Loss: 0.602768 \t\t Validation loss: 0.587733\n",
            "Training average batch accuracy: 0.669688\n",
            "Validation average batch accuracy: 0.683252\n",
            "Epoch 47: Loss: 0.601046 \t\t Validation loss: 0.572967\n",
            "BEST SCORE: tensor(0.7023, device='cuda:0')\n",
            "Training average batch accuracy: 0.673688\n",
            "Validation average batch accuracy: 0.702295\n",
            "Epoch 48: Loss: 0.592865 \t\t Validation loss: 0.574510\n",
            "Training average batch accuracy: 0.678188\n",
            "Validation average batch accuracy: 0.699023\n",
            "Epoch 49: Loss: 0.594143 \t\t Validation loss: 0.564736\n",
            "BEST SCORE: tensor(0.7142, device='cuda:0')\n",
            "Training average batch accuracy: 0.679625\n",
            "Validation average batch accuracy: 0.714160\n",
            "Epoch 50: Loss: 0.592457 \t\t Validation loss: 0.564025\n",
            "Training average batch accuracy: 0.681875\n",
            "Validation average batch accuracy: 0.706104\n",
            "Epoch 51: Loss: 0.588480 \t\t Validation loss: 0.559890\n",
            "Training average batch accuracy: 0.683438\n",
            "Validation average batch accuracy: 0.710303\n",
            "Epoch 52: Loss: 0.587249 \t\t Validation loss: 0.555645\n",
            "BEST SCORE: tensor(0.7177, device='cuda:0')\n",
            "Training average batch accuracy: 0.684313\n",
            "Validation average batch accuracy: 0.717676\n",
            "Epoch 53: Loss: 0.581044 \t\t Validation loss: 0.557667\n",
            "Training average batch accuracy: 0.694813\n",
            "Validation average batch accuracy: 0.710693\n",
            "Epoch 54: Loss: 0.583664 \t\t Validation loss: 0.557138\n",
            "Training average batch accuracy: 0.690500\n",
            "Validation average batch accuracy: 0.714502\n",
            "Epoch 55: Loss: 0.576248 \t\t Validation loss: 0.549724\n",
            "BEST SCORE: tensor(0.7184, device='cuda:0')\n",
            "Training average batch accuracy: 0.697563\n",
            "Validation average batch accuracy: 0.718359\n",
            "Epoch 56: Loss: 0.586274 \t\t Validation loss: 0.543224\n",
            "BEST SCORE: tensor(0.7292, device='cuda:0')\n",
            "Training average batch accuracy: 0.688063\n",
            "Validation average batch accuracy: 0.729248\n",
            "Epoch 57: Loss: 0.578097 \t\t Validation loss: 0.545000\n",
            "Training average batch accuracy: 0.692000\n",
            "Validation average batch accuracy: 0.728125\n",
            "Epoch 58: Loss: 0.571599 \t\t Validation loss: 0.541556\n",
            "Training average batch accuracy: 0.702625\n",
            "Validation average batch accuracy: 0.724512\n",
            "Epoch 59: Loss: 0.575952 \t\t Validation loss: 0.537750\n",
            "BEST SCORE: tensor(0.7336, device='cuda:0')\n",
            "Training average batch accuracy: 0.698813\n",
            "Validation average batch accuracy: 0.733643\n",
            "Epoch 60: Loss: 0.574142 \t\t Validation loss: 0.538395\n",
            "Training average batch accuracy: 0.697000\n",
            "Validation average batch accuracy: 0.731299\n",
            "Epoch 61: Loss: 0.568039 \t\t Validation loss: 0.533376\n",
            "Training average batch accuracy: 0.704875\n",
            "Validation average batch accuracy: 0.733545\n",
            "Epoch 62: Loss: 0.572194 \t\t Validation loss: 0.539046\n",
            "Training average batch accuracy: 0.698750\n",
            "Validation average batch accuracy: 0.728320\n",
            "Epoch 63: Loss: 0.572039 \t\t Validation loss: 0.526672\n",
            "BEST SCORE: tensor(0.7402, device='cuda:0')\n",
            "Training average batch accuracy: 0.704688\n",
            "Validation average batch accuracy: 0.740186\n",
            "Epoch 64: Loss: 0.563786 \t\t Validation loss: 0.524313\n",
            "BEST SCORE: tensor(0.7435, device='cuda:0')\n",
            "Training average batch accuracy: 0.712375\n",
            "Validation average batch accuracy: 0.743506\n",
            "Epoch 65: Loss: 0.565472 \t\t Validation loss: 0.530496\n",
            "Training average batch accuracy: 0.708688\n",
            "Validation average batch accuracy: 0.742236\n",
            "Epoch 66: Loss: 0.561623 \t\t Validation loss: 0.527651\n",
            "Training average batch accuracy: 0.714563\n",
            "Validation average batch accuracy: 0.736914\n",
            "Epoch 67: Loss: 0.557141 \t\t Validation loss: 0.525948\n",
            "Training average batch accuracy: 0.713563\n",
            "Validation average batch accuracy: 0.739795\n",
            "Epoch 68: Loss: 0.564252 \t\t Validation loss: 0.523750\n",
            "BEST SCORE: tensor(0.7467, device='cuda:0')\n",
            "Training average batch accuracy: 0.704313\n",
            "Validation average batch accuracy: 0.746680\n",
            "Epoch 69: Loss: 0.556181 \t\t Validation loss: 0.524214\n",
            "Training average batch accuracy: 0.718688\n",
            "Validation average batch accuracy: 0.738818\n",
            "Epoch 70: Loss: 0.553720 \t\t Validation loss: 0.529666\n",
            "Training average batch accuracy: 0.716438\n",
            "Validation average batch accuracy: 0.741406\n",
            "Epoch 71: Loss: 0.554776 \t\t Validation loss: 0.522330\n",
            "Training average batch accuracy: 0.714688\n",
            "Validation average batch accuracy: 0.738965\n",
            "Epoch 72: Loss: 0.555083 \t\t Validation loss: 0.540549\n",
            "Training average batch accuracy: 0.718750\n",
            "Validation average batch accuracy: 0.730371\n",
            "Epoch 73: Loss: 0.552165 \t\t Validation loss: 0.514173\n",
            "BEST SCORE: tensor(0.7495, device='cuda:0')\n",
            "Training average batch accuracy: 0.716688\n",
            "Validation average batch accuracy: 0.749512\n",
            "Epoch 74: Loss: 0.549106 \t\t Validation loss: 0.522154\n",
            "Training average batch accuracy: 0.717563\n",
            "Validation average batch accuracy: 0.743945\n",
            "Epoch 75: Loss: 0.553587 \t\t Validation loss: 0.513214\n",
            "Training average batch accuracy: 0.718938\n",
            "Validation average batch accuracy: 0.746582\n",
            "Epoch 76: Loss: 0.552045 \t\t Validation loss: 0.511821\n",
            "Training average batch accuracy: 0.720938\n",
            "Validation average batch accuracy: 0.747119\n",
            "Epoch 77: Loss: 0.553044 \t\t Validation loss: 0.521384\n",
            "Training average batch accuracy: 0.723250\n",
            "Validation average batch accuracy: 0.742676\n",
            "Epoch 78: Loss: 0.550948 \t\t Validation loss: 0.513386\n",
            "BEST SCORE: tensor(0.7514, device='cuda:0')\n",
            "Training average batch accuracy: 0.722375\n",
            "Validation average batch accuracy: 0.751367\n",
            "Epoch 79: Loss: 0.548912 \t\t Validation loss: 0.511072\n",
            "Training average batch accuracy: 0.720500\n",
            "Validation average batch accuracy: 0.750439\n",
            "Epoch 80: Loss: 0.541163 \t\t Validation loss: 0.516435\n",
            "Training average batch accuracy: 0.726313\n",
            "Validation average batch accuracy: 0.745313\n",
            "Epoch 81: Loss: 0.545556 \t\t Validation loss: 0.519000\n",
            "Training average batch accuracy: 0.724688\n",
            "Validation average batch accuracy: 0.746631\n",
            "Epoch 82: Loss: 0.543130 \t\t Validation loss: 0.511698\n",
            "BEST SCORE: tensor(0.7514, device='cuda:0')\n",
            "Training average batch accuracy: 0.725563\n",
            "Validation average batch accuracy: 0.751416\n",
            "Epoch 83: Loss: 0.541974 \t\t Validation loss: 0.508418\n",
            "BEST SCORE: tensor(0.7528, device='cuda:0')\n",
            "Training average batch accuracy: 0.726438\n",
            "Validation average batch accuracy: 0.752832\n",
            "Epoch 84: Loss: 0.541114 \t\t Validation loss: 0.515180\n",
            "Training average batch accuracy: 0.726563\n",
            "Validation average batch accuracy: 0.750391\n",
            "Epoch 85: Loss: 0.544059 \t\t Validation loss: 0.507705\n",
            "BEST SCORE: tensor(0.7539, device='cuda:0')\n",
            "Training average batch accuracy: 0.724875\n",
            "Validation average batch accuracy: 0.753857\n",
            "Epoch 86: Loss: 0.541610 \t\t Validation loss: 0.507679\n",
            "BEST SCORE: tensor(0.7579, device='cuda:0')\n",
            "Training average batch accuracy: 0.726188\n",
            "Validation average batch accuracy: 0.757910\n",
            "Epoch 87: Loss: 0.534405 \t\t Validation loss: 0.503337\n",
            "BEST SCORE: tensor(0.7592, device='cuda:0')\n",
            "Training average batch accuracy: 0.732375\n",
            "Validation average batch accuracy: 0.759180\n",
            "Epoch 88: Loss: 0.545894 \t\t Validation loss: 0.502005\n",
            "Training average batch accuracy: 0.724813\n",
            "Validation average batch accuracy: 0.758301\n",
            "Epoch 89: Loss: 0.539086 \t\t Validation loss: 0.500053\n",
            "Training average batch accuracy: 0.732750\n",
            "Validation average batch accuracy: 0.758105\n",
            "Epoch 90: Loss: 0.540429 \t\t Validation loss: 0.500277\n",
            "BEST SCORE: tensor(0.7595, device='cuda:0')\n",
            "Training average batch accuracy: 0.730063\n",
            "Validation average batch accuracy: 0.759521\n",
            "Epoch 91: Loss: 0.529297 \t\t Validation loss: 0.494034\n",
            "BEST SCORE: tensor(0.7617, device='cuda:0')\n",
            "Training average batch accuracy: 0.739188\n",
            "Validation average batch accuracy: 0.761719\n",
            "Epoch 92: Loss: 0.540183 \t\t Validation loss: 0.503595\n",
            "Training average batch accuracy: 0.733500\n",
            "Validation average batch accuracy: 0.757129\n",
            "Epoch 93: Loss: 0.531904 \t\t Validation loss: 0.505237\n",
            "Training average batch accuracy: 0.733938\n",
            "Validation average batch accuracy: 0.756201\n",
            "Epoch 94: Loss: 0.535260 \t\t Validation loss: 0.498264\n",
            "Training average batch accuracy: 0.731875\n",
            "Validation average batch accuracy: 0.758350\n",
            "Epoch 95: Loss: 0.536735 \t\t Validation loss: 0.495628\n",
            "BEST SCORE: tensor(0.7653, device='cuda:0')\n",
            "Training average batch accuracy: 0.728250\n",
            "Validation average batch accuracy: 0.765332\n",
            "Epoch 96: Loss: 0.529880 \t\t Validation loss: 0.496560\n",
            "Training average batch accuracy: 0.737938\n",
            "Validation average batch accuracy: 0.756543\n",
            "Epoch 97: Loss: 0.528942 \t\t Validation loss: 0.489100\n",
            "Training average batch accuracy: 0.736438\n",
            "Validation average batch accuracy: 0.764111\n",
            "Epoch 98: Loss: 0.526784 \t\t Validation loss: 0.491348\n",
            "Training average batch accuracy: 0.738938\n",
            "Validation average batch accuracy: 0.761328\n",
            "Epoch 99: Loss: 0.530827 \t\t Validation loss: 0.488041\n",
            "BEST SCORE: tensor(0.7690, device='cuda:0')\n",
            "Training average batch accuracy: 0.735500\n",
            "Validation average batch accuracy: 0.769043\n",
            "Epoch 100: Loss: 0.527894 \t\t Validation loss: 0.493847\n",
            "Training average batch accuracy: 0.736813\n",
            "Validation average batch accuracy: 0.758838\n",
            "Epoch 101: Loss: 0.522533 \t\t Validation loss: 0.484971\n",
            "Training average batch accuracy: 0.739063\n",
            "Validation average batch accuracy: 0.765381\n",
            "Epoch 102: Loss: 0.533453 \t\t Validation loss: 0.481171\n",
            "BEST SCORE: tensor(0.7699, device='cuda:0')\n",
            "Training average batch accuracy: 0.737000\n",
            "Validation average batch accuracy: 0.769922\n",
            "Epoch 103: Loss: 0.529413 \t\t Validation loss: 0.494001\n",
            "Training average batch accuracy: 0.738250\n",
            "Validation average batch accuracy: 0.759473\n",
            "Epoch 104: Loss: 0.526408 \t\t Validation loss: 0.487366\n",
            "Training average batch accuracy: 0.741313\n",
            "Validation average batch accuracy: 0.766553\n",
            "Epoch 105: Loss: 0.531588 \t\t Validation loss: 0.483348\n",
            "Training average batch accuracy: 0.739500\n",
            "Validation average batch accuracy: 0.769727\n",
            "Epoch 106: Loss: 0.524795 \t\t Validation loss: 0.484060\n",
            "Training average batch accuracy: 0.739375\n",
            "Validation average batch accuracy: 0.767334\n",
            "Epoch 107: Loss: 0.523856 \t\t Validation loss: 0.487505\n",
            "Training average batch accuracy: 0.740500\n",
            "Validation average batch accuracy: 0.767090\n",
            "Epoch 108: Loss: 0.522157 \t\t Validation loss: 0.488902\n",
            "Training average batch accuracy: 0.740438\n",
            "Validation average batch accuracy: 0.765967\n",
            "Epoch 109: Loss: 0.516290 \t\t Validation loss: 0.484705\n",
            "BEST SCORE: tensor(0.7721, device='cuda:0')\n",
            "Training average batch accuracy: 0.744750\n",
            "Validation average batch accuracy: 0.772070\n",
            "Epoch 110: Loss: 0.513573 \t\t Validation loss: 0.488041\n",
            "Training average batch accuracy: 0.749125\n",
            "Validation average batch accuracy: 0.763623\n",
            "Epoch 111: Loss: 0.522003 \t\t Validation loss: 0.485157\n",
            "Training average batch accuracy: 0.743250\n",
            "Validation average batch accuracy: 0.769434\n",
            "Epoch 112: Loss: 0.523992 \t\t Validation loss: 0.479352\n",
            "BEST SCORE: tensor(0.7723, device='cuda:0')\n",
            "Training average batch accuracy: 0.741250\n",
            "Validation average batch accuracy: 0.772266\n",
            "Epoch 113: Loss: 0.521823 \t\t Validation loss: 0.477091\n",
            "Training average batch accuracy: 0.744688\n",
            "Validation average batch accuracy: 0.770850\n",
            "Epoch 114: Loss: 0.518451 \t\t Validation loss: 0.479739\n",
            "BEST SCORE: tensor(0.7727, device='cuda:0')\n",
            "Training average batch accuracy: 0.746000\n",
            "Validation average batch accuracy: 0.772705\n",
            "Epoch 115: Loss: 0.516263 \t\t Validation loss: 0.481119\n",
            "Training average batch accuracy: 0.745125\n",
            "Validation average batch accuracy: 0.768994\n",
            "Epoch 116: Loss: 0.516810 \t\t Validation loss: 0.481653\n",
            "BEST SCORE: tensor(0.7740, device='cuda:0')\n",
            "Training average batch accuracy: 0.748313\n",
            "Validation average batch accuracy: 0.773975\n",
            "Epoch 117: Loss: 0.521287 \t\t Validation loss: 0.479060\n",
            "Training average batch accuracy: 0.738813\n",
            "Validation average batch accuracy: 0.771289\n",
            "Epoch 118: Loss: 0.516972 \t\t Validation loss: 0.485053\n",
            "Training average batch accuracy: 0.743000\n",
            "Validation average batch accuracy: 0.767432\n",
            "Epoch 119: Loss: 0.518745 \t\t Validation loss: 0.476465\n",
            "BEST SCORE: tensor(0.7745, device='cuda:0')\n",
            "Training average batch accuracy: 0.750875\n",
            "Validation average batch accuracy: 0.774512\n",
            "Epoch 120: Loss: 0.517530 \t\t Validation loss: 0.474607\n",
            "BEST SCORE: tensor(0.7807, device='cuda:0')\n",
            "Training average batch accuracy: 0.746000\n",
            "Validation average batch accuracy: 0.780664\n",
            "Epoch 121: Loss: 0.507627 \t\t Validation loss: 0.475618\n",
            "Training average batch accuracy: 0.752438\n",
            "Validation average batch accuracy: 0.772949\n",
            "Epoch 122: Loss: 0.515690 \t\t Validation loss: 0.481520\n",
            "Training average batch accuracy: 0.747875\n",
            "Validation average batch accuracy: 0.771045\n",
            "Epoch 123: Loss: 0.514983 \t\t Validation loss: 0.476319\n",
            "Training average batch accuracy: 0.742375\n",
            "Validation average batch accuracy: 0.771826\n",
            "Epoch 124: Loss: 0.514664 \t\t Validation loss: 0.473580\n",
            "Training average batch accuracy: 0.747063\n",
            "Validation average batch accuracy: 0.776074\n",
            "Epoch 125: Loss: 0.501287 \t\t Validation loss: 0.468986\n",
            "Training average batch accuracy: 0.757125\n",
            "Validation average batch accuracy: 0.778125\n",
            "Epoch 126: Loss: 0.507540 \t\t Validation loss: 0.470978\n",
            "Training average batch accuracy: 0.754188\n",
            "Validation average batch accuracy: 0.777734\n",
            "Epoch 127: Loss: 0.513442 \t\t Validation loss: 0.464569\n",
            "BEST SCORE: tensor(0.7832, device='cuda:0')\n",
            "Training average batch accuracy: 0.750375\n",
            "Validation average batch accuracy: 0.783203\n",
            "Epoch 128: Loss: 0.507901 \t\t Validation loss: 0.464829\n",
            "Training average batch accuracy: 0.754688\n",
            "Validation average batch accuracy: 0.782227\n",
            "Epoch 129: Loss: 0.513475 \t\t Validation loss: 0.472159\n",
            "Training average batch accuracy: 0.751313\n",
            "Validation average batch accuracy: 0.777393\n",
            "Epoch 130: Loss: 0.508938 \t\t Validation loss: 0.470059\n",
            "Training average batch accuracy: 0.755813\n",
            "Validation average batch accuracy: 0.782568\n",
            "Epoch 131: Loss: 0.504892 \t\t Validation loss: 0.462231\n",
            "Training average batch accuracy: 0.753125\n",
            "Validation average batch accuracy: 0.782813\n",
            "Epoch 132: Loss: 0.511511 \t\t Validation loss: 0.470024\n",
            "Training average batch accuracy: 0.750625\n",
            "Validation average batch accuracy: 0.776270\n",
            "Epoch 133: Loss: 0.505917 \t\t Validation loss: 0.462922\n",
            "BEST SCORE: tensor(0.7839, device='cuda:0')\n",
            "Training average batch accuracy: 0.756688\n",
            "Validation average batch accuracy: 0.783936\n",
            "Epoch 134: Loss: 0.498715 \t\t Validation loss: 0.465825\n",
            "Training average batch accuracy: 0.757063\n",
            "Validation average batch accuracy: 0.781055\n",
            "Epoch 135: Loss: 0.503727 \t\t Validation loss: 0.467592\n",
            "Training average batch accuracy: 0.753313\n",
            "Validation average batch accuracy: 0.777783\n",
            "Epoch 136: Loss: 0.502329 \t\t Validation loss: 0.461771\n",
            "Training average batch accuracy: 0.756375\n",
            "Validation average batch accuracy: 0.782471\n",
            "Epoch 137: Loss: 0.510135 \t\t Validation loss: 0.469490\n",
            "Training average batch accuracy: 0.753500\n",
            "Validation average batch accuracy: 0.778320\n",
            "Epoch 138: Loss: 0.507157 \t\t Validation loss: 0.463228\n",
            "Training average batch accuracy: 0.753375\n",
            "Validation average batch accuracy: 0.782080\n",
            "Epoch 139: Loss: 0.501324 \t\t Validation loss: 0.457488\n",
            "BEST SCORE: tensor(0.7856, device='cuda:0')\n",
            "Training average batch accuracy: 0.754188\n",
            "Validation average batch accuracy: 0.785645\n",
            "Epoch 140: Loss: 0.500523 \t\t Validation loss: 0.462081\n",
            "Training average batch accuracy: 0.761750\n",
            "Validation average batch accuracy: 0.782324\n",
            "Epoch 141: Loss: 0.503022 \t\t Validation loss: 0.461694\n",
            "Training average batch accuracy: 0.756500\n",
            "Validation average batch accuracy: 0.780273\n",
            "Epoch 142: Loss: 0.505988 \t\t Validation loss: 0.455824\n",
            "BEST SCORE: tensor(0.7893, device='cuda:0')\n",
            "Training average batch accuracy: 0.752875\n",
            "Validation average batch accuracy: 0.789258\n",
            "Epoch 143: Loss: 0.502578 \t\t Validation loss: 0.463630\n",
            "Training average batch accuracy: 0.755188\n",
            "Validation average batch accuracy: 0.783301\n",
            "Epoch 144: Loss: 0.505365 \t\t Validation loss: 0.452275\n",
            "Training average batch accuracy: 0.755938\n",
            "Validation average batch accuracy: 0.789111\n",
            "Epoch 145: Loss: 0.498935 \t\t Validation loss: 0.462530\n",
            "Training average batch accuracy: 0.756063\n",
            "Validation average batch accuracy: 0.783105\n",
            "Epoch 146: Loss: 0.499454 \t\t Validation loss: 0.454254\n",
            "Training average batch accuracy: 0.761750\n",
            "Validation average batch accuracy: 0.786914\n",
            "Epoch 147: Loss: 0.503141 \t\t Validation loss: 0.456995\n",
            "Training average batch accuracy: 0.761250\n",
            "Validation average batch accuracy: 0.787012\n",
            "Epoch 148: Loss: 0.497554 \t\t Validation loss: 0.456411\n",
            "Training average batch accuracy: 0.759875\n",
            "Validation average batch accuracy: 0.785303\n",
            "Epoch 149: Loss: 0.498640 \t\t Validation loss: 0.460668\n",
            "Training average batch accuracy: 0.759438\n",
            "Validation average batch accuracy: 0.783203\n",
            "Epoch 150: Loss: 0.494979 \t\t Validation loss: 0.455024\n",
            "Training average batch accuracy: 0.765750\n",
            "Validation average batch accuracy: 0.787354\n",
            "Epoch 151: Loss: 0.496704 \t\t Validation loss: 0.448459\n",
            "BEST SCORE: tensor(0.7927, device='cuda:0')\n",
            "Training average batch accuracy: 0.759000\n",
            "Validation average batch accuracy: 0.792676\n",
            "Epoch 152: Loss: 0.503018 \t\t Validation loss: 0.454092\n",
            "Training average batch accuracy: 0.756750\n",
            "Validation average batch accuracy: 0.787988\n",
            "Epoch 153: Loss: 0.493848 \t\t Validation loss: 0.452154\n",
            "Training average batch accuracy: 0.764438\n",
            "Validation average batch accuracy: 0.787158\n",
            "Epoch 154: Loss: 0.493050 \t\t Validation loss: 0.451379\n",
            "Training average batch accuracy: 0.764188\n",
            "Validation average batch accuracy: 0.786768\n",
            "Epoch 155: Loss: 0.494349 \t\t Validation loss: 0.453152\n",
            "Training average batch accuracy: 0.762875\n",
            "Validation average batch accuracy: 0.787939\n",
            "Epoch 156: Loss: 0.494936 \t\t Validation loss: 0.452875\n",
            "Training average batch accuracy: 0.761813\n",
            "Validation average batch accuracy: 0.787695\n",
            "Epoch 157: Loss: 0.492225 \t\t Validation loss: 0.454137\n",
            "Training average batch accuracy: 0.765125\n",
            "Validation average batch accuracy: 0.789404\n",
            "Epoch 158: Loss: 0.493424 \t\t Validation loss: 0.450325\n",
            "Training average batch accuracy: 0.761438\n",
            "Validation average batch accuracy: 0.790381\n",
            "Epoch 159: Loss: 0.492355 \t\t Validation loss: 0.447132\n",
            "BEST SCORE: tensor(0.7944, device='cuda:0')\n",
            "Training average batch accuracy: 0.763875\n",
            "Validation average batch accuracy: 0.794385\n",
            "Epoch 160: Loss: 0.490552 \t\t Validation loss: 0.444974\n",
            "BEST SCORE: tensor(0.7968, device='cuda:0')\n",
            "Training average batch accuracy: 0.767063\n",
            "Validation average batch accuracy: 0.796826\n",
            "Epoch 161: Loss: 0.486949 \t\t Validation loss: 0.447398\n",
            "Training average batch accuracy: 0.770438\n",
            "Validation average batch accuracy: 0.790918\n",
            "Epoch 162: Loss: 0.492125 \t\t Validation loss: 0.448372\n",
            "Training average batch accuracy: 0.762938\n",
            "Validation average batch accuracy: 0.791895\n",
            "Epoch 163: Loss: 0.492174 \t\t Validation loss: 0.448637\n",
            "Training average batch accuracy: 0.763438\n",
            "Validation average batch accuracy: 0.795996\n",
            "Epoch 164: Loss: 0.497737 \t\t Validation loss: 0.448579\n",
            "Training average batch accuracy: 0.757563\n",
            "Validation average batch accuracy: 0.793408\n",
            "Epoch 165: Loss: 0.484858 \t\t Validation loss: 0.446325\n",
            "Training average batch accuracy: 0.773000\n",
            "Validation average batch accuracy: 0.791748\n",
            "Epoch 166: Loss: 0.490461 \t\t Validation loss: 0.439987\n",
            "Training average batch accuracy: 0.765375\n",
            "Validation average batch accuracy: 0.795801\n",
            "Epoch 167: Loss: 0.481965 \t\t Validation loss: 0.454753\n",
            "Training average batch accuracy: 0.770625\n",
            "Validation average batch accuracy: 0.788086\n",
            "Epoch 168: Loss: 0.493038 \t\t Validation loss: 0.448644\n",
            "Training average batch accuracy: 0.762875\n",
            "Validation average batch accuracy: 0.793359\n",
            "Epoch 169: Loss: 0.482219 \t\t Validation loss: 0.443088\n",
            "Training average batch accuracy: 0.771125\n",
            "Validation average batch accuracy: 0.795068\n",
            "Epoch 170: Loss: 0.489499 \t\t Validation loss: 0.442884\n",
            "Training average batch accuracy: 0.765813\n",
            "Validation average batch accuracy: 0.790820\n",
            "Epoch 171: Loss: 0.480196 \t\t Validation loss: 0.440659\n",
            "BEST SCORE: tensor(0.7976, device='cuda:0')\n",
            "Training average batch accuracy: 0.775188\n",
            "Validation average batch accuracy: 0.797559\n",
            "Epoch 172: Loss: 0.485015 \t\t Validation loss: 0.447389\n",
            "Training average batch accuracy: 0.768813\n",
            "Validation average batch accuracy: 0.788086\n",
            "Epoch 173: Loss: 0.481885 \t\t Validation loss: 0.437810\n",
            "Training average batch accuracy: 0.769563\n",
            "Validation average batch accuracy: 0.797119\n",
            "Epoch 174: Loss: 0.484066 \t\t Validation loss: 0.434265\n",
            "BEST SCORE: tensor(0.7990, device='cuda:0')\n",
            "Training average batch accuracy: 0.769938\n",
            "Validation average batch accuracy: 0.799023\n",
            "Epoch 175: Loss: 0.482967 \t\t Validation loss: 0.442701\n",
            "Training average batch accuracy: 0.770188\n",
            "Validation average batch accuracy: 0.793604\n",
            "Epoch 176: Loss: 0.494375 \t\t Validation loss: 0.437783\n",
            "Training average batch accuracy: 0.759313\n",
            "Validation average batch accuracy: 0.798633\n",
            "Epoch 177: Loss: 0.478047 \t\t Validation loss: 0.437013\n",
            "BEST SCORE: tensor(0.7993, device='cuda:0')\n",
            "Training average batch accuracy: 0.773000\n",
            "Validation average batch accuracy: 0.799316\n",
            "Epoch 178: Loss: 0.484761 \t\t Validation loss: 0.441426\n",
            "Training average batch accuracy: 0.765500\n",
            "Validation average batch accuracy: 0.795166\n",
            "Epoch 179: Loss: 0.475665 \t\t Validation loss: 0.444707\n",
            "Training average batch accuracy: 0.774875\n",
            "Validation average batch accuracy: 0.793506\n",
            "Epoch 180: Loss: 0.485576 \t\t Validation loss: 0.439429\n",
            "Training average batch accuracy: 0.766938\n",
            "Validation average batch accuracy: 0.797852\n",
            "Epoch 181: Loss: 0.472453 \t\t Validation loss: 0.439981\n",
            "Training average batch accuracy: 0.777813\n",
            "Validation average batch accuracy: 0.796924\n",
            "Epoch 182: Loss: 0.475928 \t\t Validation loss: 0.436603\n",
            "BEST SCORE: tensor(0.8005, device='cuda:0')\n",
            "Training average batch accuracy: 0.776250\n",
            "Validation average batch accuracy: 0.800488\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-47dddbec3431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mbest_model_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0mhist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m       scheduler=scheduler)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-d2dc031d4389>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data_loader, valid_data_loader, model, optimizer, train_step, eval_step, epochs, best_model, best_model_mode, hist, scheduler)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mmean_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mvalid_mean_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_batch_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch}: Loss: {mean_loss:0.6f} \\t\\t Validation loss: {valid_mean_loss:0.6f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-47dddbec3431>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(data_loader, model, eval_step)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-47dddbec3431>\u001b[0m in \u001b[0;36mcontext_eval_step_2\u001b[0;34m(model, batch)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcontext_eval_step_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0munk_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-72f8ba004434>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_pos_tags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-72f8ba004434>\u001b[0m in \u001b[0;36mpos_tag_forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munk_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munk_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;31m#raise 'No pos tagging yet!!! Gotcha ;)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-72f8ba004434>\u001b[0m in \u001b[0;36mmain_forward\u001b[0;34m(self, tokens, unk_position, token_id, target, tags)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mseq_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags_embeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mrnn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_embeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mrnn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mlast_rnn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 662\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    663\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1tIyVwLYd3N",
        "outputId": "39f82a03-e2b8-434e-be69-ebe60445a73a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMS1CCPrDOlT"
      },
      "source": [
        "torch.save({\n",
        "            'epoch': 300,\n",
        "            'model_state_dict': best_model['state_dict'],\n",
        "            'optimizer_state_dict': optim_context.state_dict()\n",
        "}, \"/content/drive/MyDrive/Sapienza/model_context_GloVE300_nltk_pos_multi_learn.pth\" )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3zZ5i3QZv5b"
      },
      "source": [
        "# WiC Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sEo35J4mGTS"
      },
      "source": [
        "## Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "bff849e78798425580e8bf36ea327b8d",
            "9770691e8d1b4e2ba4f91ed683fae855",
            "5d228d49cc5746ff888b885618a85ba8",
            "4065f4fed41c4918b2a28d059c6690a7",
            "2e3ae5a61f4441ba877c877739127f54",
            "6baf876ea25043f7a35afb16be7c5a87",
            "28465b399309486ca1749ce720091839",
            "fce98e861fe04e78b5635fecd8189dab",
            "05be0ea1e11f44d3afe78c625c129f7d",
            "e0794d4f720142af99132cd66a0e71ed",
            "7b17a6e27ce649aabf3c31450f99b50b",
            "910f133f46ca4025ba41904fa5ab37b2",
            "b79cf63f788a4753b2ebde93aab6a79b",
            "240a97063f3544508c56ed0121610e9a",
            "7f71032ccb184eb394a443e8ea6e39a4",
            "6dd0c0e81f724caaa8e9cb796f4fe803"
          ]
        },
        "id": "0lXYzMx3QTCE",
        "outputId": "dec5e7a2-8a29-43b0-f5ff-cb528f6a85ea"
      },
      "source": [
        "seed = 1\n",
        "set_seed(seed)\n",
        "\n",
        "class PadCollatorAndLemma(DeviceObject):\n",
        "    '''\n",
        "    Everything like in case of CE but for two sentences\n",
        "    '''\n",
        "    def __init__(self, pad_token_id, include_pos_tags=False, pad_tag_id=None):\n",
        "        self.pad_token_id = pad_token_id\n",
        "        self.pad_tag_id = pad_tag_id\n",
        "        self.include_pos_tags = include_pos_tags\n",
        "    \n",
        "    def __call__(self, batch):\n",
        "        sen_tokens = []\n",
        "        where_lemma = []\n",
        "        tags = []\n",
        "        \n",
        "        for k in [0, 1]:\n",
        "            key = str(k + 1)\n",
        "            sen_tokens.append([b['tokens' + key] for b in batch])\n",
        "            \n",
        "            sen_tokens[-1] = torch.nn.utils.rnn.pad_sequence(sen_tokens[-1], batch_first=True, padding_value=self.pad_token_id)\n",
        "            shape = sen_tokens[-1].shape\n",
        "\n",
        "            where_lemma.append(torch.tensor([b['where_lemma' + key] for b in batch]).unsqueeze(1))\n",
        "            where_lemma[-1] = torch.zeros(shape[0], shape[1], dtype=torch.int).scatter(1, where_lemma[-1], 1)\n",
        "            sen_tokens[-1].to('cuda')\n",
        "\n",
        "            if self.include_pos_tags:\n",
        "                tags.append([torch.tensor(b['tags' + key]) for b in batch]) \n",
        "                tags[-1] = torch.nn.utils.rnn.pad_sequence(tags[-1], batch_first=True, padding_value=self.pad_tag_id).to(self.device)\n",
        "\n",
        "        label = torch.tensor([b['label'] for b in batch]).to(self.device)\n",
        "        pos = torch.tensor([b['pos'] for b in batch]).to(self.device)\n",
        "\n",
        "        return where_lemma, sen_tokens, pos, tags, label\n",
        "    \n",
        "\n",
        "include_pos_tags=False # Flags for model with extra data - nlts POS tags\n",
        "train_dataset = WiCDataset('data/train.jsonl', vectors, \n",
        "                           rand_replace=0.1,\n",
        "                           swap_tokens=0.3,\n",
        "                           wrong_label_prob=0,\n",
        "                           with_pos_tags=include_pos_tags, \n",
        "                           #rand_replace_mode='unk_tokens',\n",
        "                           #lemmatization=True,\n",
        "                           remove_stop_words=not include_pos_tags, \n",
        "                           swap_sequences=False, max_length=None)\n",
        "valid_dataset = WiCDataset('data/dev.jsonl', vectors, \n",
        "                           #lemmatization=True,\n",
        "                           with_pos_tags=include_pos_tags,\n",
        "                           remove_stop_words=not include_pos_tags\n",
        "                           )\n",
        "\n",
        "collate_obj = PadCollatorAndLemma(vectors.get_id('<pad>'), include_pos_tags=include_pos_tags, pad_tag_id=WiCDataset.num_pos_classes)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, collate_fn=collate_obj)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, collate_fn=collate_obj)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bff849e78798425580e8bf36ea327b8d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05be0ea1e11f44d3afe78c625c129f7d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAARYmWBmMES"
      },
      "source": [
        "## WiC Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GonKVcKs3UDb"
      },
      "source": [
        "set_seed(seed)\n",
        "class HypParams:\n",
        "    dropout = 0.95\n",
        "    pos_classes = 4\n",
        "    #pos_embed_dim = 30\n",
        "    pos_embed_dim = 0\n",
        "\n",
        "class WiCClassifier(nn.Module, DeviceObject):\n",
        "    '''\n",
        "    Classifier takes separately each sentence and feed it to Context Encoder \n",
        "    which returns contextual representation of lemma in sentence. Then, we classsify it using MLP\n",
        "    '''\n",
        "\n",
        "    def __init__(self, params, vocab, context_model, \n",
        "                 mask_tokens=False, # An option to mask token like in Context Encoder\n",
        "                 predict_pos=False, \n",
        "                 with_nltk_tags=False):\n",
        "        super().__init__()\n",
        "        self.vocab = vocab\n",
        "        self.context_model = context_model\n",
        "        self.predict_pos = predict_pos\n",
        "        self.params = params\n",
        "        self.mask_tokens = mask_tokens\n",
        "\n",
        "        embeddings = vocab.vectors\n",
        "        input_size = embeddings[0].shape[0]\n",
        "        \n",
        "        self.word_embeddings = nn.Embedding.from_pretrained(embeddings)\n",
        "        self.context_model.eval()\n",
        "\n",
        "        if params.pos_embed_dim > 0:\n",
        "            self.pos_embeddings = nn.Embedding(params.pos_classes, params.pos_embed_dim)\n",
        "\n",
        "        # Main MLP classifer\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(input_size * 4 * 2 \n",
        "                      + (params.pos_embed_dim if not predict_pos else 0)\n",
        "                      , input_size * 4),\n",
        "            nn.BatchNorm1d(input_size * 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(params.dropout),\n",
        "\n",
        "            nn.Linear(input_size * 4, 1)\n",
        "        )\n",
        "        # This is classifier for multi-tasking \n",
        "        self.pos_classifier = nn.Sequential(\n",
        "            nn.Linear(input_size * 4, params.pos_classes)\n",
        "        )\n",
        "        # Extra loss for POS classification used in multi-task mode\n",
        "        self.pos_loss = nn.CrossEntropyLoss()\n",
        "        \n",
        "        self.loss = nn.BCELoss()\n",
        "\n",
        "    def forward(self, where_lemma, tokens, pos, nltk_pos_tags, y=None): # nltk_pos_tags is empty if it is not indicted in collate object\n",
        "        contexts = []\n",
        "        rnn_averages = []\n",
        "        ave_pos_loss = 0\n",
        "\n",
        "        for i in range(2):\n",
        "            main_token_embedding = self.word_embeddings(tokens[i][where_lemma[i] == 1])\n",
        "            seq_embeds = self.word_embeddings(tokens[i])\n",
        "\n",
        "            if self.mask_tokens:\n",
        "                tokens[i][where_lemma[i] == 1] = self.vocab.get_id('<masked>')\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                args = [tokens[i], where_lemma[i]]\n",
        "                if nltk_pos_tags != []:\n",
        "                    args.append(nltk_pos_tags[i])\n",
        "\n",
        "                # Taking context from CE \n",
        "                (context, _), _, context_loss = self.context_model(*args) \n",
        "                                                              \n",
        "            contexts.append(context)\n",
        "\n",
        "        ave_pos_loss = 0\n",
        "        if self.predict_pos:\n",
        "            ### Multi-task part\n",
        "            to_classify = torch.cat(contexts, dim=1)\n",
        "            # POS classification\n",
        "            pos_class = self.pos_classifier(self.classifier[:-1](to_classify))\n",
        "            ave_pos_loss = self.pos_loss(pos_class, pos)\n",
        "        else:\n",
        "            ### Part with concatenation of POS embeddings that are trainable\n",
        "            pos_embeds = [self.pos_embeddings(pos)] if self.params.pos_embed_dim > 0 else []\n",
        "            # Taking trainable embeddings for POS tags and concatente them with context\n",
        "            to_classify = torch.cat(contexts + pos_embeds, dim=1)\n",
        "        \n",
        "        out = torch.sigmoid(self.classifier(to_classify)).squeeze()\n",
        "\n",
        "        loss = self.loss(out, y) + ave_pos_loss if y is not None else None\n",
        "        return out, loss\n",
        "\n",
        "\n",
        "def train_step_3(model, batch):\n",
        "    preds, loss = model(*list(batch)[:-1], batch[-1])\n",
        "    return {'loss': loss, 'batch_accuracy': binary_accuracy(preds, batch[-1])}\n",
        "\n",
        "def eval_step_3(model, batch):\n",
        "    preds, loss = model(*list(batch)[:-1], batch[-1])\n",
        "    return loss, binary_accuracy(preds, batch[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy1_CASjasH6"
      },
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, eval_step):\n",
        "    model.eval()\n",
        "    results = []\n",
        "    losses = []\n",
        "    \n",
        "    for i, batch in enumerate(data_loader):\n",
        "        loss, metric = eval_step(model, batch)\n",
        "        losses.append(loss.item())\n",
        "        results.append(metric)\n",
        "\n",
        "    return sum(losses) / len(losses), sum(results) / len(results)\n",
        "\n",
        "\n",
        "model_wic = WiCClassifier(HypParams(), vectors, model_context, \n",
        "                            predict_pos=False # multi-learning flag\n",
        "                          ).to('cuda')\n",
        "\n",
        "optim_wic = torch.optim.Adam(model_wic.parameters())\n",
        "\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim_wic, factor=0.5, verbose=True)\n",
        "\n",
        "#scheduler=None\n",
        "best_model = {}\n",
        "hist = {}\n",
        "\n",
        "_ = train(train_loader, valid_loader, \n",
        "      model_wic, optim_wic, \n",
        "      train_step_3, \n",
        "      eval_step_3,\n",
        "      260,\n",
        "      scheduler=scheduler, \n",
        "      best_model_mode='accuracy', \n",
        "      best_model=best_model, hist=hist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGgafwDbYCti"
      },
      "source": [
        "torch.save({\n",
        "            'epoch': 178,\n",
        "            'model_state_dict': best_model['state_dict'],\n",
        "            'optimizer_state_dict': optim_wic.state_dict()\n",
        "}, \"/content/drive/MyDrive/Sapienza/WiC_NEW_no_pos_2.pth\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLE7dOhgoFbz"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlMkkKitiEW9"
      },
      "source": [
        "# Saved Cells with training procedures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WugWlR2h5-Sg"
      },
      "source": [
        "## Context Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TBFgqDrQTGc"
      },
      "source": [
        "### Main model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM-iUVVWQUoF",
        "outputId": "264c6cd7-e3a1-45f5-c735-41c12d47b3c0"
      },
      "source": [
        "def context_train_step_2(model, batch):\n",
        "    (unk_context, rnn_context), preds, loss = model(*list(batch))\n",
        "    return {'loss': loss, 'batch_accuracy': binary_accuracy(preds, batch[-1])}\n",
        "\n",
        "def context_eval_step_2(model, batch):\n",
        "    (unk_context, rnn_context), preds, loss = model(*list(batch))\n",
        "    return loss, binary_accuracy(preds, batch[-1])\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, eval_step):\n",
        "    model.eval()\n",
        "    results = []\n",
        "    losses = []\n",
        "    \n",
        "    for k in range(10):\n",
        "        for i, batch in enumerate(data_loader):\n",
        "            loss, metric = eval_step(model, batch)\n",
        "            losses.append(loss.item())\n",
        "            results.append(metric)\n",
        "\n",
        "    return sum(losses) / len(losses), sum(results) / len(results)\n",
        "\n",
        "\n",
        "\n",
        "model_context = ContextEncoder(ContextParams(), vectors, \n",
        "                               train_dataset_context.get_used_tokens(True), \n",
        "                               binary_mode=True,\n",
        "                               #cosine_mode=True,\n",
        "                               with_pos_tags=False,\n",
        "                               ).to('cuda')\n",
        "optim_context = torch.optim.Adam(model_context.parameters(), lr=0.0001)\n",
        "\n",
        "\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(optim_context, 5000, 0.5)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim_context, factor=0.9, verbose=True)\n",
        "\n",
        "\n",
        "#scheduler=None\n",
        "best_model = {}\n",
        "\n",
        "best_state_dict, _ = train(train_loader_context, valid_loader_context, \n",
        "      model_context, optim_context, \n",
        "      context_train_step_2, \n",
        "      context_eval_step_2,\n",
        "      300, best_model, \n",
        "      best_model_mode='accuracy', \n",
        "      scheduler=scheduler)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss: 0.746419 \t\t Validation loss: 0.706265\n",
            "BEST SCORE: tensor(0.5493, device='cuda:0')\n",
            "Training average batch accuracy: 0.507688\n",
            "Validation average batch accuracy: 0.549316\n",
            "Epoch 1: Loss: 0.699652 \t\t Validation loss: 0.669616\n",
            "BEST SCORE: tensor(0.5817, device='cuda:0')\n",
            "Training average batch accuracy: 0.565375\n",
            "Validation average batch accuracy: 0.581689\n",
            "Epoch 2: Loss: 0.684071 \t\t Validation loss: 0.668921\n",
            "BEST SCORE: tensor(0.5958, device='cuda:0')\n",
            "Training average batch accuracy: 0.585313\n",
            "Validation average batch accuracy: 0.595850\n",
            "Epoch 3: Loss: 0.668838 \t\t Validation loss: 0.633007\n",
            "BEST SCORE: tensor(0.6344, device='cuda:0')\n",
            "Training average batch accuracy: 0.598250\n",
            "Validation average batch accuracy: 0.634424\n",
            "Epoch 4: Loss: 0.645157 \t\t Validation loss: 0.621927\n",
            "BEST SCORE: tensor(0.6480, device='cuda:0')\n",
            "Training average batch accuracy: 0.628688\n",
            "Validation average batch accuracy: 0.647998\n",
            "Epoch 5: Loss: 0.637111 \t\t Validation loss: 0.632501\n",
            "Training average batch accuracy: 0.633500\n",
            "Validation average batch accuracy: 0.639160\n",
            "Epoch 6: Loss: 0.639318 \t\t Validation loss: 0.619121\n",
            "BEST SCORE: tensor(0.6541, device='cuda:0')\n",
            "Training average batch accuracy: 0.632563\n",
            "Validation average batch accuracy: 0.654053\n",
            "Epoch 7: Loss: 0.629343 \t\t Validation loss: 0.612613\n",
            "BEST SCORE: tensor(0.6583, device='cuda:0')\n",
            "Training average batch accuracy: 0.643250\n",
            "Validation average batch accuracy: 0.658301\n",
            "Epoch 8: Loss: 0.622247 \t\t Validation loss: 0.609991\n",
            "BEST SCORE: tensor(0.6643, device='cuda:0')\n",
            "Training average batch accuracy: 0.649125\n",
            "Validation average batch accuracy: 0.664258\n",
            "Epoch 9: Loss: 0.619677 \t\t Validation loss: 0.616950\n",
            "Training average batch accuracy: 0.650688\n",
            "Validation average batch accuracy: 0.654980\n",
            "Epoch 10: Loss: 0.626258 \t\t Validation loss: 0.610340\n",
            "Training average batch accuracy: 0.642750\n",
            "Validation average batch accuracy: 0.659277\n",
            "Epoch 11: Loss: 0.612346 \t\t Validation loss: 0.606046\n",
            "BEST SCORE: tensor(0.6652, device='cuda:0')\n",
            "Training average batch accuracy: 0.658938\n",
            "Validation average batch accuracy: 0.665186\n",
            "Epoch 12: Loss: 0.611186 \t\t Validation loss: 0.599414\n",
            "BEST SCORE: tensor(0.6704, device='cuda:0')\n",
            "Training average batch accuracy: 0.659375\n",
            "Validation average batch accuracy: 0.670410\n",
            "Epoch 13: Loss: 0.614118 \t\t Validation loss: 0.596800\n",
            "BEST SCORE: tensor(0.6804, device='cuda:0')\n",
            "Training average batch accuracy: 0.654688\n",
            "Validation average batch accuracy: 0.680371\n",
            "Epoch 14: Loss: 0.605834 \t\t Validation loss: 0.595825\n",
            "Training average batch accuracy: 0.667438\n",
            "Validation average batch accuracy: 0.675244\n",
            "Epoch 15: Loss: 0.607973 \t\t Validation loss: 0.600453\n",
            "Training average batch accuracy: 0.666313\n",
            "Validation average batch accuracy: 0.667578\n",
            "Epoch 16: Loss: 0.599752 \t\t Validation loss: 0.595678\n",
            "Training average batch accuracy: 0.672500\n",
            "Validation average batch accuracy: 0.679102\n",
            "Epoch 17: Loss: 0.603086 \t\t Validation loss: 0.593633\n",
            "Training average batch accuracy: 0.664500\n",
            "Validation average batch accuracy: 0.678369\n",
            "Epoch 18: Loss: 0.597074 \t\t Validation loss: 0.593164\n",
            "Training average batch accuracy: 0.681500\n",
            "Validation average batch accuracy: 0.677100\n",
            "Epoch 19: Loss: 0.599070 \t\t Validation loss: 0.587951\n",
            "BEST SCORE: tensor(0.6842, device='cuda:0')\n",
            "Training average batch accuracy: 0.672688\n",
            "Validation average batch accuracy: 0.684229\n",
            "Epoch 20: Loss: 0.594657 \t\t Validation loss: 0.582656\n",
            "BEST SCORE: tensor(0.6897, device='cuda:0')\n",
            "Training average batch accuracy: 0.677500\n",
            "Validation average batch accuracy: 0.689746\n",
            "Epoch 21: Loss: 0.594325 \t\t Validation loss: 0.588728\n",
            "Training average batch accuracy: 0.677375\n",
            "Validation average batch accuracy: 0.681494\n",
            "Epoch 22: Loss: 0.593908 \t\t Validation loss: 0.586197\n",
            "Training average batch accuracy: 0.679938\n",
            "Validation average batch accuracy: 0.686084\n",
            "Epoch 23: Loss: 0.593847 \t\t Validation loss: 0.573576\n",
            "BEST SCORE: tensor(0.6956, device='cuda:0')\n",
            "Training average batch accuracy: 0.675813\n",
            "Validation average batch accuracy: 0.695605\n",
            "Epoch 24: Loss: 0.584443 \t\t Validation loss: 0.577175\n",
            "Training average batch accuracy: 0.685500\n",
            "Validation average batch accuracy: 0.694141\n",
            "Epoch 25: Loss: 0.582604 \t\t Validation loss: 0.572294\n",
            "BEST SCORE: tensor(0.6968, device='cuda:0')\n",
            "Training average batch accuracy: 0.687500\n",
            "Validation average batch accuracy: 0.696826\n",
            "Epoch 26: Loss: 0.593284 \t\t Validation loss: 0.575217\n",
            "Training average batch accuracy: 0.678688\n",
            "Validation average batch accuracy: 0.694287\n",
            "Epoch 27: Loss: 0.589275 \t\t Validation loss: 0.581816\n",
            "Training average batch accuracy: 0.684813\n",
            "Validation average batch accuracy: 0.693408\n",
            "Epoch 28: Loss: 0.580224 \t\t Validation loss: 0.570762\n",
            "BEST SCORE: tensor(0.6982, device='cuda:0')\n",
            "Training average batch accuracy: 0.690563\n",
            "Validation average batch accuracy: 0.698193\n",
            "Epoch 29: Loss: 0.588703 \t\t Validation loss: 0.566691\n",
            "BEST SCORE: tensor(0.7003, device='cuda:0')\n",
            "Training average batch accuracy: 0.685813\n",
            "Validation average batch accuracy: 0.700293\n",
            "Epoch 30: Loss: 0.582536 \t\t Validation loss: 0.571575\n",
            "Training average batch accuracy: 0.693500\n",
            "Validation average batch accuracy: 0.698291\n",
            "Epoch 31: Loss: 0.577225 \t\t Validation loss: 0.568405\n",
            "BEST SCORE: tensor(0.7018, device='cuda:0')\n",
            "Training average batch accuracy: 0.691375\n",
            "Validation average batch accuracy: 0.701807\n",
            "Epoch 32: Loss: 0.582216 \t\t Validation loss: 0.565242\n",
            "BEST SCORE: tensor(0.7050, device='cuda:0')\n",
            "Training average batch accuracy: 0.691375\n",
            "Validation average batch accuracy: 0.705029\n",
            "Epoch 33: Loss: 0.580806 \t\t Validation loss: 0.563621\n",
            "Training average batch accuracy: 0.692125\n",
            "Validation average batch accuracy: 0.701709\n",
            "Epoch 34: Loss: 0.572678 \t\t Validation loss: 0.565649\n",
            "Training average batch accuracy: 0.698813\n",
            "Validation average batch accuracy: 0.701709\n",
            "Epoch 35: Loss: 0.576205 \t\t Validation loss: 0.562222\n",
            "Training average batch accuracy: 0.698750\n",
            "Validation average batch accuracy: 0.704395\n",
            "Epoch 36: Loss: 0.572970 \t\t Validation loss: 0.557652\n",
            "BEST SCORE: tensor(0.7054, device='cuda:0')\n",
            "Training average batch accuracy: 0.695938\n",
            "Validation average batch accuracy: 0.705420\n",
            "Epoch 37: Loss: 0.571662 \t\t Validation loss: 0.558829\n",
            "Training average batch accuracy: 0.701563\n",
            "Validation average batch accuracy: 0.704980\n",
            "Epoch 38: Loss: 0.575047 \t\t Validation loss: 0.562059\n",
            "Training average batch accuracy: 0.697188\n",
            "Validation average batch accuracy: 0.703760\n",
            "Epoch 39: Loss: 0.565689 \t\t Validation loss: 0.558006\n",
            "BEST SCORE: tensor(0.7108, device='cuda:0')\n",
            "Training average batch accuracy: 0.704938\n",
            "Validation average batch accuracy: 0.710840\n",
            "Epoch 40: Loss: 0.564198 \t\t Validation loss: 0.551524\n",
            "BEST SCORE: tensor(0.7147, device='cuda:0')\n",
            "Training average batch accuracy: 0.701375\n",
            "Validation average batch accuracy: 0.714697\n",
            "Epoch 41: Loss: 0.563218 \t\t Validation loss: 0.558344\n",
            "Training average batch accuracy: 0.709438\n",
            "Validation average batch accuracy: 0.707471\n",
            "Epoch 42: Loss: 0.566386 \t\t Validation loss: 0.554788\n",
            "BEST SCORE: tensor(0.7149, device='cuda:0')\n",
            "Training average batch accuracy: 0.703188\n",
            "Validation average batch accuracy: 0.714941\n",
            "Epoch 43: Loss: 0.567621 \t\t Validation loss: 0.565332\n",
            "Training average batch accuracy: 0.701375\n",
            "Validation average batch accuracy: 0.705615\n",
            "Epoch 44: Loss: 0.567764 \t\t Validation loss: 0.548985\n",
            "BEST SCORE: tensor(0.7171, device='cuda:0')\n",
            "Training average batch accuracy: 0.705188\n",
            "Validation average batch accuracy: 0.717090\n",
            "Epoch 45: Loss: 0.565264 \t\t Validation loss: 0.552656\n",
            "Training average batch accuracy: 0.705750\n",
            "Validation average batch accuracy: 0.713965\n",
            "Epoch 46: Loss: 0.562792 \t\t Validation loss: 0.560918\n",
            "Training average batch accuracy: 0.706750\n",
            "Validation average batch accuracy: 0.704199\n",
            "Epoch 47: Loss: 0.563347 \t\t Validation loss: 0.552912\n",
            "Training average batch accuracy: 0.705063\n",
            "Validation average batch accuracy: 0.713525\n",
            "Epoch 48: Loss: 0.567606 \t\t Validation loss: 0.551277\n",
            "Training average batch accuracy: 0.703500\n",
            "Validation average batch accuracy: 0.713867\n",
            "Epoch 49: Loss: 0.562582 \t\t Validation loss: 0.557345\n",
            "Training average batch accuracy: 0.710000\n",
            "Validation average batch accuracy: 0.709717\n",
            "Epoch 50: Loss: 0.557928 \t\t Validation loss: 0.560011\n",
            "Training average batch accuracy: 0.711750\n",
            "Validation average batch accuracy: 0.707227\n",
            "Epoch 51: Loss: 0.564402 \t\t Validation loss: 0.556892\n",
            "Training average batch accuracy: 0.705000\n",
            "Validation average batch accuracy: 0.707227\n",
            "Epoch 52: Loss: 0.560935 \t\t Validation loss: 0.556750\n",
            "Training average batch accuracy: 0.705438\n",
            "Validation average batch accuracy: 0.708936\n",
            "Epoch 53: Loss: 0.563335 \t\t Validation loss: 0.548415\n",
            "Training average batch accuracy: 0.704563\n",
            "Validation average batch accuracy: 0.715039\n",
            "Epoch 54: Loss: 0.570157 \t\t Validation loss: 0.544221\n",
            "BEST SCORE: tensor(0.7199, device='cuda:0')\n",
            "Training average batch accuracy: 0.702125\n",
            "Validation average batch accuracy: 0.719873\n",
            "Epoch 55: Loss: 0.555526 \t\t Validation loss: 0.559024\n",
            "Training average batch accuracy: 0.714500\n",
            "Validation average batch accuracy: 0.710791\n",
            "Epoch 56: Loss: 0.555675 \t\t Validation loss: 0.550489\n",
            "Training average batch accuracy: 0.713375\n",
            "Validation average batch accuracy: 0.716113\n",
            "Epoch 57: Loss: 0.562345 \t\t Validation loss: 0.551576\n",
            "Training average batch accuracy: 0.704813\n",
            "Validation average batch accuracy: 0.714404\n",
            "Epoch 58: Loss: 0.549019 \t\t Validation loss: 0.542957\n",
            "BEST SCORE: tensor(0.7204, device='cuda:0')\n",
            "Training average batch accuracy: 0.717125\n",
            "Validation average batch accuracy: 0.720361\n",
            "Epoch 59: Loss: 0.554053 \t\t Validation loss: 0.549501\n",
            "Training average batch accuracy: 0.713063\n",
            "Validation average batch accuracy: 0.714746\n",
            "Epoch 60: Loss: 0.557896 \t\t Validation loss: 0.541796\n",
            "BEST SCORE: tensor(0.7253, device='cuda:0')\n",
            "Training average batch accuracy: 0.714938\n",
            "Validation average batch accuracy: 0.725342\n",
            "Epoch 61: Loss: 0.565930 \t\t Validation loss: 0.544661\n",
            "Training average batch accuracy: 0.706063\n",
            "Validation average batch accuracy: 0.719189\n",
            "Epoch 62: Loss: 0.552651 \t\t Validation loss: 0.546233\n",
            "Training average batch accuracy: 0.718375\n",
            "Validation average batch accuracy: 0.720313\n",
            "Epoch 63: Loss: 0.554195 \t\t Validation loss: 0.546060\n",
            "Training average batch accuracy: 0.716250\n",
            "Validation average batch accuracy: 0.721191\n",
            "Epoch 64: Loss: 0.548558 \t\t Validation loss: 0.545692\n",
            "Training average batch accuracy: 0.719375\n",
            "Validation average batch accuracy: 0.719531\n",
            "Epoch 65: Loss: 0.560640 \t\t Validation loss: 0.558129\n",
            "Training average batch accuracy: 0.709063\n",
            "Validation average batch accuracy: 0.709766\n",
            "Epoch 66: Loss: 0.562699 \t\t Validation loss: 0.545427\n",
            "Training average batch accuracy: 0.707313\n",
            "Validation average batch accuracy: 0.719336\n",
            "Epoch 67: Loss: 0.545828 \t\t Validation loss: 0.541497\n",
            "Training average batch accuracy: 0.718813\n",
            "Validation average batch accuracy: 0.720850\n",
            "Epoch 68: Loss: 0.555383 \t\t Validation loss: 0.549753\n",
            "Training average batch accuracy: 0.710563\n",
            "Validation average batch accuracy: 0.716211\n",
            "Epoch 69: Loss: 0.554752 \t\t Validation loss: 0.545086\n",
            "Training average batch accuracy: 0.715875\n",
            "Validation average batch accuracy: 0.719922\n",
            "Epoch 70: Loss: 0.556038 \t\t Validation loss: 0.546271\n",
            "Training average batch accuracy: 0.715563\n",
            "Validation average batch accuracy: 0.720557\n",
            "Epoch 71: Loss: 0.547552 \t\t Validation loss: 0.547880\n",
            "Training average batch accuracy: 0.717750\n",
            "Validation average batch accuracy: 0.717432\n",
            "Epoch 72: Loss: 0.551868 \t\t Validation loss: 0.541152\n",
            "Training average batch accuracy: 0.717500\n",
            "Validation average batch accuracy: 0.717627\n",
            "Epoch 73: Loss: 0.552751 \t\t Validation loss: 0.544779\n",
            "Training average batch accuracy: 0.712938\n",
            "Validation average batch accuracy: 0.719678\n",
            "Epoch 74: Loss: 0.547865 \t\t Validation loss: 0.541819\n",
            "Training average batch accuracy: 0.719063\n",
            "Validation average batch accuracy: 0.722852\n",
            "Epoch 75: Loss: 0.545107 \t\t Validation loss: 0.539298\n",
            "Training average batch accuracy: 0.717813\n",
            "Validation average batch accuracy: 0.725195\n",
            "Epoch 76: Loss: 0.550115 \t\t Validation loss: 0.549146\n",
            "Training average batch accuracy: 0.719438\n",
            "Validation average batch accuracy: 0.715967\n",
            "Epoch 77: Loss: 0.551911 \t\t Validation loss: 0.537903\n",
            "BEST SCORE: tensor(0.7271, device='cuda:0')\n",
            "Training average batch accuracy: 0.712500\n",
            "Validation average batch accuracy: 0.727100\n",
            "Epoch 78: Loss: 0.546924 \t\t Validation loss: 0.545064\n",
            "Training average batch accuracy: 0.721500\n",
            "Validation average batch accuracy: 0.720117\n",
            "Epoch 79: Loss: 0.548920 \t\t Validation loss: 0.542344\n",
            "Training average batch accuracy: 0.717375\n",
            "Validation average batch accuracy: 0.722022\n",
            "Epoch 80: Loss: 0.543550 \t\t Validation loss: 0.537192\n",
            "Training average batch accuracy: 0.726500\n",
            "Validation average batch accuracy: 0.726025\n",
            "Epoch 81: Loss: 0.553232 \t\t Validation loss: 0.538448\n",
            "BEST SCORE: tensor(0.7272, device='cuda:0')\n",
            "Training average batch accuracy: 0.713375\n",
            "Validation average batch accuracy: 0.727197\n",
            "Epoch 82: Loss: 0.546278 \t\t Validation loss: 0.528371\n",
            "BEST SCORE: tensor(0.7350, device='cuda:0')\n",
            "Training average batch accuracy: 0.719625\n",
            "Validation average batch accuracy: 0.734961\n",
            "Epoch 83: Loss: 0.544644 \t\t Validation loss: 0.544583\n",
            "Training average batch accuracy: 0.724563\n",
            "Validation average batch accuracy: 0.720410\n",
            "Epoch 84: Loss: 0.546260 \t\t Validation loss: 0.543660\n",
            "Training average batch accuracy: 0.718813\n",
            "Validation average batch accuracy: 0.718994\n",
            "Epoch 85: Loss: 0.544715 \t\t Validation loss: 0.537680\n",
            "Training average batch accuracy: 0.721688\n",
            "Validation average batch accuracy: 0.725244\n",
            "Epoch 86: Loss: 0.546816 \t\t Validation loss: 0.534677\n",
            "Training average batch accuracy: 0.720938\n",
            "Validation average batch accuracy: 0.728125\n",
            "Epoch 87: Loss: 0.546061 \t\t Validation loss: 0.528759\n",
            "Training average batch accuracy: 0.719313\n",
            "Validation average batch accuracy: 0.733203\n",
            "Epoch 88: Loss: 0.541090 \t\t Validation loss: 0.538652\n",
            "Training average batch accuracy: 0.723313\n",
            "Validation average batch accuracy: 0.727246\n",
            "Epoch 89: Loss: 0.540540 \t\t Validation loss: 0.535840\n",
            "Training average batch accuracy: 0.726125\n",
            "Validation average batch accuracy: 0.727734\n",
            "Epoch 90: Loss: 0.548995 \t\t Validation loss: 0.526032\n",
            "BEST SCORE: tensor(0.7355, device='cuda:0')\n",
            "Training average batch accuracy: 0.717250\n",
            "Validation average batch accuracy: 0.735547\n",
            "Epoch 91: Loss: 0.537451 \t\t Validation loss: 0.532169\n",
            "Training average batch accuracy: 0.723938\n",
            "Validation average batch accuracy: 0.730957\n",
            "Epoch 92: Loss: 0.553354 \t\t Validation loss: 0.536572\n",
            "Training average batch accuracy: 0.718188\n",
            "Validation average batch accuracy: 0.725098\n",
            "Epoch 93: Loss: 0.544911 \t\t Validation loss: 0.534457\n",
            "Training average batch accuracy: 0.720250\n",
            "Validation average batch accuracy: 0.731934\n",
            "Epoch 94: Loss: 0.543081 \t\t Validation loss: 0.534000\n",
            "Training average batch accuracy: 0.720688\n",
            "Validation average batch accuracy: 0.730078\n",
            "Epoch 95: Loss: 0.537470 \t\t Validation loss: 0.538880\n",
            "Training average batch accuracy: 0.725000\n",
            "Validation average batch accuracy: 0.726709\n",
            "Epoch 96: Loss: 0.535679 \t\t Validation loss: 0.540872\n",
            "Training average batch accuracy: 0.728625\n",
            "Validation average batch accuracy: 0.721826\n",
            "Epoch 97: Loss: 0.543513 \t\t Validation loss: 0.533143\n",
            "Training average batch accuracy: 0.725000\n",
            "Validation average batch accuracy: 0.729150\n",
            "Epoch 98: Loss: 0.545632 \t\t Validation loss: 0.527930\n",
            "Training average batch accuracy: 0.719250\n",
            "Validation average batch accuracy: 0.725244\n",
            "Epoch 99: Loss: 0.543285 \t\t Validation loss: 0.536109\n",
            "Training average batch accuracy: 0.721688\n",
            "Validation average batch accuracy: 0.728564\n",
            "Epoch 100: Loss: 0.538659 \t\t Validation loss: 0.532664\n",
            "Training average batch accuracy: 0.724250\n",
            "Validation average batch accuracy: 0.728955\n",
            "Epoch 101: Loss: 0.534310 \t\t Validation loss: 0.527678\n",
            "BEST SCORE: tensor(0.7388, device='cuda:0')\n",
            "Training average batch accuracy: 0.726188\n",
            "Epoch   102: reducing learning rate of group 0 to 9.0000e-05.\n",
            "Validation average batch accuracy: 0.738770\n",
            "Epoch 102: Loss: 0.537286 \t\t Validation loss: 0.536163\n",
            "Training average batch accuracy: 0.728688\n",
            "Validation average batch accuracy: 0.726709\n",
            "Epoch 103: Loss: 0.539898 \t\t Validation loss: 0.528968\n",
            "Training average batch accuracy: 0.726938\n",
            "Validation average batch accuracy: 0.732227\n",
            "Epoch 104: Loss: 0.533963 \t\t Validation loss: 0.525752\n",
            "Training average batch accuracy: 0.731750\n",
            "Validation average batch accuracy: 0.734180\n",
            "Epoch 105: Loss: 0.530754 \t\t Validation loss: 0.528993\n",
            "Training average batch accuracy: 0.730750\n",
            "Validation average batch accuracy: 0.728662\n",
            "Epoch 106: Loss: 0.534261 \t\t Validation loss: 0.525646\n",
            "Training average batch accuracy: 0.728875\n",
            "Validation average batch accuracy: 0.735352\n",
            "Epoch 107: Loss: 0.530729 \t\t Validation loss: 0.527237\n",
            "Training average batch accuracy: 0.733000\n",
            "Validation average batch accuracy: 0.729443\n",
            "Epoch 108: Loss: 0.534008 \t\t Validation loss: 0.528491\n",
            "Training average batch accuracy: 0.728375\n",
            "Validation average batch accuracy: 0.738232\n",
            "Epoch 109: Loss: 0.529979 \t\t Validation loss: 0.530104\n",
            "Training average batch accuracy: 0.730438\n",
            "Validation average batch accuracy: 0.733594\n",
            "Epoch 110: Loss: 0.534481 \t\t Validation loss: 0.530058\n",
            "Training average batch accuracy: 0.731688\n",
            "Validation average batch accuracy: 0.733643\n",
            "Epoch 111: Loss: 0.540213 \t\t Validation loss: 0.524588\n",
            "Training average batch accuracy: 0.725188\n",
            "Validation average batch accuracy: 0.734570\n",
            "Epoch 112: Loss: 0.538172 \t\t Validation loss: 0.527606\n",
            "Training average batch accuracy: 0.725875\n",
            "Validation average batch accuracy: 0.735791\n",
            "Epoch 113: Loss: 0.536760 \t\t Validation loss: 0.520623\n",
            "BEST SCORE: tensor(0.7418, device='cuda:0')\n",
            "Training average batch accuracy: 0.726563\n",
            "Validation average batch accuracy: 0.741846\n",
            "Epoch 114: Loss: 0.534689 \t\t Validation loss: 0.528331\n",
            "Training average batch accuracy: 0.730063\n",
            "Validation average batch accuracy: 0.729834\n",
            "Epoch 115: Loss: 0.532957 \t\t Validation loss: 0.528205\n",
            "Training average batch accuracy: 0.730938\n",
            "Validation average batch accuracy: 0.733838\n",
            "Epoch 116: Loss: 0.533738 \t\t Validation loss: 0.522388\n",
            "Training average batch accuracy: 0.728750\n",
            "Validation average batch accuracy: 0.738281\n",
            "Epoch 117: Loss: 0.531548 \t\t Validation loss: 0.526526\n",
            "Training average batch accuracy: 0.729000\n",
            "Validation average batch accuracy: 0.735645\n",
            "Epoch 118: Loss: 0.529171 \t\t Validation loss: 0.522917\n",
            "Training average batch accuracy: 0.732063\n",
            "Validation average batch accuracy: 0.733691\n",
            "Epoch 119: Loss: 0.530643 \t\t Validation loss: 0.519005\n",
            "Training average batch accuracy: 0.729938\n",
            "Validation average batch accuracy: 0.737549\n",
            "Epoch 120: Loss: 0.531272 \t\t Validation loss: 0.534020\n",
            "Training average batch accuracy: 0.732250\n",
            "Validation average batch accuracy: 0.726514\n",
            "Epoch 121: Loss: 0.530034 \t\t Validation loss: 0.525685\n",
            "Training average batch accuracy: 0.732875\n",
            "Validation average batch accuracy: 0.736377\n",
            "Epoch 122: Loss: 0.527873 \t\t Validation loss: 0.526578\n",
            "Training average batch accuracy: 0.730813\n",
            "Validation average batch accuracy: 0.732764\n",
            "Epoch 123: Loss: 0.529968 \t\t Validation loss: 0.522701\n",
            "Training average batch accuracy: 0.732063\n",
            "Validation average batch accuracy: 0.735645\n",
            "Epoch 124: Loss: 0.529163 \t\t Validation loss: 0.522145\n",
            "Training average batch accuracy: 0.735063\n",
            "Validation average batch accuracy: 0.736377\n",
            "Epoch 125: Loss: 0.527424 \t\t Validation loss: 0.519925\n",
            "Training average batch accuracy: 0.733438\n",
            "Validation average batch accuracy: 0.740479\n",
            "Epoch 126: Loss: 0.521896 \t\t Validation loss: 0.517522\n",
            "BEST SCORE: tensor(0.7445, device='cuda:0')\n",
            "Training average batch accuracy: 0.736500\n",
            "Validation average batch accuracy: 0.744531\n",
            "Epoch 127: Loss: 0.523119 \t\t Validation loss: 0.522779\n",
            "Training average batch accuracy: 0.737688\n",
            "Validation average batch accuracy: 0.737988\n",
            "Epoch 128: Loss: 0.533813 \t\t Validation loss: 0.528885\n",
            "Training average batch accuracy: 0.727375\n",
            "Validation average batch accuracy: 0.732080\n",
            "Epoch 129: Loss: 0.523233 \t\t Validation loss: 0.525270\n",
            "Training average batch accuracy: 0.736063\n",
            "Validation average batch accuracy: 0.733545\n",
            "Epoch 130: Loss: 0.524674 \t\t Validation loss: 0.521281\n",
            "Training average batch accuracy: 0.740000\n",
            "Validation average batch accuracy: 0.739404\n",
            "Epoch 131: Loss: 0.529465 \t\t Validation loss: 0.519832\n",
            "Training average batch accuracy: 0.735688\n",
            "Validation average batch accuracy: 0.743701\n",
            "Epoch 132: Loss: 0.526867 \t\t Validation loss: 0.522131\n",
            "Training average batch accuracy: 0.733188\n",
            "Validation average batch accuracy: 0.739258\n",
            "Epoch 133: Loss: 0.525009 \t\t Validation loss: 0.527450\n",
            "Training average batch accuracy: 0.734313\n",
            "Validation average batch accuracy: 0.732422\n",
            "Epoch 134: Loss: 0.524803 \t\t Validation loss: 0.519181\n",
            "Training average batch accuracy: 0.736750\n",
            "Validation average batch accuracy: 0.738770\n",
            "Epoch 135: Loss: 0.527826 \t\t Validation loss: 0.514677\n",
            "Training average batch accuracy: 0.732313\n",
            "Validation average batch accuracy: 0.743652\n",
            "Epoch 136: Loss: 0.520898 \t\t Validation loss: 0.525401\n",
            "Training average batch accuracy: 0.740063\n",
            "Validation average batch accuracy: 0.735742\n",
            "Epoch 137: Loss: 0.524104 \t\t Validation loss: 0.522115\n",
            "Training average batch accuracy: 0.734875\n",
            "Validation average batch accuracy: 0.742041\n",
            "Epoch 138: Loss: 0.524553 \t\t Validation loss: 0.516876\n",
            "Training average batch accuracy: 0.738125\n",
            "Validation average batch accuracy: 0.743701\n",
            "Epoch 139: Loss: 0.526465 \t\t Validation loss: 0.516084\n",
            "Training average batch accuracy: 0.737625\n",
            "Validation average batch accuracy: 0.743311\n",
            "Epoch 140: Loss: 0.525468 \t\t Validation loss: 0.522809\n",
            "Training average batch accuracy: 0.737500\n",
            "Validation average batch accuracy: 0.739551\n",
            "Epoch 141: Loss: 0.525328 \t\t Validation loss: 0.520529\n",
            "Training average batch accuracy: 0.739063\n",
            "Validation average batch accuracy: 0.740967\n",
            "Epoch 142: Loss: 0.527927 \t\t Validation loss: 0.517407\n",
            "Training average batch accuracy: 0.731500\n",
            "Validation average batch accuracy: 0.741357\n",
            "Epoch 143: Loss: 0.521159 \t\t Validation loss: 0.521007\n",
            "Training average batch accuracy: 0.738438\n",
            "Validation average batch accuracy: 0.735400\n",
            "Epoch 144: Loss: 0.526330 \t\t Validation loss: 0.518173\n",
            "Training average batch accuracy: 0.735625\n",
            "Validation average batch accuracy: 0.742432\n",
            "Epoch 145: Loss: 0.515473 \t\t Validation loss: 0.518700\n",
            "Training average batch accuracy: 0.743125\n",
            "Validation average batch accuracy: 0.739258\n",
            "Epoch 146: Loss: 0.521010 \t\t Validation loss: 0.517042\n",
            "Training average batch accuracy: 0.741250\n",
            "Epoch   147: reducing learning rate of group 0 to 8.1000e-05.\n",
            "Validation average batch accuracy: 0.740527\n",
            "Epoch 147: Loss: 0.523975 \t\t Validation loss: 0.524723\n",
            "Training average batch accuracy: 0.736875\n",
            "Validation average batch accuracy: 0.738281\n",
            "Epoch 148: Loss: 0.520072 \t\t Validation loss: 0.515788\n",
            "Training average batch accuracy: 0.738313\n",
            "Validation average batch accuracy: 0.742334\n",
            "Epoch 149: Loss: 0.518520 \t\t Validation loss: 0.520274\n",
            "Training average batch accuracy: 0.736688\n",
            "Validation average batch accuracy: 0.737207\n",
            "Epoch 150: Loss: 0.518818 \t\t Validation loss: 0.515842\n",
            "Training average batch accuracy: 0.741688\n",
            "Validation average batch accuracy: 0.741797\n",
            "Epoch 151: Loss: 0.523220 \t\t Validation loss: 0.514414\n",
            "Training average batch accuracy: 0.739000\n",
            "Validation average batch accuracy: 0.742041\n",
            "Epoch 152: Loss: 0.517466 \t\t Validation loss: 0.515079\n",
            "Training average batch accuracy: 0.739500\n",
            "Validation average batch accuracy: 0.741553\n",
            "Epoch 153: Loss: 0.507815 \t\t Validation loss: 0.516590\n",
            "Training average batch accuracy: 0.745438\n",
            "Validation average batch accuracy: 0.738037\n",
            "Epoch 154: Loss: 0.518802 \t\t Validation loss: 0.516293\n",
            "BEST SCORE: tensor(0.7454, device='cuda:0')\n",
            "Training average batch accuracy: 0.742500\n",
            "Validation average batch accuracy: 0.745361\n",
            "Epoch 155: Loss: 0.513085 \t\t Validation loss: 0.513898\n",
            "BEST SCORE: tensor(0.7457, device='cuda:0')\n",
            "Training average batch accuracy: 0.744375\n",
            "Validation average batch accuracy: 0.745703\n",
            "Epoch 156: Loss: 0.519216 \t\t Validation loss: 0.520983\n",
            "Training average batch accuracy: 0.741875\n",
            "Validation average batch accuracy: 0.735986\n",
            "Epoch 157: Loss: 0.522480 \t\t Validation loss: 0.515223\n",
            "Training average batch accuracy: 0.737625\n",
            "Validation average batch accuracy: 0.739453\n",
            "Epoch 158: Loss: 0.518170 \t\t Validation loss: 0.511944\n",
            "Training average batch accuracy: 0.741313\n",
            "Validation average batch accuracy: 0.744189\n",
            "Epoch 159: Loss: 0.518132 \t\t Validation loss: 0.514973\n",
            "Training average batch accuracy: 0.741125\n",
            "Validation average batch accuracy: 0.738379\n",
            "Epoch 160: Loss: 0.511913 \t\t Validation loss: 0.520462\n",
            "Training average batch accuracy: 0.746813\n",
            "Validation average batch accuracy: 0.739844\n",
            "Epoch 161: Loss: 0.513316 \t\t Validation loss: 0.511817\n",
            "Training average batch accuracy: 0.744188\n",
            "Validation average batch accuracy: 0.742627\n",
            "Epoch 162: Loss: 0.513654 \t\t Validation loss: 0.512615\n",
            "BEST SCORE: tensor(0.7464, device='cuda:0')\n",
            "Training average batch accuracy: 0.747250\n",
            "Validation average batch accuracy: 0.746387\n",
            "Epoch 163: Loss: 0.521619 \t\t Validation loss: 0.511979\n",
            "BEST SCORE: tensor(0.7478, device='cuda:0')\n",
            "Training average batch accuracy: 0.741563\n",
            "Validation average batch accuracy: 0.747803\n",
            "Epoch 164: Loss: 0.513045 \t\t Validation loss: 0.512623\n",
            "Training average batch accuracy: 0.743813\n",
            "Validation average batch accuracy: 0.743311\n",
            "Epoch 165: Loss: 0.517870 \t\t Validation loss: 0.510474\n",
            "Training average batch accuracy: 0.741688\n",
            "Validation average batch accuracy: 0.746484\n",
            "Epoch 166: Loss: 0.515375 \t\t Validation loss: 0.514142\n",
            "Training average batch accuracy: 0.746688\n",
            "Validation average batch accuracy: 0.741602\n",
            "Epoch 167: Loss: 0.512846 \t\t Validation loss: 0.505213\n",
            "BEST SCORE: tensor(0.7487, device='cuda:0')\n",
            "Training average batch accuracy: 0.746625\n",
            "Validation average batch accuracy: 0.748730\n",
            "Epoch 168: Loss: 0.523608 \t\t Validation loss: 0.515633\n",
            "Training average batch accuracy: 0.739938\n",
            "Validation average batch accuracy: 0.745117\n",
            "Epoch 169: Loss: 0.512160 \t\t Validation loss: 0.512229\n",
            "Training average batch accuracy: 0.746750\n",
            "Validation average batch accuracy: 0.742920\n",
            "Epoch 170: Loss: 0.515604 \t\t Validation loss: 0.516258\n",
            "Training average batch accuracy: 0.740938\n",
            "Validation average batch accuracy: 0.743018\n",
            "Epoch 171: Loss: 0.515073 \t\t Validation loss: 0.511871\n",
            "Training average batch accuracy: 0.745875\n",
            "Validation average batch accuracy: 0.746436\n",
            "Epoch 172: Loss: 0.510579 \t\t Validation loss: 0.510220\n",
            "Training average batch accuracy: 0.745625\n",
            "Validation average batch accuracy: 0.746924\n",
            "Epoch 173: Loss: 0.510437 \t\t Validation loss: 0.505400\n",
            "BEST SCORE: tensor(0.7496, device='cuda:0')\n",
            "Training average batch accuracy: 0.747625\n",
            "Validation average batch accuracy: 0.749609\n",
            "Epoch 174: Loss: 0.501743 \t\t Validation loss: 0.515492\n",
            "Training average batch accuracy: 0.752750\n",
            "Validation average batch accuracy: 0.740381\n",
            "Epoch 175: Loss: 0.522766 \t\t Validation loss: 0.515688\n",
            "Training average batch accuracy: 0.737188\n",
            "Validation average batch accuracy: 0.743750\n",
            "Epoch 176: Loss: 0.519472 \t\t Validation loss: 0.507713\n",
            "Training average batch accuracy: 0.740813\n",
            "Validation average batch accuracy: 0.748730\n",
            "Epoch 177: Loss: 0.513615 \t\t Validation loss: 0.503695\n",
            "BEST SCORE: tensor(0.7533, device='cuda:0')\n",
            "Training average batch accuracy: 0.743250\n",
            "Validation average batch accuracy: 0.753272\n",
            "Epoch 178: Loss: 0.514316 \t\t Validation loss: 0.513398\n",
            "Training average batch accuracy: 0.742875\n",
            "Validation average batch accuracy: 0.745020\n",
            "Epoch 179: Loss: 0.511558 \t\t Validation loss: 0.506775\n",
            "BEST SCORE: tensor(0.7543, device='cuda:0')\n",
            "Training average batch accuracy: 0.744813\n",
            "Validation average batch accuracy: 0.754297\n",
            "Epoch 180: Loss: 0.502281 \t\t Validation loss: 0.507734\n",
            "Training average batch accuracy: 0.749938\n",
            "Validation average batch accuracy: 0.745508\n",
            "Epoch 181: Loss: 0.510942 \t\t Validation loss: 0.510070\n",
            "Training average batch accuracy: 0.745875\n",
            "Validation average batch accuracy: 0.747656\n",
            "Epoch 182: Loss: 0.512594 \t\t Validation loss: 0.513561\n",
            "Training average batch accuracy: 0.746813\n",
            "Validation average batch accuracy: 0.748047\n",
            "Epoch 183: Loss: 0.510044 \t\t Validation loss: 0.510116\n",
            "Training average batch accuracy: 0.746813\n",
            "Validation average batch accuracy: 0.749414\n",
            "Epoch 184: Loss: 0.508301 \t\t Validation loss: 0.505996\n",
            "Training average batch accuracy: 0.750125\n",
            "Validation average batch accuracy: 0.748584\n",
            "Epoch 185: Loss: 0.512037 \t\t Validation loss: 0.508929\n",
            "Training average batch accuracy: 0.747438\n",
            "Validation average batch accuracy: 0.745264\n",
            "Epoch 186: Loss: 0.503631 \t\t Validation loss: 0.511033\n",
            "Training average batch accuracy: 0.751938\n",
            "Validation average batch accuracy: 0.743701\n",
            "Epoch 187: Loss: 0.503184 \t\t Validation loss: 0.507109\n",
            "Training average batch accuracy: 0.749938\n",
            "Validation average batch accuracy: 0.748242\n",
            "Epoch 188: Loss: 0.504862 \t\t Validation loss: 0.507356\n",
            "Training average batch accuracy: 0.747813\n",
            "Epoch   189: reducing learning rate of group 0 to 7.2900e-05.\n",
            "Validation average batch accuracy: 0.747754\n",
            "Epoch 189: Loss: 0.508499 \t\t Validation loss: 0.515268\n",
            "Training average batch accuracy: 0.746313\n",
            "Validation average batch accuracy: 0.744775\n",
            "Epoch 190: Loss: 0.503042 \t\t Validation loss: 0.509060\n",
            "Training average batch accuracy: 0.752188\n",
            "Validation average batch accuracy: 0.749414\n",
            "Epoch 191: Loss: 0.506424 \t\t Validation loss: 0.504364\n",
            "Training average batch accuracy: 0.752313\n",
            "Validation average batch accuracy: 0.744141\n",
            "Epoch 192: Loss: 0.509023 \t\t Validation loss: 0.508039\n",
            "Training average batch accuracy: 0.748938\n",
            "Validation average batch accuracy: 0.747949\n",
            "Epoch 193: Loss: 0.506768 \t\t Validation loss: 0.503364\n",
            "Training average batch accuracy: 0.748000\n",
            "Validation average batch accuracy: 0.753076\n",
            "Epoch 194: Loss: 0.509243 \t\t Validation loss: 0.502717\n",
            "Training average batch accuracy: 0.746625\n",
            "Validation average batch accuracy: 0.748047\n",
            "Epoch 195: Loss: 0.499794 \t\t Validation loss: 0.512813\n",
            "Training average batch accuracy: 0.752375\n",
            "Validation average batch accuracy: 0.741650\n",
            "Epoch 196: Loss: 0.511326 \t\t Validation loss: 0.504588\n",
            "Training average batch accuracy: 0.743063\n",
            "Validation average batch accuracy: 0.749756\n",
            "Epoch 197: Loss: 0.504897 \t\t Validation loss: 0.508518\n",
            "Training average batch accuracy: 0.754438\n",
            "Validation average batch accuracy: 0.747119\n",
            "Epoch 198: Loss: 0.512447 \t\t Validation loss: 0.503917\n",
            "Training average batch accuracy: 0.743750\n",
            "Validation average batch accuracy: 0.749365\n",
            "Epoch 199: Loss: 0.507402 \t\t Validation loss: 0.504790\n",
            "Training average batch accuracy: 0.748813\n",
            "Validation average batch accuracy: 0.749414\n",
            "Epoch 200: Loss: 0.507833 \t\t Validation loss: 0.506368\n",
            "Training average batch accuracy: 0.748188\n",
            "Validation average batch accuracy: 0.749170\n",
            "Epoch 201: Loss: 0.513459 \t\t Validation loss: 0.505260\n",
            "Training average batch accuracy: 0.748813\n",
            "Validation average batch accuracy: 0.745605\n",
            "Epoch 202: Loss: 0.503782 \t\t Validation loss: 0.506923\n",
            "Training average batch accuracy: 0.750750\n",
            "Validation average batch accuracy: 0.749121\n",
            "Epoch 203: Loss: 0.498262 \t\t Validation loss: 0.503092\n",
            "Training average batch accuracy: 0.755625\n",
            "Validation average batch accuracy: 0.751074\n",
            "Epoch 204: Loss: 0.499512 \t\t Validation loss: 0.507954\n",
            "Training average batch accuracy: 0.751813\n",
            "Validation average batch accuracy: 0.745996\n",
            "Epoch 205: Loss: 0.502545 \t\t Validation loss: 0.497830\n",
            "BEST SCORE: tensor(0.7549, device='cuda:0')\n",
            "Training average batch accuracy: 0.753875\n",
            "Validation average batch accuracy: 0.754932\n",
            "Epoch 206: Loss: 0.502520 \t\t Validation loss: 0.500319\n",
            "BEST SCORE: tensor(0.7565, device='cuda:0')\n",
            "Training average batch accuracy: 0.747125\n",
            "Validation average batch accuracy: 0.756494\n",
            "Epoch 207: Loss: 0.502119 \t\t Validation loss: 0.506846\n",
            "Training average batch accuracy: 0.753813\n",
            "Validation average batch accuracy: 0.749170\n",
            "Epoch 208: Loss: 0.501890 \t\t Validation loss: 0.506059\n",
            "Training average batch accuracy: 0.753125\n",
            "Validation average batch accuracy: 0.748730\n",
            "Epoch 209: Loss: 0.504420 \t\t Validation loss: 0.503689\n",
            "Training average batch accuracy: 0.752438\n",
            "Validation average batch accuracy: 0.751660\n",
            "Epoch 210: Loss: 0.502504 \t\t Validation loss: 0.503113\n",
            "Training average batch accuracy: 0.753500\n",
            "Validation average batch accuracy: 0.751611\n",
            "Epoch 211: Loss: 0.505430 \t\t Validation loss: 0.510161\n",
            "Training average batch accuracy: 0.751875\n",
            "Validation average batch accuracy: 0.746875\n",
            "Epoch 212: Loss: 0.506242 \t\t Validation loss: 0.508662\n",
            "Training average batch accuracy: 0.749125\n",
            "Validation average batch accuracy: 0.744531\n",
            "Epoch 213: Loss: 0.499288 \t\t Validation loss: 0.507181\n",
            "Training average batch accuracy: 0.752063\n",
            "Validation average batch accuracy: 0.752441\n",
            "Epoch 214: Loss: 0.503422 \t\t Validation loss: 0.504532\n",
            "Training average batch accuracy: 0.747688\n",
            "Validation average batch accuracy: 0.749023\n",
            "Epoch 215: Loss: 0.495906 \t\t Validation loss: 0.501999\n",
            "Training average batch accuracy: 0.757063\n",
            "Validation average batch accuracy: 0.755811\n",
            "Epoch 216: Loss: 0.496584 \t\t Validation loss: 0.499528\n",
            "Training average batch accuracy: 0.758313\n",
            "Epoch   217: reducing learning rate of group 0 to 6.5610e-05.\n",
            "Validation average batch accuracy: 0.754297\n",
            "Epoch 217: Loss: 0.496969 \t\t Validation loss: 0.502657\n",
            "Training average batch accuracy: 0.755500\n",
            "Validation average batch accuracy: 0.751855\n",
            "Epoch 218: Loss: 0.494415 \t\t Validation loss: 0.502267\n",
            "Training average batch accuracy: 0.757313\n",
            "Validation average batch accuracy: 0.753320\n",
            "Epoch 219: Loss: 0.489754 \t\t Validation loss: 0.498121\n",
            "Training average batch accuracy: 0.760063\n",
            "Validation average batch accuracy: 0.749805\n",
            "Epoch 220: Loss: 0.505749 \t\t Validation loss: 0.502069\n",
            "Training average batch accuracy: 0.748188\n",
            "Validation average batch accuracy: 0.752734\n",
            "Epoch 221: Loss: 0.497260 \t\t Validation loss: 0.502980\n",
            "Training average batch accuracy: 0.753313\n",
            "Validation average batch accuracy: 0.753760\n",
            "Epoch 222: Loss: 0.500891 \t\t Validation loss: 0.507237\n",
            "Training average batch accuracy: 0.751188\n",
            "Validation average batch accuracy: 0.747510\n",
            "Epoch 223: Loss: 0.497181 \t\t Validation loss: 0.502759\n",
            "Training average batch accuracy: 0.755250\n",
            "Validation average batch accuracy: 0.748486\n",
            "Epoch 224: Loss: 0.495405 \t\t Validation loss: 0.502610\n",
            "Training average batch accuracy: 0.757938\n",
            "Validation average batch accuracy: 0.748193\n",
            "Epoch 225: Loss: 0.490340 \t\t Validation loss: 0.498190\n",
            "Training average batch accuracy: 0.762438\n",
            "Validation average batch accuracy: 0.753223\n",
            "Epoch 226: Loss: 0.496323 \t\t Validation loss: 0.500686\n",
            "Training average batch accuracy: 0.759250\n",
            "Validation average batch accuracy: 0.752783\n",
            "Epoch 227: Loss: 0.487007 \t\t Validation loss: 0.518065\n",
            "Training average batch accuracy: 0.759313\n",
            "Epoch   228: reducing learning rate of group 0 to 5.9049e-05.\n",
            "Validation average batch accuracy: 0.741602\n",
            "Epoch 228: Loss: 0.496662 \t\t Validation loss: 0.506816\n",
            "Training average batch accuracy: 0.757813\n",
            "Validation average batch accuracy: 0.750781\n",
            "Epoch 229: Loss: 0.495844 \t\t Validation loss: 0.501414\n",
            "Training average batch accuracy: 0.754625\n",
            "Validation average batch accuracy: 0.755127\n",
            "Epoch 230: Loss: 0.495259 \t\t Validation loss: 0.508075\n",
            "Training average batch accuracy: 0.758938\n",
            "Validation average batch accuracy: 0.747168\n",
            "Epoch 231: Loss: 0.485240 \t\t Validation loss: 0.507647\n",
            "Training average batch accuracy: 0.763563\n",
            "Validation average batch accuracy: 0.749170\n",
            "Epoch 232: Loss: 0.492441 \t\t Validation loss: 0.496976\n",
            "BEST SCORE: tensor(0.7578, device='cuda:0')\n",
            "Training average batch accuracy: 0.756938\n",
            "Validation average batch accuracy: 0.757812\n",
            "Epoch 233: Loss: 0.495906 \t\t Validation loss: 0.505024\n",
            "Training average batch accuracy: 0.752125\n",
            "Validation average batch accuracy: 0.747949\n",
            "Epoch 234: Loss: 0.501145 \t\t Validation loss: 0.500482\n",
            "Training average batch accuracy: 0.755313\n",
            "Validation average batch accuracy: 0.751270\n",
            "Epoch 235: Loss: 0.498631 \t\t Validation loss: 0.499337\n",
            "Training average batch accuracy: 0.752188\n",
            "Validation average batch accuracy: 0.749170\n",
            "Epoch 236: Loss: 0.490255 \t\t Validation loss: 0.499181\n",
            "Training average batch accuracy: 0.759375\n",
            "Validation average batch accuracy: 0.752393\n",
            "Epoch 237: Loss: 0.489384 \t\t Validation loss: 0.498831\n",
            "Training average batch accuracy: 0.759000\n",
            "Validation average batch accuracy: 0.755371\n",
            "Epoch 238: Loss: 0.494849 \t\t Validation loss: 0.504210\n",
            "Training average batch accuracy: 0.757563\n",
            "Validation average batch accuracy: 0.750244\n",
            "Epoch 239: Loss: 0.487586 \t\t Validation loss: 0.494188\n",
            "Training average batch accuracy: 0.760938\n",
            "Validation average batch accuracy: 0.757617\n",
            "Epoch 240: Loss: 0.488648 \t\t Validation loss: 0.498693\n",
            "Training average batch accuracy: 0.763438\n",
            "Validation average batch accuracy: 0.753564\n",
            "Epoch 241: Loss: 0.496801 \t\t Validation loss: 0.502631\n",
            "Training average batch accuracy: 0.759500\n",
            "Validation average batch accuracy: 0.753809\n",
            "Epoch 242: Loss: 0.490734 \t\t Validation loss: 0.502255\n",
            "Training average batch accuracy: 0.762125\n",
            "Validation average batch accuracy: 0.756006\n",
            "Epoch 243: Loss: 0.493814 \t\t Validation loss: 0.503334\n",
            "Training average batch accuracy: 0.758750\n",
            "Validation average batch accuracy: 0.748730\n",
            "Epoch 244: Loss: 0.491107 \t\t Validation loss: 0.500145\n",
            "Training average batch accuracy: 0.760000\n",
            "Validation average batch accuracy: 0.752734\n",
            "Epoch 245: Loss: 0.503059 \t\t Validation loss: 0.490605\n",
            "BEST SCORE: tensor(0.7599, device='cuda:0')\n",
            "Training average batch accuracy: 0.753813\n",
            "Validation average batch accuracy: 0.759863\n",
            "Epoch 246: Loss: 0.493941 \t\t Validation loss: 0.502762\n",
            "Training average batch accuracy: 0.758313\n",
            "Validation average batch accuracy: 0.751221\n",
            "Epoch 247: Loss: 0.501277 \t\t Validation loss: 0.508889\n",
            "Training average batch accuracy: 0.754563\n",
            "Validation average batch accuracy: 0.745898\n",
            "Epoch 248: Loss: 0.493821 \t\t Validation loss: 0.507102\n",
            "Training average batch accuracy: 0.759688\n",
            "Validation average batch accuracy: 0.748145\n",
            "Epoch 249: Loss: 0.492372 \t\t Validation loss: 0.502356\n",
            "Training average batch accuracy: 0.760750\n",
            "Validation average batch accuracy: 0.750635\n",
            "Epoch 250: Loss: 0.491876 \t\t Validation loss: 0.495747\n",
            "Training average batch accuracy: 0.758125\n",
            "Validation average batch accuracy: 0.757227\n",
            "Epoch 251: Loss: 0.481229 \t\t Validation loss: 0.505424\n",
            "Training average batch accuracy: 0.763375\n",
            "Validation average batch accuracy: 0.754590\n",
            "Epoch 252: Loss: 0.487704 \t\t Validation loss: 0.503181\n",
            "Training average batch accuracy: 0.762563\n",
            "Validation average batch accuracy: 0.750781\n",
            "Epoch 253: Loss: 0.485546 \t\t Validation loss: 0.505139\n",
            "Training average batch accuracy: 0.762125\n",
            "Validation average batch accuracy: 0.750391\n",
            "Epoch 254: Loss: 0.496205 \t\t Validation loss: 0.500119\n",
            "Training average batch accuracy: 0.759313\n",
            "Validation average batch accuracy: 0.751807\n",
            "Epoch 255: Loss: 0.488388 \t\t Validation loss: 0.500516\n",
            "Training average batch accuracy: 0.758875\n",
            "Validation average batch accuracy: 0.753711\n",
            "Epoch 256: Loss: 0.484132 \t\t Validation loss: 0.503370\n",
            "Training average batch accuracy: 0.765000\n",
            "Epoch   257: reducing learning rate of group 0 to 5.3144e-05.\n",
            "Validation average batch accuracy: 0.752295\n",
            "Epoch 257: Loss: 0.491449 \t\t Validation loss: 0.493682\n",
            "Training average batch accuracy: 0.764063\n",
            "Validation average batch accuracy: 0.754541\n",
            "Epoch 258: Loss: 0.480195 \t\t Validation loss: 0.496744\n",
            "Training average batch accuracy: 0.768938\n",
            "Validation average batch accuracy: 0.758301\n",
            "Epoch 259: Loss: 0.487317 \t\t Validation loss: 0.500376\n",
            "Training average batch accuracy: 0.764563\n",
            "Validation average batch accuracy: 0.752490\n",
            "Epoch 260: Loss: 0.486474 \t\t Validation loss: 0.503721\n",
            "Training average batch accuracy: 0.764500\n",
            "Validation average batch accuracy: 0.751807\n",
            "Epoch 261: Loss: 0.484295 \t\t Validation loss: 0.494305\n",
            "Training average batch accuracy: 0.763313\n",
            "Validation average batch accuracy: 0.758301\n",
            "Epoch 262: Loss: 0.485899 \t\t Validation loss: 0.500099\n",
            "Training average batch accuracy: 0.763750\n",
            "Validation average batch accuracy: 0.753320\n",
            "Epoch 263: Loss: 0.488165 \t\t Validation loss: 0.501087\n",
            "Training average batch accuracy: 0.762750\n",
            "Validation average batch accuracy: 0.756299\n",
            "Epoch 264: Loss: 0.484201 \t\t Validation loss: 0.499469\n",
            "Training average batch accuracy: 0.765250\n",
            "Validation average batch accuracy: 0.758203\n",
            "Epoch 265: Loss: 0.489879 \t\t Validation loss: 0.501483\n",
            "Training average batch accuracy: 0.763250\n",
            "Validation average batch accuracy: 0.753223\n",
            "Epoch 266: Loss: 0.482818 \t\t Validation loss: 0.492977\n",
            "Training average batch accuracy: 0.767188\n",
            "Validation average batch accuracy: 0.756641\n",
            "Epoch 267: Loss: 0.487385 \t\t Validation loss: 0.500225\n",
            "Training average batch accuracy: 0.763563\n",
            "Epoch   268: reducing learning rate of group 0 to 4.7830e-05.\n",
            "Validation average batch accuracy: 0.754102\n",
            "Epoch 268: Loss: 0.484089 \t\t Validation loss: 0.503229\n",
            "Training average batch accuracy: 0.770000\n",
            "Validation average batch accuracy: 0.749268\n",
            "Epoch 269: Loss: 0.481647 \t\t Validation loss: 0.502952\n",
            "Training average batch accuracy: 0.768000\n",
            "Validation average batch accuracy: 0.750781\n",
            "Epoch 270: Loss: 0.484936 \t\t Validation loss: 0.495376\n",
            "Training average batch accuracy: 0.761813\n",
            "Validation average batch accuracy: 0.758154\n",
            "Epoch 271: Loss: 0.488878 \t\t Validation loss: 0.501870\n",
            "Training average batch accuracy: 0.764188\n",
            "Validation average batch accuracy: 0.755908\n",
            "Epoch 272: Loss: 0.493756 \t\t Validation loss: 0.497321\n",
            "Training average batch accuracy: 0.761563\n",
            "Validation average batch accuracy: 0.754687\n",
            "Epoch 273: Loss: 0.479074 \t\t Validation loss: 0.493863\n",
            "Training average batch accuracy: 0.764875\n",
            "Validation average batch accuracy: 0.754932\n",
            "Epoch 274: Loss: 0.482357 \t\t Validation loss: 0.501714\n",
            "Training average batch accuracy: 0.765313\n",
            "Validation average batch accuracy: 0.752686\n",
            "Epoch 275: Loss: 0.480105 \t\t Validation loss: 0.491303\n",
            "Training average batch accuracy: 0.767250\n",
            "Validation average batch accuracy: 0.758252\n",
            "Epoch 276: Loss: 0.491715 \t\t Validation loss: 0.500478\n",
            "Training average batch accuracy: 0.759375\n",
            "Validation average batch accuracy: 0.749854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4o4l4wRQUoG"
      },
      "source": [
        "\n",
        "torch.save({\n",
        "            'epoch': 300,\n",
        "            'model_state_dict': best_model['state_dict'],\n",
        "            'optimizer_state_dict': optim_context.state_dict()\n",
        "}, \"/content/drive/MyDrive/Sapienza/model_context_GloVE300_swap_replace_to_show.pth\" )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riLpt9ZgqRha"
      },
      "source": [
        "### Extra POS tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxsBocA2nAAr",
        "outputId": "d11b6c46-ec29-4b69-9e0b-de3debdf42ef"
      },
      "source": [
        "def context_train_step_2(model, batch):\n",
        "    (unk_context, rnn_context), preds, loss = model(*list(batch))\n",
        "    return {'loss': loss, 'batch_accuracy': binary_accuracy(preds, batch[-1])}\n",
        "\n",
        "def context_eval_step_2(model, batch):\n",
        "    (unk_context, rnn_context), preds, loss = model(*list(batch))\n",
        "    return loss, binary_accuracy(preds, batch[-1])\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, eval_step):\n",
        "    model.eval()\n",
        "    results = []\n",
        "    losses = []\n",
        "    \n",
        "    for k in range(10):\n",
        "        for i, batch in enumerate(data_loader):\n",
        "            loss, metric = eval_step(model, batch)\n",
        "            losses.append(loss.item())\n",
        "            results.append(metric)\n",
        "\n",
        "    return sum(losses) / len(losses), sum(results) / len(results)\n",
        "\n",
        "\n",
        "\n",
        "model_context = ContextEncoder(ContextParams(), vectors, \n",
        "                               train_dataset_context.get_used_tokens(True), \n",
        "                               binary_mode=True,\n",
        "                               #cosine_mode=True\n",
        "                               with_pos_tags=True,\n",
        "                               ).to('cuda')\n",
        "optim_context = torch.optim.Adam(model_context.parameters(), lr=0.0001)\n",
        "\n",
        "\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(optim_context, 5000, 0.5)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim_context, factor=0.9, verbose=True)\n",
        "\n",
        "\n",
        "#scheduler=None\n",
        "best_model = {}\n",
        "\n",
        "best_state_dict, _ = train(train_loader_context, valid_loader_context, \n",
        "      model_context, optim_context, \n",
        "      context_train_step_2, \n",
        "      context_eval_step_2,\n",
        "      300, best_model, scheduler=scheduler)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss: 0.748208 \t\t Validation loss: 0.695917\n",
            "BEST SCORE: 0.6959173830226064\n",
            "Training average batch accuracy: 0.509750\n",
            "Validation average batch accuracy: 0.545654\n",
            "Epoch 1: Loss: 0.699311 \t\t Validation loss: 0.643406\n",
            "BEST SCORE: 0.6434062253683805\n",
            "Training average batch accuracy: 0.568438\n",
            "Validation average batch accuracy: 0.614990\n",
            "Epoch 2: Loss: 0.651556 \t\t Validation loss: 0.607569\n",
            "BEST SCORE: 0.6075685690157115\n",
            "Training average batch accuracy: 0.622063\n",
            "Validation average batch accuracy: 0.663232\n",
            "Epoch 3: Loss: 0.623186 \t\t Validation loss: 0.581332\n",
            "BEST SCORE: 0.5813317835330963\n",
            "Training average batch accuracy: 0.651563\n",
            "Validation average batch accuracy: 0.683105\n",
            "Epoch 4: Loss: 0.604053 \t\t Validation loss: 0.569139\n",
            "BEST SCORE: 0.5691392871551215\n",
            "Training average batch accuracy: 0.668063\n",
            "Validation average batch accuracy: 0.704736\n",
            "Epoch 5: Loss: 0.588343 \t\t Validation loss: 0.550592\n",
            "BEST SCORE: 0.5505923122167588\n",
            "Training average batch accuracy: 0.685313\n",
            "Validation average batch accuracy: 0.716699\n",
            "Epoch 6: Loss: 0.575234 \t\t Validation loss: 0.545011\n",
            "BEST SCORE: 0.5450114291161299\n",
            "Training average batch accuracy: 0.697938\n",
            "Validation average batch accuracy: 0.723535\n",
            "Epoch 7: Loss: 0.568490 \t\t Validation loss: 0.543910\n",
            "BEST SCORE: 0.5439096775837242\n",
            "Training average batch accuracy: 0.703250\n",
            "Validation average batch accuracy: 0.721143\n",
            "Epoch 8: Loss: 0.555535 \t\t Validation loss: 0.533217\n",
            "BEST SCORE: 0.5332166563719511\n",
            "Training average batch accuracy: 0.713813\n",
            "Validation average batch accuracy: 0.729834\n",
            "Epoch 9: Loss: 0.550935 \t\t Validation loss: 0.519503\n",
            "BEST SCORE: 0.5195025025866926\n",
            "Training average batch accuracy: 0.715875\n",
            "Validation average batch accuracy: 0.743066\n",
            "Epoch 10: Loss: 0.553892 \t\t Validation loss: 0.518121\n",
            "BEST SCORE: 0.5181212925352157\n",
            "Training average batch accuracy: 0.716563\n",
            "Validation average batch accuracy: 0.744287\n",
            "Epoch 11: Loss: 0.535599 \t\t Validation loss: 0.523202\n",
            "Training average batch accuracy: 0.730500\n",
            "Validation average batch accuracy: 0.738721\n",
            "Epoch 12: Loss: 0.540591 \t\t Validation loss: 0.510802\n",
            "BEST SCORE: 0.510801811888814\n",
            "Training average batch accuracy: 0.726875\n",
            "Validation average batch accuracy: 0.751221\n",
            "Epoch 13: Loss: 0.538237 \t\t Validation loss: 0.501212\n",
            "BEST SCORE: 0.5012119229882955\n",
            "Training average batch accuracy: 0.730500\n",
            "Validation average batch accuracy: 0.753320\n",
            "Epoch 14: Loss: 0.526450 \t\t Validation loss: 0.501792\n",
            "Training average batch accuracy: 0.738688\n",
            "Validation average batch accuracy: 0.755957\n",
            "Epoch 15: Loss: 0.526641 \t\t Validation loss: 0.496418\n",
            "BEST SCORE: 0.496418129093945\n",
            "Training average batch accuracy: 0.736750\n",
            "Validation average batch accuracy: 0.754883\n",
            "Epoch 16: Loss: 0.519310 \t\t Validation loss: 0.488738\n",
            "BEST SCORE: 0.4887380232103169\n",
            "Training average batch accuracy: 0.742000\n",
            "Validation average batch accuracy: 0.760352\n",
            "Epoch 17: Loss: 0.522439 \t\t Validation loss: 0.496964\n",
            "Training average batch accuracy: 0.745125\n",
            "Validation average batch accuracy: 0.758057\n",
            "Epoch 18: Loss: 0.518235 \t\t Validation loss: 0.490739\n",
            "Training average batch accuracy: 0.744938\n",
            "Validation average batch accuracy: 0.764453\n",
            "Epoch 19: Loss: 0.511444 \t\t Validation loss: 0.487132\n",
            "BEST SCORE: 0.4871320036239922\n",
            "Training average batch accuracy: 0.746313\n",
            "Validation average batch accuracy: 0.767139\n",
            "Epoch 20: Loss: 0.512177 \t\t Validation loss: 0.485158\n",
            "BEST SCORE: 0.48515774505212905\n",
            "Training average batch accuracy: 0.745000\n",
            "Validation average batch accuracy: 0.767773\n",
            "Epoch 21: Loss: 0.514442 \t\t Validation loss: 0.482925\n",
            "BEST SCORE: 0.48292462192475794\n",
            "Training average batch accuracy: 0.749438\n",
            "Validation average batch accuracy: 0.770215\n",
            "Epoch 22: Loss: 0.497077 \t\t Validation loss: 0.483843\n",
            "Training average batch accuracy: 0.761188\n",
            "Validation average batch accuracy: 0.767041\n",
            "Epoch 23: Loss: 0.499007 \t\t Validation loss: 0.474909\n",
            "BEST SCORE: 0.47490933956578374\n",
            "Training average batch accuracy: 0.759125\n",
            "Validation average batch accuracy: 0.771729\n",
            "Epoch 24: Loss: 0.495512 \t\t Validation loss: 0.476683\n",
            "Training average batch accuracy: 0.758688\n",
            "Validation average batch accuracy: 0.770508\n",
            "Epoch 25: Loss: 0.492099 \t\t Validation loss: 0.476272\n",
            "Training average batch accuracy: 0.758188\n",
            "Validation average batch accuracy: 0.772217\n",
            "Epoch 26: Loss: 0.508208 \t\t Validation loss: 0.477021\n",
            "Training average batch accuracy: 0.752313\n",
            "Validation average batch accuracy: 0.772754\n",
            "Epoch 27: Loss: 0.502001 \t\t Validation loss: 0.474668\n",
            "BEST SCORE: 0.47466754969209435\n",
            "Training average batch accuracy: 0.758750\n",
            "Validation average batch accuracy: 0.774414\n",
            "Epoch 28: Loss: 0.500910 \t\t Validation loss: 0.469871\n",
            "BEST SCORE: 0.4698708713054657\n",
            "Training average batch accuracy: 0.760375\n",
            "Validation average batch accuracy: 0.780273\n",
            "Epoch 29: Loss: 0.491724 \t\t Validation loss: 0.462446\n",
            "BEST SCORE: 0.46244647409766915\n",
            "Training average batch accuracy: 0.764688\n",
            "Validation average batch accuracy: 0.780420\n",
            "Epoch 30: Loss: 0.488763 \t\t Validation loss: 0.463054\n",
            "Training average batch accuracy: 0.766875\n",
            "Validation average batch accuracy: 0.782178\n",
            "Epoch 31: Loss: 0.487109 \t\t Validation loss: 0.461867\n",
            "BEST SCORE: 0.4618673285469413\n",
            "Training average batch accuracy: 0.765938\n",
            "Validation average batch accuracy: 0.781104\n",
            "Epoch 32: Loss: 0.486897 \t\t Validation loss: 0.465750\n",
            "Training average batch accuracy: 0.767625\n",
            "Validation average batch accuracy: 0.777783\n",
            "Epoch 33: Loss: 0.485315 \t\t Validation loss: 0.452180\n",
            "BEST SCORE: 0.4521801174618304\n",
            "Training average batch accuracy: 0.765750\n",
            "Validation average batch accuracy: 0.786182\n",
            "Epoch 34: Loss: 0.484366 \t\t Validation loss: 0.462195\n",
            "Training average batch accuracy: 0.767438\n",
            "Validation average batch accuracy: 0.781104\n",
            "Epoch 35: Loss: 0.483458 \t\t Validation loss: 0.457063\n",
            "Training average batch accuracy: 0.770438\n",
            "Validation average batch accuracy: 0.787158\n",
            "Epoch 36: Loss: 0.483381 \t\t Validation loss: 0.465338\n",
            "Training average batch accuracy: 0.771313\n",
            "Validation average batch accuracy: 0.783789\n",
            "Epoch 37: Loss: 0.492794 \t\t Validation loss: 0.461794\n",
            "Training average batch accuracy: 0.765938\n",
            "Validation average batch accuracy: 0.783594\n",
            "Epoch 38: Loss: 0.480991 \t\t Validation loss: 0.458092\n",
            "Training average batch accuracy: 0.771188\n",
            "Validation average batch accuracy: 0.782520\n",
            "Epoch 39: Loss: 0.478870 \t\t Validation loss: 0.452628\n",
            "Training average batch accuracy: 0.771438\n",
            "Validation average batch accuracy: 0.787402\n",
            "Epoch 40: Loss: 0.473485 \t\t Validation loss: 0.450544\n",
            "BEST SCORE: 0.4505441254936159\n",
            "Training average batch accuracy: 0.777625\n",
            "Validation average batch accuracy: 0.785937\n",
            "Epoch 41: Loss: 0.473147 \t\t Validation loss: 0.453844\n",
            "Training average batch accuracy: 0.777313\n",
            "Validation average batch accuracy: 0.787744\n",
            "Epoch 42: Loss: 0.474838 \t\t Validation loss: 0.462123\n",
            "Training average batch accuracy: 0.774563\n",
            "Validation average batch accuracy: 0.785986\n",
            "Epoch 43: Loss: 0.473852 \t\t Validation loss: 0.450973\n",
            "Training average batch accuracy: 0.775188\n",
            "Validation average batch accuracy: 0.789551\n",
            "Epoch 44: Loss: 0.467232 \t\t Validation loss: 0.449582\n",
            "BEST SCORE: 0.4495815412141383\n",
            "Training average batch accuracy: 0.778938\n",
            "Validation average batch accuracy: 0.791211\n",
            "Epoch 45: Loss: 0.474684 \t\t Validation loss: 0.450117\n",
            "Training average batch accuracy: 0.776500\n",
            "Validation average batch accuracy: 0.791455\n",
            "Epoch 46: Loss: 0.469096 \t\t Validation loss: 0.445563\n",
            "BEST SCORE: 0.44556252704933286\n",
            "Training average batch accuracy: 0.778563\n",
            "Validation average batch accuracy: 0.792188\n",
            "Epoch 47: Loss: 0.464796 \t\t Validation loss: 0.439155\n",
            "BEST SCORE: 0.4391551117412746\n",
            "Training average batch accuracy: 0.779000\n",
            "Validation average batch accuracy: 0.793164\n",
            "Epoch 48: Loss: 0.469943 \t\t Validation loss: 0.448793\n",
            "Training average batch accuracy: 0.777188\n",
            "Validation average batch accuracy: 0.791748\n",
            "Epoch 49: Loss: 0.470274 \t\t Validation loss: 0.444335\n",
            "Training average batch accuracy: 0.783375\n",
            "Validation average batch accuracy: 0.798145\n",
            "Epoch 50: Loss: 0.466396 \t\t Validation loss: 0.446037\n",
            "Training average batch accuracy: 0.780438\n",
            "Validation average batch accuracy: 0.791455\n",
            "Epoch 51: Loss: 0.466706 \t\t Validation loss: 0.433830\n",
            "BEST SCORE: 0.4338304807431996\n",
            "Training average batch accuracy: 0.777938\n",
            "Validation average batch accuracy: 0.802539\n",
            "Epoch 52: Loss: 0.465809 \t\t Validation loss: 0.445760\n",
            "Training average batch accuracy: 0.783375\n",
            "Validation average batch accuracy: 0.794629\n",
            "Epoch 53: Loss: 0.461897 \t\t Validation loss: 0.439385\n",
            "Training average batch accuracy: 0.782688\n",
            "Validation average batch accuracy: 0.795752\n",
            "Epoch 54: Loss: 0.464946 \t\t Validation loss: 0.441937\n",
            "Training average batch accuracy: 0.778250\n",
            "Validation average batch accuracy: 0.795654\n",
            "Epoch 55: Loss: 0.461076 \t\t Validation loss: 0.437180\n",
            "Training average batch accuracy: 0.784375\n",
            "Validation average batch accuracy: 0.797510\n",
            "Epoch 56: Loss: 0.463938 \t\t Validation loss: 0.436889\n",
            "Training average batch accuracy: 0.782875\n",
            "Validation average batch accuracy: 0.791650\n",
            "Epoch 57: Loss: 0.452663 \t\t Validation loss: 0.444863\n",
            "Training average batch accuracy: 0.787875\n",
            "Validation average batch accuracy: 0.798145\n",
            "Epoch 58: Loss: 0.456308 \t\t Validation loss: 0.435549\n",
            "Training average batch accuracy: 0.789688\n",
            "Validation average batch accuracy: 0.798584\n",
            "Epoch 59: Loss: 0.456230 \t\t Validation loss: 0.429377\n",
            "BEST SCORE: 0.4293768304865807\n",
            "Training average batch accuracy: 0.788688\n",
            "Validation average batch accuracy: 0.802148\n",
            "Epoch 60: Loss: 0.453324 \t\t Validation loss: 0.431536\n",
            "Training average batch accuracy: 0.787563\n",
            "Validation average batch accuracy: 0.805273\n",
            "Epoch 61: Loss: 0.455760 \t\t Validation loss: 0.437642\n",
            "Training average batch accuracy: 0.791313\n",
            "Validation average batch accuracy: 0.795313\n",
            "Epoch 62: Loss: 0.450941 \t\t Validation loss: 0.431763\n",
            "Training average batch accuracy: 0.791500\n",
            "Validation average batch accuracy: 0.802100\n",
            "Epoch 63: Loss: 0.451858 \t\t Validation loss: 0.439840\n",
            "Training average batch accuracy: 0.790125\n",
            "Validation average batch accuracy: 0.796338\n",
            "Epoch 64: Loss: 0.453457 \t\t Validation loss: 0.432828\n",
            "Training average batch accuracy: 0.788375\n",
            "Validation average batch accuracy: 0.801514\n",
            "Epoch 65: Loss: 0.446987 \t\t Validation loss: 0.426486\n",
            "BEST SCORE: 0.42648606216534973\n",
            "Training average batch accuracy: 0.793688\n",
            "Validation average batch accuracy: 0.807178\n",
            "Epoch 66: Loss: 0.449514 \t\t Validation loss: 0.435742\n",
            "Training average batch accuracy: 0.795188\n",
            "Validation average batch accuracy: 0.796582\n",
            "Epoch 67: Loss: 0.444318 \t\t Validation loss: 0.426202\n",
            "BEST SCORE: 0.42620207769796253\n",
            "Training average batch accuracy: 0.794875\n",
            "Validation average batch accuracy: 0.804492\n",
            "Epoch 68: Loss: 0.447881 \t\t Validation loss: 0.427752\n",
            "Training average batch accuracy: 0.796500\n",
            "Validation average batch accuracy: 0.803369\n",
            "Epoch 69: Loss: 0.445647 \t\t Validation loss: 0.429385\n",
            "Training average batch accuracy: 0.795188\n",
            "Validation average batch accuracy: 0.804492\n",
            "Epoch 70: Loss: 0.459613 \t\t Validation loss: 0.423461\n",
            "BEST SCORE: 0.423461288632825\n",
            "Training average batch accuracy: 0.785688\n",
            "Validation average batch accuracy: 0.809717\n",
            "Epoch 71: Loss: 0.445402 \t\t Validation loss: 0.414913\n",
            "BEST SCORE: 0.4149129897356033\n",
            "Training average batch accuracy: 0.793750\n",
            "Validation average batch accuracy: 0.814648\n",
            "Epoch 72: Loss: 0.442151 \t\t Validation loss: 0.427241\n",
            "Training average batch accuracy: 0.797750\n",
            "Validation average batch accuracy: 0.807422\n",
            "Epoch 73: Loss: 0.451922 \t\t Validation loss: 0.423347\n",
            "Training average batch accuracy: 0.790250\n",
            "Validation average batch accuracy: 0.808887\n",
            "Epoch 74: Loss: 0.446382 \t\t Validation loss: 0.425754\n",
            "Training average batch accuracy: 0.796375\n",
            "Validation average batch accuracy: 0.804639\n",
            "Epoch 75: Loss: 0.439069 \t\t Validation loss: 0.421411\n",
            "Training average batch accuracy: 0.797938\n",
            "Validation average batch accuracy: 0.804492\n",
            "Epoch 76: Loss: 0.440849 \t\t Validation loss: 0.418463\n",
            "Training average batch accuracy: 0.797625\n",
            "Validation average batch accuracy: 0.810156\n",
            "Epoch 77: Loss: 0.436927 \t\t Validation loss: 0.417115\n",
            "Training average batch accuracy: 0.798000\n",
            "Validation average batch accuracy: 0.810449\n",
            "Epoch 78: Loss: 0.437813 \t\t Validation loss: 0.413833\n",
            "BEST SCORE: 0.4138327086344361\n",
            "Training average batch accuracy: 0.800938\n",
            "Validation average batch accuracy: 0.812451\n",
            "Epoch 79: Loss: 0.435714 \t\t Validation loss: 0.423679\n",
            "Training average batch accuracy: 0.802813\n",
            "Validation average batch accuracy: 0.811328\n",
            "Epoch 80: Loss: 0.440921 \t\t Validation loss: 0.413603\n",
            "BEST SCORE: 0.4136030192486942\n",
            "Training average batch accuracy: 0.797563\n",
            "Validation average batch accuracy: 0.813818\n",
            "Epoch 81: Loss: 0.438509 \t\t Validation loss: 0.419410\n",
            "Training average batch accuracy: 0.797313\n",
            "Validation average batch accuracy: 0.810107\n",
            "Epoch 82: Loss: 0.438814 \t\t Validation loss: 0.421746\n",
            "Training average batch accuracy: 0.800500\n",
            "Validation average batch accuracy: 0.809814\n",
            "Epoch 83: Loss: 0.432984 \t\t Validation loss: 0.426535\n",
            "Training average batch accuracy: 0.802875\n",
            "Validation average batch accuracy: 0.802051\n",
            "Epoch 84: Loss: 0.432649 \t\t Validation loss: 0.415194\n",
            "Training average batch accuracy: 0.803250\n",
            "Validation average batch accuracy: 0.814893\n",
            "Epoch 85: Loss: 0.440140 \t\t Validation loss: 0.418128\n",
            "Training average batch accuracy: 0.798125\n",
            "Validation average batch accuracy: 0.808057\n",
            "Epoch 86: Loss: 0.433109 \t\t Validation loss: 0.413512\n",
            "BEST SCORE: 0.41351150153204796\n",
            "Training average batch accuracy: 0.802750\n",
            "Validation average batch accuracy: 0.809814\n",
            "Epoch 87: Loss: 0.434947 \t\t Validation loss: 0.423258\n",
            "Training average batch accuracy: 0.800875\n",
            "Validation average batch accuracy: 0.810205\n",
            "Epoch 88: Loss: 0.431612 \t\t Validation loss: 0.410603\n",
            "BEST SCORE: 0.4106025218497962\n",
            "Training average batch accuracy: 0.803750\n",
            "Validation average batch accuracy: 0.813770\n",
            "Epoch 89: Loss: 0.434033 \t\t Validation loss: 0.420983\n",
            "Training average batch accuracy: 0.801875\n",
            "Validation average batch accuracy: 0.810791\n",
            "Epoch 90: Loss: 0.429321 \t\t Validation loss: 0.418268\n",
            "Training average batch accuracy: 0.804500\n",
            "Validation average batch accuracy: 0.807861\n",
            "Epoch 91: Loss: 0.440801 \t\t Validation loss: 0.409715\n",
            "BEST SCORE: 0.4097151917871088\n",
            "Training average batch accuracy: 0.798813\n",
            "Validation average batch accuracy: 0.815723\n",
            "Epoch 92: Loss: 0.425859 \t\t Validation loss: 0.413190\n",
            "Training average batch accuracy: 0.806313\n",
            "Validation average batch accuracy: 0.812891\n",
            "Epoch 93: Loss: 0.436334 \t\t Validation loss: 0.410680\n",
            "Training average batch accuracy: 0.800438\n",
            "Validation average batch accuracy: 0.817285\n",
            "Epoch 94: Loss: 0.434265 \t\t Validation loss: 0.414616\n",
            "Training average batch accuracy: 0.800313\n",
            "Validation average batch accuracy: 0.813916\n",
            "Epoch 95: Loss: 0.424897 \t\t Validation loss: 0.409166\n",
            "BEST SCORE: 0.4091664628824219\n",
            "Training average batch accuracy: 0.809750\n",
            "Validation average batch accuracy: 0.814111\n",
            "Epoch 96: Loss: 0.423189 \t\t Validation loss: 0.414263\n",
            "Training average batch accuracy: 0.810688\n",
            "Validation average batch accuracy: 0.812402\n",
            "Epoch 97: Loss: 0.427606 \t\t Validation loss: 0.409642\n",
            "Training average batch accuracy: 0.806063\n",
            "Validation average batch accuracy: 0.815772\n",
            "Epoch 98: Loss: 0.431331 \t\t Validation loss: 0.409603\n",
            "Training average batch accuracy: 0.807938\n",
            "Validation average batch accuracy: 0.815576\n",
            "Epoch 99: Loss: 0.424423 \t\t Validation loss: 0.409243\n",
            "Training average batch accuracy: 0.806938\n",
            "Validation average batch accuracy: 0.818896\n",
            "Epoch 100: Loss: 0.427893 \t\t Validation loss: 0.402976\n",
            "BEST SCORE: 0.4029762559104711\n",
            "Training average batch accuracy: 0.803000\n",
            "Validation average batch accuracy: 0.817822\n",
            "Epoch 101: Loss: 0.433300 \t\t Validation loss: 0.395990\n",
            "BEST SCORE: 0.39599006292410194\n",
            "Training average batch accuracy: 0.799625\n",
            "Validation average batch accuracy: 0.823145\n",
            "Epoch 102: Loss: 0.425921 \t\t Validation loss: 0.404016\n",
            "Training average batch accuracy: 0.806500\n",
            "Validation average batch accuracy: 0.819922\n",
            "Epoch 103: Loss: 0.435332 \t\t Validation loss: 0.411375\n",
            "Training average batch accuracy: 0.798813\n",
            "Validation average batch accuracy: 0.812158\n",
            "Epoch 104: Loss: 0.421386 \t\t Validation loss: 0.415607\n",
            "Training average batch accuracy: 0.810688\n",
            "Validation average batch accuracy: 0.815088\n",
            "Epoch 105: Loss: 0.422703 \t\t Validation loss: 0.403887\n",
            "Training average batch accuracy: 0.807375\n",
            "Validation average batch accuracy: 0.821924\n",
            "Epoch 106: Loss: 0.425716 \t\t Validation loss: 0.397023\n",
            "Training average batch accuracy: 0.810625\n",
            "Validation average batch accuracy: 0.822900\n",
            "Epoch 107: Loss: 0.426171 \t\t Validation loss: 0.399109\n",
            "Training average batch accuracy: 0.810500\n",
            "Validation average batch accuracy: 0.821973\n",
            "Epoch 108: Loss: 0.424308 \t\t Validation loss: 0.410773\n",
            "Training average batch accuracy: 0.808688\n",
            "Validation average batch accuracy: 0.817236\n",
            "Epoch 109: Loss: 0.428673 \t\t Validation loss: 0.395362\n",
            "BEST SCORE: 0.3953621727414429\n",
            "Training average batch accuracy: 0.805563\n",
            "Validation average batch accuracy: 0.821729\n",
            "Epoch 110: Loss: 0.429901 \t\t Validation loss: 0.404803\n",
            "Training average batch accuracy: 0.803313\n",
            "Validation average batch accuracy: 0.817139\n",
            "Epoch 111: Loss: 0.423435 \t\t Validation loss: 0.405856\n",
            "Training average batch accuracy: 0.804563\n",
            "Validation average batch accuracy: 0.817920\n",
            "Epoch 112: Loss: 0.430870 \t\t Validation loss: 0.399199\n",
            "Training average batch accuracy: 0.805813\n",
            "Validation average batch accuracy: 0.821387\n",
            "Epoch 113: Loss: 0.416619 \t\t Validation loss: 0.400460\n",
            "Training average batch accuracy: 0.813625\n",
            "Validation average batch accuracy: 0.819727\n",
            "Epoch 114: Loss: 0.414056 \t\t Validation loss: 0.399342\n",
            "Training average batch accuracy: 0.812500\n",
            "Validation average batch accuracy: 0.819580\n",
            "Epoch 115: Loss: 0.416874 \t\t Validation loss: 0.402239\n",
            "Training average batch accuracy: 0.814188\n",
            "Validation average batch accuracy: 0.820996\n",
            "Epoch 116: Loss: 0.418450 \t\t Validation loss: 0.406438\n",
            "Training average batch accuracy: 0.811625\n",
            "Validation average batch accuracy: 0.816650\n",
            "Epoch 117: Loss: 0.430072 \t\t Validation loss: 0.402313\n",
            "Training average batch accuracy: 0.803938\n",
            "Validation average batch accuracy: 0.820410\n",
            "Epoch 118: Loss: 0.412833 \t\t Validation loss: 0.403987\n",
            "Training average batch accuracy: 0.814938\n",
            "Validation average batch accuracy: 0.819775\n",
            "Epoch 119: Loss: 0.430441 \t\t Validation loss: 0.394650\n",
            "BEST SCORE: 0.394650170719251\n",
            "Training average batch accuracy: 0.804813\n",
            "Validation average batch accuracy: 0.826611\n",
            "Epoch 120: Loss: 0.419804 \t\t Validation loss: 0.396991\n",
            "Training average batch accuracy: 0.812250\n",
            "Validation average batch accuracy: 0.820166\n",
            "Epoch 121: Loss: 0.418136 \t\t Validation loss: 0.403442\n",
            "Training average batch accuracy: 0.810313\n",
            "Validation average batch accuracy: 0.815869\n",
            "Epoch 122: Loss: 0.418243 \t\t Validation loss: 0.398661\n",
            "Training average batch accuracy: 0.810188\n",
            "Validation average batch accuracy: 0.820361\n",
            "Epoch 123: Loss: 0.409442 \t\t Validation loss: 0.407949\n",
            "Training average batch accuracy: 0.815125\n",
            "Validation average batch accuracy: 0.814258\n",
            "Epoch 124: Loss: 0.418492 \t\t Validation loss: 0.400960\n",
            "Training average batch accuracy: 0.810375\n",
            "Validation average batch accuracy: 0.822266\n",
            "Epoch 125: Loss: 0.409828 \t\t Validation loss: 0.392514\n",
            "BEST SCORE: 0.39251375435851515\n",
            "Training average batch accuracy: 0.811688\n",
            "Validation average batch accuracy: 0.826611\n",
            "Epoch 126: Loss: 0.420015 \t\t Validation loss: 0.396526\n",
            "Training average batch accuracy: 0.808875\n",
            "Validation average batch accuracy: 0.824219\n",
            "Epoch 127: Loss: 0.413639 \t\t Validation loss: 0.391404\n",
            "BEST SCORE: 0.39140423722565176\n",
            "Training average batch accuracy: 0.812375\n",
            "Validation average batch accuracy: 0.826318\n",
            "Epoch 128: Loss: 0.406191 \t\t Validation loss: 0.397787\n",
            "Training average batch accuracy: 0.818313\n",
            "Validation average batch accuracy: 0.820312\n",
            "Epoch 129: Loss: 0.408016 \t\t Validation loss: 0.402448\n",
            "Training average batch accuracy: 0.818813\n",
            "Validation average batch accuracy: 0.821143\n",
            "Epoch 130: Loss: 0.414524 \t\t Validation loss: 0.400726\n",
            "Training average batch accuracy: 0.814625\n",
            "Validation average batch accuracy: 0.820410\n",
            "Epoch 131: Loss: 0.420310 \t\t Validation loss: 0.402104\n",
            "Training average batch accuracy: 0.810438\n",
            "Validation average batch accuracy: 0.819727\n",
            "Epoch 132: Loss: 0.411048 \t\t Validation loss: 0.396666\n",
            "Training average batch accuracy: 0.815063\n",
            "Validation average batch accuracy: 0.825684\n",
            "Epoch 133: Loss: 0.413851 \t\t Validation loss: 0.392804\n",
            "Training average batch accuracy: 0.811750\n",
            "Validation average batch accuracy: 0.826563\n",
            "Epoch 134: Loss: 0.409039 \t\t Validation loss: 0.397021\n",
            "Training average batch accuracy: 0.818813\n",
            "Validation average batch accuracy: 0.824854\n",
            "Epoch 135: Loss: 0.400626 \t\t Validation loss: 0.393644\n",
            "Training average batch accuracy: 0.822938\n",
            "Validation average batch accuracy: 0.825098\n",
            "Epoch 136: Loss: 0.411310 \t\t Validation loss: 0.397688\n",
            "Training average batch accuracy: 0.816625\n",
            "Validation average batch accuracy: 0.821729\n",
            "Epoch 137: Loss: 0.410276 \t\t Validation loss: 0.396709\n",
            "Training average batch accuracy: 0.816125\n",
            "Validation average batch accuracy: 0.823193\n",
            "Epoch 138: Loss: 0.412697 \t\t Validation loss: 0.396768\n",
            "Training average batch accuracy: 0.816188\n",
            "Epoch   139: reducing learning rate of group 0 to 9.0000e-05.\n",
            "Validation average batch accuracy: 0.820801\n",
            "Epoch 139: Loss: 0.408314 \t\t Validation loss: 0.393702\n",
            "Training average batch accuracy: 0.818000\n",
            "Validation average batch accuracy: 0.823486\n",
            "Epoch 140: Loss: 0.408980 \t\t Validation loss: 0.383543\n",
            "BEST SCORE: 0.3835432821884751\n",
            "Training average batch accuracy: 0.817938\n",
            "Validation average batch accuracy: 0.831934\n",
            "Epoch 141: Loss: 0.403265 \t\t Validation loss: 0.388980\n",
            "Training average batch accuracy: 0.822188\n",
            "Validation average batch accuracy: 0.826611\n",
            "Epoch 142: Loss: 0.406872 \t\t Validation loss: 0.388619\n",
            "Training average batch accuracy: 0.817000\n",
            "Validation average batch accuracy: 0.831787\n",
            "Epoch 143: Loss: 0.399978 \t\t Validation loss: 0.384801\n",
            "Training average batch accuracy: 0.820625\n",
            "Validation average batch accuracy: 0.830029\n",
            "Epoch 144: Loss: 0.405095 \t\t Validation loss: 0.381446\n",
            "BEST SCORE: 0.38144639544188974\n",
            "Training average batch accuracy: 0.818938\n",
            "Validation average batch accuracy: 0.829004\n",
            "Epoch 145: Loss: 0.405619 \t\t Validation loss: 0.384728\n",
            "Training average batch accuracy: 0.819688\n",
            "Validation average batch accuracy: 0.831494\n",
            "Epoch 146: Loss: 0.396922 \t\t Validation loss: 0.387416\n",
            "Training average batch accuracy: 0.823875\n",
            "Validation average batch accuracy: 0.829785\n",
            "Epoch 147: Loss: 0.398453 \t\t Validation loss: 0.384728\n",
            "Training average batch accuracy: 0.826000\n",
            "Validation average batch accuracy: 0.831787\n",
            "Epoch 148: Loss: 0.395904 \t\t Validation loss: 0.383901\n",
            "Training average batch accuracy: 0.824438\n",
            "Validation average batch accuracy: 0.830176\n",
            "Epoch 149: Loss: 0.399167 \t\t Validation loss: 0.387085\n",
            "Training average batch accuracy: 0.818875\n",
            "Validation average batch accuracy: 0.830127\n",
            "Epoch 150: Loss: 0.404266 \t\t Validation loss: 0.386276\n",
            "Training average batch accuracy: 0.820500\n",
            "Validation average batch accuracy: 0.826953\n",
            "Epoch 151: Loss: 0.401591 \t\t Validation loss: 0.387665\n",
            "Training average batch accuracy: 0.820750\n",
            "Validation average batch accuracy: 0.828369\n",
            "Epoch 152: Loss: 0.400766 \t\t Validation loss: 0.388501\n",
            "Training average batch accuracy: 0.822813\n",
            "Validation average batch accuracy: 0.830029\n",
            "Epoch 153: Loss: 0.393999 \t\t Validation loss: 0.383929\n",
            "Training average batch accuracy: 0.821250\n",
            "Validation average batch accuracy: 0.827393\n",
            "Epoch 154: Loss: 0.398598 \t\t Validation loss: 0.392326\n",
            "Training average batch accuracy: 0.823625\n",
            "Validation average batch accuracy: 0.825146\n",
            "Epoch 155: Loss: 0.394849 \t\t Validation loss: 0.384698\n",
            "Training average batch accuracy: 0.826750\n",
            "Epoch   156: reducing learning rate of group 0 to 8.1000e-05.\n",
            "Validation average batch accuracy: 0.827783\n",
            "Epoch 156: Loss: 0.400394 \t\t Validation loss: 0.389448\n",
            "Training average batch accuracy: 0.821625\n",
            "Validation average batch accuracy: 0.827490\n",
            "Epoch 157: Loss: 0.398312 \t\t Validation loss: 0.385866\n",
            "Training average batch accuracy: 0.823625\n",
            "Validation average batch accuracy: 0.828760\n",
            "Epoch 158: Loss: 0.394174 \t\t Validation loss: 0.375657\n",
            "BEST SCORE: 0.37565675941295923\n",
            "Training average batch accuracy: 0.825938\n",
            "Validation average batch accuracy: 0.837158\n",
            "Epoch 159: Loss: 0.390988 \t\t Validation loss: 0.380206\n",
            "Training average batch accuracy: 0.827313\n",
            "Validation average batch accuracy: 0.829932\n",
            "Epoch 160: Loss: 0.399259 \t\t Validation loss: 0.386047\n",
            "Training average batch accuracy: 0.821563\n",
            "Validation average batch accuracy: 0.828223\n",
            "Epoch 161: Loss: 0.390054 \t\t Validation loss: 0.369703\n",
            "BEST SCORE: 0.36970340120606127\n",
            "Training average batch accuracy: 0.827375\n",
            "Validation average batch accuracy: 0.839160\n",
            "Epoch 162: Loss: 0.392540 \t\t Validation loss: 0.381640\n",
            "Training average batch accuracy: 0.830063\n",
            "Validation average batch accuracy: 0.830957\n",
            "Epoch 163: Loss: 0.390257 \t\t Validation loss: 0.384481\n",
            "Training average batch accuracy: 0.826250\n",
            "Validation average batch accuracy: 0.831055\n",
            "Epoch 164: Loss: 0.392949 \t\t Validation loss: 0.377812\n",
            "Training average batch accuracy: 0.824563\n",
            "Validation average batch accuracy: 0.835986\n",
            "Epoch 165: Loss: 0.396670 \t\t Validation loss: 0.383661\n",
            "Training average batch accuracy: 0.822000\n",
            "Validation average batch accuracy: 0.829492\n",
            "Epoch 166: Loss: 0.395500 \t\t Validation loss: 0.375650\n",
            "Training average batch accuracy: 0.826688\n",
            "Validation average batch accuracy: 0.834961\n",
            "Epoch 167: Loss: 0.386221 \t\t Validation loss: 0.385796\n",
            "Training average batch accuracy: 0.829063\n",
            "Validation average batch accuracy: 0.828809\n",
            "Epoch 168: Loss: 0.389274 \t\t Validation loss: 0.369833\n",
            "Training average batch accuracy: 0.826750\n",
            "Validation average batch accuracy: 0.838867\n",
            "Epoch 169: Loss: 0.385235 \t\t Validation loss: 0.378274\n",
            "Training average batch accuracy: 0.828750\n",
            "Validation average batch accuracy: 0.835205\n",
            "Epoch 170: Loss: 0.378647 \t\t Validation loss: 0.374418\n",
            "Training average batch accuracy: 0.837250\n",
            "Validation average batch accuracy: 0.837646\n",
            "Epoch 171: Loss: 0.389844 \t\t Validation loss: 0.383166\n",
            "Training average batch accuracy: 0.829688\n",
            "Validation average batch accuracy: 0.830078\n",
            "Epoch 172: Loss: 0.382495 \t\t Validation loss: 0.380096\n",
            "Training average batch accuracy: 0.834875\n",
            "Epoch   173: reducing learning rate of group 0 to 7.2900e-05.\n",
            "Validation average batch accuracy: 0.833106\n",
            "Epoch 173: Loss: 0.380873 \t\t Validation loss: 0.378494\n",
            "Training average batch accuracy: 0.833688\n",
            "Validation average batch accuracy: 0.833789\n",
            "Epoch 174: Loss: 0.386841 \t\t Validation loss: 0.379050\n",
            "Training average batch accuracy: 0.831500\n",
            "Validation average batch accuracy: 0.836230\n",
            "Epoch 175: Loss: 0.387498 \t\t Validation loss: 0.381733\n",
            "Training average batch accuracy: 0.828875\n",
            "Validation average batch accuracy: 0.833350\n",
            "Epoch 176: Loss: 0.394768 \t\t Validation loss: 0.377737\n",
            "Training average batch accuracy: 0.820250\n",
            "Validation average batch accuracy: 0.831397\n",
            "Epoch 177: Loss: 0.379775 \t\t Validation loss: 0.373879\n",
            "Training average batch accuracy: 0.833875\n",
            "Validation average batch accuracy: 0.834814\n",
            "Epoch 178: Loss: 0.387741 \t\t Validation loss: 0.379903\n",
            "Training average batch accuracy: 0.827688\n",
            "Validation average batch accuracy: 0.833545\n",
            "Epoch 179: Loss: 0.384677 \t\t Validation loss: 0.375382\n",
            "Training average batch accuracy: 0.831188\n",
            "Validation average batch accuracy: 0.835107\n",
            "Epoch 180: Loss: 0.374368 \t\t Validation loss: 0.372474\n",
            "Training average batch accuracy: 0.835500\n",
            "Validation average batch accuracy: 0.839160\n",
            "Epoch 181: Loss: 0.388696 \t\t Validation loss: 0.371785\n",
            "Training average batch accuracy: 0.829250\n",
            "Validation average batch accuracy: 0.838184\n",
            "Epoch 182: Loss: 0.382397 \t\t Validation loss: 0.373775\n",
            "Training average batch accuracy: 0.832750\n",
            "Validation average batch accuracy: 0.835938\n",
            "Epoch 183: Loss: 0.381814 \t\t Validation loss: 0.381008\n",
            "Training average batch accuracy: 0.832375\n",
            "Epoch   184: reducing learning rate of group 0 to 6.5610e-05.\n",
            "Validation average batch accuracy: 0.830566\n",
            "Epoch 184: Loss: 0.376387 \t\t Validation loss: 0.375757\n",
            "Training average batch accuracy: 0.834813\n",
            "Validation average batch accuracy: 0.833691\n",
            "Epoch 185: Loss: 0.382282 \t\t Validation loss: 0.368224\n",
            "BEST SCORE: 0.3682240857742727\n",
            "Training average batch accuracy: 0.833500\n",
            "Validation average batch accuracy: 0.840918\n",
            "Epoch 186: Loss: 0.383957 \t\t Validation loss: 0.370326\n",
            "Training average batch accuracy: 0.831500\n",
            "Validation average batch accuracy: 0.836084\n",
            "Epoch 187: Loss: 0.383418 \t\t Validation loss: 0.372177\n",
            "Training average batch accuracy: 0.829875\n",
            "Validation average batch accuracy: 0.837500\n",
            "Epoch 188: Loss: 0.383108 \t\t Validation loss: 0.370893\n",
            "Training average batch accuracy: 0.833125\n",
            "Validation average batch accuracy: 0.838916\n",
            "Epoch 189: Loss: 0.381511 \t\t Validation loss: 0.383799\n",
            "Training average batch accuracy: 0.831875\n",
            "Validation average batch accuracy: 0.831934\n",
            "Epoch 190: Loss: 0.374479 \t\t Validation loss: 0.375689\n",
            "Training average batch accuracy: 0.836063\n",
            "Validation average batch accuracy: 0.837207\n",
            "Epoch 191: Loss: 0.381103 \t\t Validation loss: 0.366510\n",
            "BEST SCORE: 0.366510050278157\n",
            "Training average batch accuracy: 0.833625\n",
            "Validation average batch accuracy: 0.838330\n",
            "Epoch 192: Loss: 0.374753 \t\t Validation loss: 0.370912\n",
            "Training average batch accuracy: 0.837250\n",
            "Validation average batch accuracy: 0.835352\n",
            "Epoch 193: Loss: 0.378963 \t\t Validation loss: 0.363395\n",
            "BEST SCORE: 0.36339505049400034\n",
            "Training average batch accuracy: 0.834813\n",
            "Validation average batch accuracy: 0.844043\n",
            "Epoch 194: Loss: 0.370369 \t\t Validation loss: 0.375449\n",
            "Training average batch accuracy: 0.838125\n",
            "Validation average batch accuracy: 0.834570\n",
            "Epoch 195: Loss: 0.380249 \t\t Validation loss: 0.371580\n",
            "Training average batch accuracy: 0.832500\n",
            "Validation average batch accuracy: 0.838428\n",
            "Epoch 196: Loss: 0.366842 \t\t Validation loss: 0.373287\n",
            "Training average batch accuracy: 0.839938\n",
            "Validation average batch accuracy: 0.837305\n",
            "Epoch 197: Loss: 0.380711 \t\t Validation loss: 0.371992\n",
            "Training average batch accuracy: 0.834188\n",
            "Validation average batch accuracy: 0.837549\n",
            "Epoch 198: Loss: 0.374393 \t\t Validation loss: 0.372950\n",
            "Training average batch accuracy: 0.838125\n",
            "Validation average batch accuracy: 0.838330\n",
            "Epoch 199: Loss: 0.372929 \t\t Validation loss: 0.372351\n",
            "Training average batch accuracy: 0.836313\n",
            "Validation average batch accuracy: 0.836230\n",
            "Epoch 200: Loss: 0.374371 \t\t Validation loss: 0.362493\n",
            "BEST SCORE: 0.3624929106794298\n",
            "Training average batch accuracy: 0.837938\n",
            "Validation average batch accuracy: 0.841797\n",
            "Epoch 201: Loss: 0.380775 \t\t Validation loss: 0.367613\n",
            "Training average batch accuracy: 0.830875\n",
            "Validation average batch accuracy: 0.840137\n",
            "Epoch 202: Loss: 0.375134 \t\t Validation loss: 0.364626\n",
            "Training average batch accuracy: 0.835250\n",
            "Validation average batch accuracy: 0.841016\n",
            "Epoch 203: Loss: 0.373782 \t\t Validation loss: 0.371014\n",
            "Training average batch accuracy: 0.839250\n",
            "Validation average batch accuracy: 0.836572\n",
            "Epoch 204: Loss: 0.375528 \t\t Validation loss: 0.365816\n",
            "Training average batch accuracy: 0.837500\n",
            "Validation average batch accuracy: 0.838818\n",
            "Epoch 205: Loss: 0.378549 \t\t Validation loss: 0.371997\n",
            "Training average batch accuracy: 0.832938\n",
            "Validation average batch accuracy: 0.838330\n",
            "Epoch 206: Loss: 0.371347 \t\t Validation loss: 0.367354\n",
            "Training average batch accuracy: 0.840125\n",
            "Validation average batch accuracy: 0.842041\n",
            "Epoch 207: Loss: 0.367324 \t\t Validation loss: 0.372073\n",
            "Training average batch accuracy: 0.838438\n",
            "Validation average batch accuracy: 0.837451\n",
            "Epoch 208: Loss: 0.372626 \t\t Validation loss: 0.367683\n",
            "Training average batch accuracy: 0.836375\n",
            "Validation average batch accuracy: 0.841357\n",
            "Epoch 209: Loss: 0.368558 \t\t Validation loss: 0.371404\n",
            "Training average batch accuracy: 0.841438\n",
            "Validation average batch accuracy: 0.835449\n",
            "Epoch 210: Loss: 0.370355 \t\t Validation loss: 0.369147\n",
            "Training average batch accuracy: 0.839688\n",
            "Validation average batch accuracy: 0.840186\n",
            "Epoch 211: Loss: 0.377103 \t\t Validation loss: 0.361653\n",
            "BEST SCORE: 0.3616526891011745\n",
            "Training average batch accuracy: 0.832188\n",
            "Validation average batch accuracy: 0.845508\n",
            "Epoch 212: Loss: 0.375913 \t\t Validation loss: 0.371822\n",
            "Training average batch accuracy: 0.835500\n",
            "Validation average batch accuracy: 0.838477\n",
            "Epoch 213: Loss: 0.376869 \t\t Validation loss: 0.358029\n",
            "BEST SCORE: 0.3580288581550121\n",
            "Training average batch accuracy: 0.838188\n",
            "Validation average batch accuracy: 0.846143\n",
            "Epoch 214: Loss: 0.366370 \t\t Validation loss: 0.365180\n",
            "Training average batch accuracy: 0.841313\n",
            "Validation average batch accuracy: 0.843848\n",
            "Epoch 215: Loss: 0.371028 \t\t Validation loss: 0.369376\n",
            "Training average batch accuracy: 0.840188\n",
            "Validation average batch accuracy: 0.843066\n",
            "Epoch 216: Loss: 0.368286 \t\t Validation loss: 0.363778\n",
            "Training average batch accuracy: 0.841625\n",
            "Validation average batch accuracy: 0.839844\n",
            "Epoch 217: Loss: 0.372309 \t\t Validation loss: 0.363113\n",
            "Training average batch accuracy: 0.834750\n",
            "Validation average batch accuracy: 0.843506\n",
            "Epoch 218: Loss: 0.365779 \t\t Validation loss: 0.364706\n",
            "Training average batch accuracy: 0.843313\n",
            "Validation average batch accuracy: 0.840625\n",
            "Epoch 219: Loss: 0.365143 \t\t Validation loss: 0.366825\n",
            "Training average batch accuracy: 0.845938\n",
            "Validation average batch accuracy: 0.841650\n",
            "Epoch 220: Loss: 0.365973 \t\t Validation loss: 0.360483\n",
            "Training average batch accuracy: 0.841313\n",
            "Validation average batch accuracy: 0.841455\n",
            "Epoch 221: Loss: 0.365056 \t\t Validation loss: 0.365735\n",
            "Training average batch accuracy: 0.839125\n",
            "Validation average batch accuracy: 0.842969\n",
            "Epoch 222: Loss: 0.363019 \t\t Validation loss: 0.363438\n",
            "Training average batch accuracy: 0.842563\n",
            "Validation average batch accuracy: 0.839844\n",
            "Epoch 223: Loss: 0.361828 \t\t Validation loss: 0.365932\n",
            "Training average batch accuracy: 0.845750\n",
            "Validation average batch accuracy: 0.840479\n",
            "Epoch 224: Loss: 0.369726 \t\t Validation loss: 0.364737\n",
            "Training average batch accuracy: 0.839375\n",
            "Epoch   225: reducing learning rate of group 0 to 5.9049e-05.\n",
            "Validation average batch accuracy: 0.840820\n",
            "Epoch 225: Loss: 0.366583 \t\t Validation loss: 0.364636\n",
            "Training average batch accuracy: 0.839813\n",
            "Validation average batch accuracy: 0.839502\n",
            "Epoch 226: Loss: 0.357434 \t\t Validation loss: 0.365685\n",
            "Training average batch accuracy: 0.844813\n",
            "Validation average batch accuracy: 0.840967\n",
            "Epoch 227: Loss: 0.375263 \t\t Validation loss: 0.366981\n",
            "Training average batch accuracy: 0.836688\n",
            "Validation average batch accuracy: 0.837402\n",
            "Epoch 228: Loss: 0.365925 \t\t Validation loss: 0.363697\n",
            "Training average batch accuracy: 0.842938\n",
            "Validation average batch accuracy: 0.839014\n",
            "Epoch 229: Loss: 0.366894 \t\t Validation loss: 0.353652\n",
            "BEST SCORE: 0.3536520454566926\n",
            "Training average batch accuracy: 0.843563\n",
            "Validation average batch accuracy: 0.847852\n",
            "Epoch 230: Loss: 0.359659 \t\t Validation loss: 0.362529\n",
            "Training average batch accuracy: 0.840875\n",
            "Validation average batch accuracy: 0.841748\n",
            "Epoch 231: Loss: 0.370875 \t\t Validation loss: 0.352794\n",
            "BEST SCORE: 0.3527941081672907\n",
            "Training average batch accuracy: 0.839625\n",
            "Validation average batch accuracy: 0.846045\n",
            "Epoch 232: Loss: 0.358086 \t\t Validation loss: 0.367763\n",
            "Training average batch accuracy: 0.845938\n",
            "Validation average batch accuracy: 0.839648\n",
            "Epoch 233: Loss: 0.369704 \t\t Validation loss: 0.356489\n",
            "Training average batch accuracy: 0.840438\n",
            "Validation average batch accuracy: 0.846826\n",
            "Epoch 234: Loss: 0.366139 \t\t Validation loss: 0.365855\n",
            "Training average batch accuracy: 0.843063\n",
            "Validation average batch accuracy: 0.839697\n",
            "Epoch 235: Loss: 0.359600 \t\t Validation loss: 0.356721\n",
            "Training average batch accuracy: 0.846188\n",
            "Validation average batch accuracy: 0.844775\n",
            "Epoch 236: Loss: 0.359288 \t\t Validation loss: 0.365452\n",
            "Training average batch accuracy: 0.845125\n",
            "Validation average batch accuracy: 0.842480\n",
            "Epoch 237: Loss: 0.367381 \t\t Validation loss: 0.362182\n",
            "Training average batch accuracy: 0.841250\n",
            "Validation average batch accuracy: 0.841797\n",
            "Epoch 238: Loss: 0.360347 \t\t Validation loss: 0.359932\n",
            "Training average batch accuracy: 0.844063\n",
            "Validation average batch accuracy: 0.843018\n",
            "Epoch 239: Loss: 0.363987 \t\t Validation loss: 0.365422\n",
            "Training average batch accuracy: 0.842875\n",
            "Validation average batch accuracy: 0.842432\n",
            "Epoch 240: Loss: 0.360257 \t\t Validation loss: 0.359097\n",
            "Training average batch accuracy: 0.845813\n",
            "Validation average batch accuracy: 0.845313\n",
            "Epoch 241: Loss: 0.357458 \t\t Validation loss: 0.366834\n",
            "Training average batch accuracy: 0.847625\n",
            "Validation average batch accuracy: 0.839795\n",
            "Epoch 242: Loss: 0.356706 \t\t Validation loss: 0.360692\n",
            "Training average batch accuracy: 0.845375\n",
            "Epoch   243: reducing learning rate of group 0 to 5.3144e-05.\n",
            "Validation average batch accuracy: 0.842139\n",
            "Epoch 243: Loss: 0.355171 \t\t Validation loss: 0.355502\n",
            "Training average batch accuracy: 0.846750\n",
            "Validation average batch accuracy: 0.845020\n",
            "Epoch 244: Loss: 0.363657 \t\t Validation loss: 0.356039\n",
            "Training average batch accuracy: 0.843000\n",
            "Validation average batch accuracy: 0.843408\n",
            "Epoch 245: Loss: 0.360343 \t\t Validation loss: 0.363658\n",
            "Training average batch accuracy: 0.843313\n",
            "Validation average batch accuracy: 0.839844\n",
            "Epoch 246: Loss: 0.357844 \t\t Validation loss: 0.362315\n",
            "Training average batch accuracy: 0.845188\n",
            "Validation average batch accuracy: 0.840967\n",
            "Epoch 247: Loss: 0.357991 \t\t Validation loss: 0.365964\n",
            "Training average batch accuracy: 0.843625\n",
            "Validation average batch accuracy: 0.841602\n",
            "Epoch 248: Loss: 0.354805 \t\t Validation loss: 0.370055\n",
            "Training average batch accuracy: 0.847813\n",
            "Validation average batch accuracy: 0.838428\n",
            "Epoch 249: Loss: 0.354444 \t\t Validation loss: 0.360843\n",
            "Training average batch accuracy: 0.845000\n",
            "Validation average batch accuracy: 0.842529\n",
            "Epoch 250: Loss: 0.357468 \t\t Validation loss: 0.357240\n",
            "Training average batch accuracy: 0.846500\n",
            "Validation average batch accuracy: 0.846289\n",
            "Epoch 251: Loss: 0.354065 \t\t Validation loss: 0.361538\n",
            "Training average batch accuracy: 0.846563\n",
            "Validation average batch accuracy: 0.841162\n",
            "Epoch 252: Loss: 0.353192 \t\t Validation loss: 0.366802\n",
            "Training average batch accuracy: 0.850125\n",
            "Validation average batch accuracy: 0.842139\n",
            "Epoch 253: Loss: 0.359723 \t\t Validation loss: 0.358408\n",
            "Training average batch accuracy: 0.847875\n",
            "Epoch   254: reducing learning rate of group 0 to 4.7830e-05.\n",
            "Validation average batch accuracy: 0.845703\n",
            "Epoch 254: Loss: 0.355210 \t\t Validation loss: 0.361447\n",
            "Training average batch accuracy: 0.845125\n",
            "Validation average batch accuracy: 0.843359\n",
            "Epoch 255: Loss: 0.355666 \t\t Validation loss: 0.353105\n",
            "Training average batch accuracy: 0.846250\n",
            "Validation average batch accuracy: 0.844141\n",
            "Epoch 256: Loss: 0.352156 \t\t Validation loss: 0.356707\n",
            "Training average batch accuracy: 0.849313\n",
            "Validation average batch accuracy: 0.849707\n",
            "Epoch 257: Loss: 0.353510 \t\t Validation loss: 0.355273\n",
            "Training average batch accuracy: 0.851563\n",
            "Validation average batch accuracy: 0.846094\n",
            "Epoch 258: Loss: 0.354775 \t\t Validation loss: 0.360375\n",
            "Training average batch accuracy: 0.845375\n",
            "Validation average batch accuracy: 0.840869\n",
            "Epoch 259: Loss: 0.346444 \t\t Validation loss: 0.354202\n",
            "Training average batch accuracy: 0.853000\n",
            "Validation average batch accuracy: 0.845459\n",
            "Epoch 260: Loss: 0.359100 \t\t Validation loss: 0.360666\n",
            "Training average batch accuracy: 0.843000\n",
            "Validation average batch accuracy: 0.841846\n",
            "Epoch 261: Loss: 0.348570 \t\t Validation loss: 0.359662\n",
            "Training average batch accuracy: 0.847688\n",
            "Validation average batch accuracy: 0.842236\n",
            "Epoch 262: Loss: 0.351060 \t\t Validation loss: 0.354596\n",
            "Training average batch accuracy: 0.848750\n",
            "Validation average batch accuracy: 0.843897\n",
            "Epoch 263: Loss: 0.346991 \t\t Validation loss: 0.360646\n",
            "Training average batch accuracy: 0.851688\n",
            "Validation average batch accuracy: 0.844678\n",
            "Epoch 264: Loss: 0.347108 \t\t Validation loss: 0.355123\n",
            "Training average batch accuracy: 0.854000\n",
            "Epoch   265: reducing learning rate of group 0 to 4.3047e-05.\n",
            "Validation average batch accuracy: 0.845947\n",
            "Epoch 265: Loss: 0.358632 \t\t Validation loss: 0.352712\n",
            "BEST SCORE: 0.3527121725957841\n",
            "Training average batch accuracy: 0.845875\n",
            "Validation average batch accuracy: 0.844531\n",
            "Epoch 266: Loss: 0.350655 \t\t Validation loss: 0.360600\n",
            "Training average batch accuracy: 0.849250\n",
            "Validation average batch accuracy: 0.842920\n",
            "Epoch 267: Loss: 0.360571 \t\t Validation loss: 0.362210\n",
            "Training average batch accuracy: 0.847938\n",
            "Validation average batch accuracy: 0.843750\n",
            "Epoch 268: Loss: 0.358535 \t\t Validation loss: 0.367869\n",
            "Training average batch accuracy: 0.845750\n",
            "Validation average batch accuracy: 0.838477\n",
            "Epoch 269: Loss: 0.351314 \t\t Validation loss: 0.355161\n",
            "Training average batch accuracy: 0.851063\n",
            "Validation average batch accuracy: 0.845166\n",
            "Epoch 270: Loss: 0.360903 \t\t Validation loss: 0.353192\n",
            "Training average batch accuracy: 0.843875\n",
            "Validation average batch accuracy: 0.849219\n",
            "Epoch 271: Loss: 0.353472 \t\t Validation loss: 0.356562\n",
            "Training average batch accuracy: 0.847188\n",
            "Validation average batch accuracy: 0.846973\n",
            "Epoch 272: Loss: 0.346837 \t\t Validation loss: 0.352296\n",
            "BEST SCORE: 0.35229644924402237\n",
            "Training average batch accuracy: 0.851938\n",
            "Validation average batch accuracy: 0.848096\n",
            "Epoch 273: Loss: 0.345264 \t\t Validation loss: 0.350282\n",
            "BEST SCORE: 0.350281817978248\n",
            "Training average batch accuracy: 0.852188\n",
            "Validation average batch accuracy: 0.849463\n",
            "Epoch 274: Loss: 0.346912 \t\t Validation loss: 0.354711\n",
            "Training average batch accuracy: 0.850250\n",
            "Validation average batch accuracy: 0.846289\n",
            "Epoch 275: Loss: 0.347763 \t\t Validation loss: 0.348732\n",
            "BEST SCORE: 0.3487319317180663\n",
            "Training average batch accuracy: 0.849063\n",
            "Validation average batch accuracy: 0.849072\n",
            "Epoch 276: Loss: 0.344574 \t\t Validation loss: 0.353488\n",
            "Training average batch accuracy: 0.853188\n",
            "Validation average batch accuracy: 0.848291\n",
            "Epoch 277: Loss: 0.339283 \t\t Validation loss: 0.356169\n",
            "Training average batch accuracy: 0.856688\n",
            "Validation average batch accuracy: 0.847363\n",
            "Epoch 278: Loss: 0.340464 \t\t Validation loss: 0.356292\n",
            "Training average batch accuracy: 0.858000\n",
            "Validation average batch accuracy: 0.844824\n",
            "Epoch 279: Loss: 0.335194 \t\t Validation loss: 0.358538\n",
            "Training average batch accuracy: 0.856563\n",
            "Validation average batch accuracy: 0.846582\n",
            "Epoch 280: Loss: 0.354691 \t\t Validation loss: 0.353448\n",
            "Training average batch accuracy: 0.850250\n",
            "Validation average batch accuracy: 0.847754\n",
            "Epoch 281: Loss: 0.348618 \t\t Validation loss: 0.353510\n",
            "Training average batch accuracy: 0.849250\n",
            "Validation average batch accuracy: 0.847607\n",
            "Epoch 282: Loss: 0.338779 \t\t Validation loss: 0.354961\n",
            "Training average batch accuracy: 0.857000\n",
            "Validation average batch accuracy: 0.847656\n",
            "Epoch 283: Loss: 0.348153 \t\t Validation loss: 0.351641\n",
            "Training average batch accuracy: 0.852500\n",
            "Validation average batch accuracy: 0.845801\n",
            "Epoch 284: Loss: 0.357003 \t\t Validation loss: 0.349624\n",
            "Training average batch accuracy: 0.845188\n",
            "Validation average batch accuracy: 0.851465\n",
            "Epoch 285: Loss: 0.347525 \t\t Validation loss: 0.350830\n",
            "Training average batch accuracy: 0.850875\n",
            "Validation average batch accuracy: 0.847900\n",
            "Epoch 286: Loss: 0.343496 \t\t Validation loss: 0.346301\n",
            "BEST SCORE: 0.34630119814537463\n",
            "Training average batch accuracy: 0.855813\n",
            "Validation average batch accuracy: 0.851611\n",
            "Epoch 287: Loss: 0.345278 \t\t Validation loss: 0.352537\n",
            "Training average batch accuracy: 0.855250\n",
            "Validation average batch accuracy: 0.847754\n",
            "Epoch 288: Loss: 0.338020 \t\t Validation loss: 0.359812\n",
            "Training average batch accuracy: 0.857250\n",
            "Validation average batch accuracy: 0.845947\n",
            "Epoch 289: Loss: 0.340026 \t\t Validation loss: 0.357270\n",
            "Training average batch accuracy: 0.853750\n",
            "Validation average batch accuracy: 0.846338\n",
            "Epoch 290: Loss: 0.340435 \t\t Validation loss: 0.349002\n",
            "Training average batch accuracy: 0.853438\n",
            "Validation average batch accuracy: 0.850244\n",
            "Epoch 291: Loss: 0.340637 \t\t Validation loss: 0.355438\n",
            "Training average batch accuracy: 0.853875\n",
            "Validation average batch accuracy: 0.845996\n",
            "Epoch 292: Loss: 0.346852 \t\t Validation loss: 0.342985\n",
            "BEST SCORE: 0.3429853906389326\n",
            "Training average batch accuracy: 0.847875\n",
            "Validation average batch accuracy: 0.851074\n",
            "Epoch 293: Loss: 0.342624 \t\t Validation loss: 0.353089\n",
            "Training average batch accuracy: 0.854563\n",
            "Validation average batch accuracy: 0.845801\n",
            "Epoch 294: Loss: 0.352115 \t\t Validation loss: 0.352731\n",
            "Training average batch accuracy: 0.848313\n",
            "Validation average batch accuracy: 0.845654\n",
            "Epoch 295: Loss: 0.343235 \t\t Validation loss: 0.359739\n",
            "Training average batch accuracy: 0.855063\n",
            "Validation average batch accuracy: 0.846045\n",
            "Epoch 296: Loss: 0.333112 \t\t Validation loss: 0.357469\n",
            "Training average batch accuracy: 0.860438\n",
            "Validation average batch accuracy: 0.845020\n",
            "Epoch 297: Loss: 0.351174 \t\t Validation loss: 0.354822\n",
            "Training average batch accuracy: 0.850438\n",
            "Validation average batch accuracy: 0.846826\n",
            "Epoch 298: Loss: 0.338610 \t\t Validation loss: 0.353890\n",
            "Training average batch accuracy: 0.859563\n",
            "Validation average batch accuracy: 0.847168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgTNSrBC_SOA"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mMnZivE_SxG"
      },
      "source": [
        "### + Cosine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RNOkWBky_hnl",
        "outputId": "d3de5701-b613-4f9e-e05f-73a8c1e3ca0a"
      },
      "source": [
        "def context_train_step_2(model, batch):\n",
        "    (unk_context, rnn_context), preds, loss = model(*list(batch))\n",
        "    return {'loss': loss, 'batch_accuracy': binary_accuracy(preds, batch[-1])}\n",
        "\n",
        "def context_eval_step_2(model, batch):\n",
        "    (unk_context, rnn_context), preds, loss = model(*list(batch))\n",
        "    return loss, binary_accuracy(preds, batch[-1])\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, eval_step):\n",
        "    model.eval()\n",
        "    results = []\n",
        "    losses = []\n",
        "    \n",
        "    for k in range(10):\n",
        "        for i, batch in enumerate(data_loader):\n",
        "            loss, metric = eval_step(model, batch)\n",
        "            losses.append(loss.item())\n",
        "            results.append(metric)\n",
        "\n",
        "    return sum(losses) / len(losses), sum(results) / len(results)\n",
        "\n",
        "\n",
        "\n",
        "model_context = ContextEncoder(ContextParams(), vectors, \n",
        "                               train_dataset_context.get_used_tokens(True), \n",
        "                               binary_mode=True,\n",
        "                               cosine_mode=True,\n",
        "                               with_pos_tags=False,\n",
        "                               ).to('cuda')\n",
        "optim_context = torch.optim.Adam(model_context.parameters(), lr=0.0001)\n",
        "\n",
        "\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(optim_context, 5000, 0.5)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim_context, factor=0.9, verbose=True)\n",
        "\n",
        "\n",
        "#scheduler=None\n",
        "best_model = {}\n",
        "\n",
        "best_state_dict, _ = train(train_loader_context, valid_loader_context, \n",
        "      model_context, optim_context, \n",
        "      context_train_step_2, \n",
        "      context_eval_step_2,\n",
        "      300, best_model, \n",
        "      best_model='accuracy', \n",
        "      scheduler=scheduler)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss: 0.684557 \t\t Validation loss: 0.665980\n",
            "Training average batch accuracy: 0.553250\n",
            "Validation average batch accuracy: 0.611377\n",
            "Epoch 1: Loss: 0.664028 \t\t Validation loss: 0.652783\n",
            "Training average batch accuracy: 0.620750\n",
            "Validation average batch accuracy: 0.636670\n",
            "Epoch 2: Loss: 0.654639 \t\t Validation loss: 0.644205\n",
            "Training average batch accuracy: 0.640688\n",
            "Validation average batch accuracy: 0.659131\n",
            "Epoch 3: Loss: 0.648989 \t\t Validation loss: 0.641474\n",
            "Training average batch accuracy: 0.653250\n",
            "Validation average batch accuracy: 0.664990\n",
            "Epoch 4: Loss: 0.645561 \t\t Validation loss: 0.638285\n",
            "Training average batch accuracy: 0.668188\n",
            "Validation average batch accuracy: 0.672607\n",
            "Epoch 5: Loss: 0.640959 \t\t Validation loss: 0.636568\n",
            "Training average batch accuracy: 0.673438\n",
            "Validation average batch accuracy: 0.672266\n",
            "Epoch 6: Loss: 0.641299 \t\t Validation loss: 0.632887\n",
            "Training average batch accuracy: 0.674313\n",
            "Validation average batch accuracy: 0.686182\n",
            "Epoch 7: Loss: 0.636668 \t\t Validation loss: 0.633951\n",
            "Training average batch accuracy: 0.684625\n",
            "Validation average batch accuracy: 0.683154\n",
            "Epoch 8: Loss: 0.634562 \t\t Validation loss: 0.634033\n",
            "Training average batch accuracy: 0.687375\n",
            "Validation average batch accuracy: 0.683105\n",
            "Epoch 9: Loss: 0.634189 \t\t Validation loss: 0.633143\n",
            "Training average batch accuracy: 0.686813\n",
            "Validation average batch accuracy: 0.680664\n",
            "Epoch 10: Loss: 0.634838 \t\t Validation loss: 0.629248\n",
            "Training average batch accuracy: 0.688750\n",
            "Validation average batch accuracy: 0.691406\n",
            "Epoch 11: Loss: 0.635382 \t\t Validation loss: 0.631155\n",
            "Training average batch accuracy: 0.682500\n",
            "Validation average batch accuracy: 0.684619\n",
            "Epoch 12: Loss: 0.633644 \t\t Validation loss: 0.630406\n",
            "Training average batch accuracy: 0.685000\n",
            "Validation average batch accuracy: 0.689453\n",
            "Epoch 13: Loss: 0.634190 \t\t Validation loss: 0.629676\n",
            "Training average batch accuracy: 0.686188\n",
            "Validation average batch accuracy: 0.690869\n",
            "Epoch 14: Loss: 0.633759 \t\t Validation loss: 0.629129\n",
            "Training average batch accuracy: 0.685063\n",
            "Validation average batch accuracy: 0.692969\n",
            "Epoch 15: Loss: 0.632070 \t\t Validation loss: 0.628043\n",
            "Training average batch accuracy: 0.693000\n",
            "Validation average batch accuracy: 0.696777\n",
            "Epoch 16: Loss: 0.629647 \t\t Validation loss: 0.628443\n",
            "Training average batch accuracy: 0.696688\n",
            "Validation average batch accuracy: 0.694775\n",
            "Epoch 17: Loss: 0.631272 \t\t Validation loss: 0.626768\n",
            "Training average batch accuracy: 0.690375\n",
            "Validation average batch accuracy: 0.696826\n",
            "Epoch 18: Loss: 0.629794 \t\t Validation loss: 0.625876\n",
            "Training average batch accuracy: 0.688438\n",
            "Validation average batch accuracy: 0.699512\n",
            "Epoch 19: Loss: 0.629235 \t\t Validation loss: 0.629236\n",
            "Training average batch accuracy: 0.693313\n",
            "Validation average batch accuracy: 0.691943\n",
            "Epoch 20: Loss: 0.628300 \t\t Validation loss: 0.627342\n",
            "Training average batch accuracy: 0.697750\n",
            "Validation average batch accuracy: 0.693213\n",
            "Epoch 21: Loss: 0.630006 \t\t Validation loss: 0.625106\n",
            "Training average batch accuracy: 0.686875\n",
            "Validation average batch accuracy: 0.696582\n",
            "Epoch 22: Loss: 0.626500 \t\t Validation loss: 0.626052\n",
            "Training average batch accuracy: 0.702813\n",
            "Validation average batch accuracy: 0.700488\n",
            "Epoch 23: Loss: 0.626525 \t\t Validation loss: 0.626121\n",
            "Training average batch accuracy: 0.699188\n",
            "Validation average batch accuracy: 0.693750\n",
            "Epoch 24: Loss: 0.627203 \t\t Validation loss: 0.626318\n",
            "Training average batch accuracy: 0.696813\n",
            "Validation average batch accuracy: 0.697168\n",
            "Epoch 25: Loss: 0.627285 \t\t Validation loss: 0.624071\n",
            "Training average batch accuracy: 0.695250\n",
            "Validation average batch accuracy: 0.703223\n",
            "Epoch 26: Loss: 0.627984 \t\t Validation loss: 0.625995\n",
            "Training average batch accuracy: 0.697563\n",
            "Validation average batch accuracy: 0.694971\n",
            "Epoch 27: Loss: 0.625258 \t\t Validation loss: 0.623354\n",
            "Training average batch accuracy: 0.699563\n",
            "Validation average batch accuracy: 0.704053\n",
            "Epoch 28: Loss: 0.626436 \t\t Validation loss: 0.622847\n",
            "Training average batch accuracy: 0.698813\n",
            "Validation average batch accuracy: 0.702100\n",
            "Epoch 29: Loss: 0.626458 \t\t Validation loss: 0.622301\n",
            "Training average batch accuracy: 0.698500\n",
            "Validation average batch accuracy: 0.704834\n",
            "Epoch 30: Loss: 0.625254 \t\t Validation loss: 0.622199\n",
            "Training average batch accuracy: 0.705500\n",
            "Validation average batch accuracy: 0.711328\n",
            "Epoch 31: Loss: 0.624794 \t\t Validation loss: 0.622793\n",
            "Training average batch accuracy: 0.704125\n",
            "Validation average batch accuracy: 0.705420\n",
            "Epoch 32: Loss: 0.625571 \t\t Validation loss: 0.621670\n",
            "Training average batch accuracy: 0.702188\n",
            "Validation average batch accuracy: 0.703223\n",
            "Epoch 33: Loss: 0.627308 \t\t Validation loss: 0.622516\n",
            "Training average batch accuracy: 0.695625\n",
            "Validation average batch accuracy: 0.709766\n",
            "Epoch 34: Loss: 0.624132 \t\t Validation loss: 0.624118\n",
            "Training average batch accuracy: 0.708438\n",
            "Validation average batch accuracy: 0.700098\n",
            "Epoch 35: Loss: 0.624414 \t\t Validation loss: 0.623235\n",
            "Training average batch accuracy: 0.699750\n",
            "Validation average batch accuracy: 0.704443\n",
            "Epoch 36: Loss: 0.625142 \t\t Validation loss: 0.620564\n",
            "Training average batch accuracy: 0.703188\n",
            "Validation average batch accuracy: 0.708203\n",
            "Epoch 37: Loss: 0.624428 \t\t Validation loss: 0.622025\n",
            "Training average batch accuracy: 0.702438\n",
            "Validation average batch accuracy: 0.708545\n",
            "Epoch 38: Loss: 0.625152 \t\t Validation loss: 0.619776\n",
            "Training average batch accuracy: 0.706188\n",
            "Validation average batch accuracy: 0.711328\n",
            "Epoch 39: Loss: 0.621819 \t\t Validation loss: 0.620836\n",
            "Training average batch accuracy: 0.708688\n",
            "Validation average batch accuracy: 0.711963\n",
            "Epoch 40: Loss: 0.624318 \t\t Validation loss: 0.622184\n",
            "Training average batch accuracy: 0.701250\n",
            "Validation average batch accuracy: 0.708106\n",
            "Epoch 41: Loss: 0.623150 \t\t Validation loss: 0.620952\n",
            "Training average batch accuracy: 0.705625\n",
            "Validation average batch accuracy: 0.707275\n",
            "Epoch 42: Loss: 0.623554 \t\t Validation loss: 0.620549\n",
            "Training average batch accuracy: 0.704500\n",
            "Validation average batch accuracy: 0.708594\n",
            "Epoch 43: Loss: 0.623813 \t\t Validation loss: 0.619107\n",
            "Training average batch accuracy: 0.701875\n",
            "Validation average batch accuracy: 0.711914\n",
            "Epoch 44: Loss: 0.621322 \t\t Validation loss: 0.621113\n",
            "Training average batch accuracy: 0.709063\n",
            "Validation average batch accuracy: 0.704492\n",
            "Epoch 45: Loss: 0.622210 \t\t Validation loss: 0.620202\n",
            "Training average batch accuracy: 0.703375\n",
            "Validation average batch accuracy: 0.712500\n",
            "Epoch 46: Loss: 0.621840 \t\t Validation loss: 0.621658\n",
            "Training average batch accuracy: 0.708688\n",
            "Validation average batch accuracy: 0.703662\n",
            "Epoch 47: Loss: 0.622659 \t\t Validation loss: 0.618660\n",
            "Training average batch accuracy: 0.709750\n",
            "Validation average batch accuracy: 0.713916\n",
            "Epoch 48: Loss: 0.621901 \t\t Validation loss: 0.617585\n",
            "Training average batch accuracy: 0.702750\n",
            "Validation average batch accuracy: 0.713965\n",
            "Epoch 49: Loss: 0.621803 \t\t Validation loss: 0.618215\n",
            "Training average batch accuracy: 0.707750\n",
            "Validation average batch accuracy: 0.711621\n",
            "Epoch 50: Loss: 0.622210 \t\t Validation loss: 0.620496\n",
            "Training average batch accuracy: 0.704813\n",
            "Validation average batch accuracy: 0.706348\n",
            "Epoch 51: Loss: 0.620595 \t\t Validation loss: 0.618240\n",
            "Training average batch accuracy: 0.707625\n",
            "Validation average batch accuracy: 0.714258\n",
            "Epoch 52: Loss: 0.619348 \t\t Validation loss: 0.619693\n",
            "Training average batch accuracy: 0.710500\n",
            "Validation average batch accuracy: 0.709180\n",
            "Epoch 53: Loss: 0.618159 \t\t Validation loss: 0.618807\n",
            "Training average batch accuracy: 0.714750\n",
            "Validation average batch accuracy: 0.708936\n",
            "Epoch 54: Loss: 0.619463 \t\t Validation loss: 0.618106\n",
            "Training average batch accuracy: 0.712250\n",
            "Validation average batch accuracy: 0.715430\n",
            "Epoch 55: Loss: 0.620726 \t\t Validation loss: 0.618090\n",
            "Training average batch accuracy: 0.710250\n",
            "Validation average batch accuracy: 0.712402\n",
            "Epoch 56: Loss: 0.621225 \t\t Validation loss: 0.617742\n",
            "Training average batch accuracy: 0.706813\n",
            "Validation average batch accuracy: 0.714160\n",
            "Epoch 57: Loss: 0.621589 \t\t Validation loss: 0.618816\n",
            "Training average batch accuracy: 0.712625\n",
            "Validation average batch accuracy: 0.712012\n",
            "Epoch 58: Loss: 0.619686 \t\t Validation loss: 0.618325\n",
            "Training average batch accuracy: 0.712000\n",
            "Validation average batch accuracy: 0.711670\n",
            "Epoch 59: Loss: 0.618773 \t\t Validation loss: 0.618072\n",
            "Training average batch accuracy: 0.711563\n",
            "Epoch    60: reducing learning rate of group 0 to 9.0000e-05.\n",
            "Validation average batch accuracy: 0.712598\n",
            "Epoch 60: Loss: 0.619630 \t\t Validation loss: 0.619386\n",
            "Training average batch accuracy: 0.713063\n",
            "Validation average batch accuracy: 0.711475\n",
            "Epoch 61: Loss: 0.618815 \t\t Validation loss: 0.616192\n",
            "Training average batch accuracy: 0.717375\n",
            "Validation average batch accuracy: 0.716504\n",
            "Epoch 62: Loss: 0.618240 \t\t Validation loss: 0.615795\n",
            "Training average batch accuracy: 0.713188\n",
            "Validation average batch accuracy: 0.718066\n",
            "Epoch 63: Loss: 0.617598 \t\t Validation loss: 0.617920\n",
            "Training average batch accuracy: 0.716063\n",
            "Validation average batch accuracy: 0.710596\n",
            "Epoch 64: Loss: 0.618409 \t\t Validation loss: 0.616495\n",
            "Training average batch accuracy: 0.714938\n",
            "Validation average batch accuracy: 0.711475\n",
            "Epoch 65: Loss: 0.616804 \t\t Validation loss: 0.618432\n",
            "Training average batch accuracy: 0.715313\n",
            "Validation average batch accuracy: 0.711865\n",
            "Epoch 66: Loss: 0.617001 \t\t Validation loss: 0.618366\n",
            "Training average batch accuracy: 0.714813\n",
            "Validation average batch accuracy: 0.711621\n",
            "Epoch 67: Loss: 0.617032 \t\t Validation loss: 0.616708\n",
            "Training average batch accuracy: 0.720688\n",
            "Validation average batch accuracy: 0.722168\n",
            "Epoch 68: Loss: 0.618913 \t\t Validation loss: 0.617334\n",
            "Training average batch accuracy: 0.715313\n",
            "Validation average batch accuracy: 0.714502\n",
            "Epoch 69: Loss: 0.617670 \t\t Validation loss: 0.613819\n",
            "Training average batch accuracy: 0.715375\n",
            "Validation average batch accuracy: 0.721338\n",
            "Epoch 70: Loss: 0.616799 \t\t Validation loss: 0.617738\n",
            "Training average batch accuracy: 0.713000\n",
            "Validation average batch accuracy: 0.718115\n",
            "Epoch 71: Loss: 0.616246 \t\t Validation loss: 0.617265\n",
            "Training average batch accuracy: 0.719500\n",
            "Validation average batch accuracy: 0.712012\n",
            "Epoch 72: Loss: 0.615849 \t\t Validation loss: 0.617112\n",
            "Training average batch accuracy: 0.722750\n",
            "Validation average batch accuracy: 0.716162\n",
            "Epoch 73: Loss: 0.617616 \t\t Validation loss: 0.617317\n",
            "Training average batch accuracy: 0.716688\n",
            "Validation average batch accuracy: 0.712451\n",
            "Epoch 74: Loss: 0.616648 \t\t Validation loss: 0.615834\n",
            "Training average batch accuracy: 0.713813\n",
            "Validation average batch accuracy: 0.718115\n",
            "Epoch 75: Loss: 0.616816 \t\t Validation loss: 0.618758\n",
            "Training average batch accuracy: 0.718625\n",
            "Validation average batch accuracy: 0.710449\n",
            "Epoch 76: Loss: 0.617260 \t\t Validation loss: 0.617107\n",
            "Training average batch accuracy: 0.712750\n",
            "Validation average batch accuracy: 0.718359\n",
            "Epoch 77: Loss: 0.616047 \t\t Validation loss: 0.615328\n",
            "Training average batch accuracy: 0.715188\n",
            "Validation average batch accuracy: 0.717285\n",
            "Epoch 78: Loss: 0.616875 \t\t Validation loss: 0.614656\n",
            "Training average batch accuracy: 0.717750\n",
            "Validation average batch accuracy: 0.719385\n",
            "Epoch 79: Loss: 0.616649 \t\t Validation loss: 0.616077\n",
            "Training average batch accuracy: 0.719438\n",
            "Validation average batch accuracy: 0.718066\n",
            "Epoch 80: Loss: 0.616769 \t\t Validation loss: 0.616031\n",
            "Training average batch accuracy: 0.716188\n",
            "Epoch    81: reducing learning rate of group 0 to 8.1000e-05.\n",
            "Validation average batch accuracy: 0.715723\n",
            "Epoch 81: Loss: 0.616873 \t\t Validation loss: 0.615564\n",
            "Training average batch accuracy: 0.715750\n",
            "Validation average batch accuracy: 0.712402\n",
            "Epoch 82: Loss: 0.615921 \t\t Validation loss: 0.616481\n",
            "Training average batch accuracy: 0.716250\n",
            "Validation average batch accuracy: 0.714551\n",
            "Epoch 83: Loss: 0.617025 \t\t Validation loss: 0.616051\n",
            "Training average batch accuracy: 0.711688\n",
            "Validation average batch accuracy: 0.712598\n",
            "Epoch 84: Loss: 0.615876 \t\t Validation loss: 0.616510\n",
            "Training average batch accuracy: 0.722125\n",
            "Validation average batch accuracy: 0.717432\n",
            "Epoch 85: Loss: 0.613953 \t\t Validation loss: 0.615586\n",
            "Training average batch accuracy: 0.719125\n",
            "Validation average batch accuracy: 0.718555\n",
            "Epoch 86: Loss: 0.613861 \t\t Validation loss: 0.614398\n",
            "Training average batch accuracy: 0.719750\n",
            "Validation average batch accuracy: 0.721582\n",
            "Epoch 87: Loss: 0.615006 \t\t Validation loss: 0.613798\n",
            "Training average batch accuracy: 0.719750\n",
            "Validation average batch accuracy: 0.718994\n",
            "Epoch 88: Loss: 0.613332 \t\t Validation loss: 0.613006\n",
            "Training average batch accuracy: 0.722688\n",
            "Validation average batch accuracy: 0.722998\n",
            "Epoch 89: Loss: 0.615369 \t\t Validation loss: 0.613075\n",
            "Training average batch accuracy: 0.717313\n",
            "Validation average batch accuracy: 0.724170\n",
            "Epoch 90: Loss: 0.618184 \t\t Validation loss: 0.615181\n",
            "Training average batch accuracy: 0.714938\n",
            "Validation average batch accuracy: 0.721631\n",
            "Epoch 91: Loss: 0.614150 \t\t Validation loss: 0.614185\n",
            "Training average batch accuracy: 0.719938\n",
            "Validation average batch accuracy: 0.720996\n",
            "Epoch 92: Loss: 0.613838 \t\t Validation loss: 0.615685\n",
            "Training average batch accuracy: 0.722500\n",
            "Validation average batch accuracy: 0.718115\n",
            "Epoch 93: Loss: 0.613521 \t\t Validation loss: 0.614069\n",
            "Training average batch accuracy: 0.720313\n",
            "Validation average batch accuracy: 0.723242\n",
            "Epoch 94: Loss: 0.612687 \t\t Validation loss: 0.616342\n",
            "Training average batch accuracy: 0.724125\n",
            "Validation average batch accuracy: 0.714941\n",
            "Epoch 95: Loss: 0.616534 \t\t Validation loss: 0.615209\n",
            "Training average batch accuracy: 0.714813\n",
            "Validation average batch accuracy: 0.715771\n",
            "Epoch 96: Loss: 0.614872 \t\t Validation loss: 0.612276\n",
            "Training average batch accuracy: 0.719438\n",
            "Validation average batch accuracy: 0.727441\n",
            "Epoch 97: Loss: 0.616528 \t\t Validation loss: 0.616017\n",
            "Training average batch accuracy: 0.712438\n",
            "Validation average batch accuracy: 0.711963\n",
            "Epoch 98: Loss: 0.613768 \t\t Validation loss: 0.615255\n",
            "Training average batch accuracy: 0.718938\n",
            "Validation average batch accuracy: 0.717285\n",
            "Epoch 99: Loss: 0.613059 \t\t Validation loss: 0.615500\n",
            "Training average batch accuracy: 0.724500\n",
            "Validation average batch accuracy: 0.717627\n",
            "Epoch 100: Loss: 0.613758 \t\t Validation loss: 0.614648\n",
            "Training average batch accuracy: 0.713625\n",
            "Validation average batch accuracy: 0.719727\n",
            "Epoch 101: Loss: 0.613761 \t\t Validation loss: 0.612792\n",
            "Training average batch accuracy: 0.722625\n",
            "Validation average batch accuracy: 0.719922\n",
            "Epoch 102: Loss: 0.614417 \t\t Validation loss: 0.613666\n",
            "Training average batch accuracy: 0.721625\n",
            "Validation average batch accuracy: 0.724365\n",
            "Epoch 103: Loss: 0.612991 \t\t Validation loss: 0.612272\n",
            "Training average batch accuracy: 0.725938\n",
            "Validation average batch accuracy: 0.721143\n",
            "Epoch 104: Loss: 0.613797 \t\t Validation loss: 0.616063\n",
            "Training average batch accuracy: 0.719688\n",
            "Validation average batch accuracy: 0.717725\n",
            "Epoch 105: Loss: 0.612373 \t\t Validation loss: 0.615374\n",
            "Training average batch accuracy: 0.724063\n",
            "Validation average batch accuracy: 0.716602\n",
            "Epoch 106: Loss: 0.615187 \t\t Validation loss: 0.614016\n",
            "Training average batch accuracy: 0.718000\n",
            "Validation average batch accuracy: 0.722803\n",
            "Epoch 107: Loss: 0.614089 \t\t Validation loss: 0.616123\n",
            "Training average batch accuracy: 0.726250\n",
            "Epoch   108: reducing learning rate of group 0 to 7.2900e-05.\n",
            "Validation average batch accuracy: 0.713965\n",
            "Epoch 108: Loss: 0.614540 \t\t Validation loss: 0.611451\n",
            "Training average batch accuracy: 0.723188\n",
            "Validation average batch accuracy: 0.728857\n",
            "Epoch 109: Loss: 0.612693 \t\t Validation loss: 0.611768\n",
            "Training average batch accuracy: 0.722125\n",
            "Validation average batch accuracy: 0.729102\n",
            "Epoch 110: Loss: 0.613459 \t\t Validation loss: 0.613251\n",
            "Training average batch accuracy: 0.725625\n",
            "Validation average batch accuracy: 0.723096\n",
            "Epoch 111: Loss: 0.613220 \t\t Validation loss: 0.613836\n",
            "Training average batch accuracy: 0.720438\n",
            "Validation average batch accuracy: 0.722314\n",
            "Epoch 112: Loss: 0.614131 \t\t Validation loss: 0.612632\n",
            "Training average batch accuracy: 0.719438\n",
            "Validation average batch accuracy: 0.721631\n",
            "Epoch 113: Loss: 0.613493 \t\t Validation loss: 0.613962\n",
            "Training average batch accuracy: 0.724500\n",
            "Validation average batch accuracy: 0.718750\n",
            "Epoch 114: Loss: 0.612783 \t\t Validation loss: 0.612784\n",
            "Training average batch accuracy: 0.721438\n",
            "Validation average batch accuracy: 0.726709\n",
            "Epoch 115: Loss: 0.611701 \t\t Validation loss: 0.612880\n",
            "Training average batch accuracy: 0.726188\n",
            "Validation average batch accuracy: 0.719873\n",
            "Epoch 116: Loss: 0.612604 \t\t Validation loss: 0.612089\n",
            "Training average batch accuracy: 0.728813\n",
            "Validation average batch accuracy: 0.722900\n",
            "Epoch 117: Loss: 0.612030 \t\t Validation loss: 0.615806\n",
            "Training average batch accuracy: 0.724625\n",
            "Validation average batch accuracy: 0.718799\n",
            "Epoch 118: Loss: 0.612664 \t\t Validation loss: 0.614348\n",
            "Training average batch accuracy: 0.723188\n",
            "Validation average batch accuracy: 0.720459\n",
            "Epoch 119: Loss: 0.611818 \t\t Validation loss: 0.612505\n",
            "Training average batch accuracy: 0.726063\n",
            "Epoch   120: reducing learning rate of group 0 to 6.5610e-05.\n",
            "Validation average batch accuracy: 0.722168\n",
            "Epoch 120: Loss: 0.612487 \t\t Validation loss: 0.614222\n",
            "Training average batch accuracy: 0.727313\n",
            "Validation average batch accuracy: 0.715186\n",
            "Epoch 121: Loss: 0.612555 \t\t Validation loss: 0.612685\n",
            "Training average batch accuracy: 0.725188\n",
            "Validation average batch accuracy: 0.725439\n",
            "Epoch 122: Loss: 0.610804 \t\t Validation loss: 0.613363\n",
            "Training average batch accuracy: 0.727000\n",
            "Validation average batch accuracy: 0.724951\n",
            "Epoch 123: Loss: 0.612044 \t\t Validation loss: 0.614667\n",
            "Training average batch accuracy: 0.722500\n",
            "Validation average batch accuracy: 0.718359\n",
            "Epoch 124: Loss: 0.611019 \t\t Validation loss: 0.613707\n",
            "Training average batch accuracy: 0.728000\n",
            "Validation average batch accuracy: 0.722998\n",
            "Epoch 125: Loss: 0.611460 \t\t Validation loss: 0.612181\n",
            "Training average batch accuracy: 0.726438\n",
            "Validation average batch accuracy: 0.722266\n",
            "Epoch 126: Loss: 0.611669 \t\t Validation loss: 0.609447\n",
            "Training average batch accuracy: 0.727125\n",
            "Validation average batch accuracy: 0.728369\n",
            "Epoch 127: Loss: 0.612155 \t\t Validation loss: 0.612106\n",
            "Training average batch accuracy: 0.722125\n",
            "Validation average batch accuracy: 0.721533\n",
            "Epoch 128: Loss: 0.611424 \t\t Validation loss: 0.613142\n",
            "Training average batch accuracy: 0.721125\n",
            "Validation average batch accuracy: 0.723633\n",
            "Epoch 129: Loss: 0.609810 \t\t Validation loss: 0.612295\n",
            "Training average batch accuracy: 0.728500\n",
            "Validation average batch accuracy: 0.719873\n",
            "Epoch 130: Loss: 0.611566 \t\t Validation loss: 0.610333\n",
            "Training average batch accuracy: 0.726188\n",
            "Validation average batch accuracy: 0.731641\n",
            "Epoch 131: Loss: 0.611733 \t\t Validation loss: 0.609975\n",
            "Training average batch accuracy: 0.727438\n",
            "Validation average batch accuracy: 0.726855\n",
            "Epoch 132: Loss: 0.612130 \t\t Validation loss: 0.612444\n",
            "Training average batch accuracy: 0.722875\n",
            "Validation average batch accuracy: 0.723437\n",
            "Epoch 133: Loss: 0.613041 \t\t Validation loss: 0.610767\n",
            "Training average batch accuracy: 0.720063\n",
            "Validation average batch accuracy: 0.729004\n",
            "Epoch 134: Loss: 0.609747 \t\t Validation loss: 0.611637\n",
            "Training average batch accuracy: 0.732813\n",
            "Validation average batch accuracy: 0.723975\n",
            "Epoch 135: Loss: 0.610994 \t\t Validation loss: 0.612851\n",
            "Training average batch accuracy: 0.726688\n",
            "Validation average batch accuracy: 0.719873\n",
            "Epoch 136: Loss: 0.607452 \t\t Validation loss: 0.611677\n",
            "Training average batch accuracy: 0.733250\n",
            "Validation average batch accuracy: 0.725977\n",
            "Epoch 137: Loss: 0.610485 \t\t Validation loss: 0.610396\n",
            "Training average batch accuracy: 0.731313\n",
            "Epoch   138: reducing learning rate of group 0 to 5.9049e-05.\n",
            "Validation average batch accuracy: 0.726514\n",
            "Epoch 138: Loss: 0.610584 \t\t Validation loss: 0.613920\n",
            "Training average batch accuracy: 0.728125\n",
            "Validation average batch accuracy: 0.717236\n",
            "Epoch 139: Loss: 0.611828 \t\t Validation loss: 0.612000\n",
            "Training average batch accuracy: 0.726250\n",
            "Validation average batch accuracy: 0.725439\n",
            "Epoch 140: Loss: 0.611054 \t\t Validation loss: 0.612189\n",
            "Training average batch accuracy: 0.729875\n",
            "Validation average batch accuracy: 0.723096\n",
            "Epoch 141: Loss: 0.612517 \t\t Validation loss: 0.612620\n",
            "Training average batch accuracy: 0.721563\n",
            "Validation average batch accuracy: 0.721143\n",
            "Epoch 142: Loss: 0.610528 \t\t Validation loss: 0.611626\n",
            "Training average batch accuracy: 0.730125\n",
            "Validation average batch accuracy: 0.725293\n",
            "Epoch 143: Loss: 0.611565 \t\t Validation loss: 0.612601\n",
            "Training average batch accuracy: 0.724313\n",
            "Validation average batch accuracy: 0.722168\n",
            "Epoch 144: Loss: 0.608457 \t\t Validation loss: 0.609744\n",
            "Training average batch accuracy: 0.728125\n",
            "Validation average batch accuracy: 0.729004\n",
            "Epoch 145: Loss: 0.611032 \t\t Validation loss: 0.611570\n",
            "Training average batch accuracy: 0.728438\n",
            "Validation average batch accuracy: 0.721094\n",
            "Epoch 146: Loss: 0.609132 \t\t Validation loss: 0.609011\n",
            "Training average batch accuracy: 0.730313\n",
            "Validation average batch accuracy: 0.732959\n",
            "Epoch 147: Loss: 0.609338 \t\t Validation loss: 0.612106\n",
            "Training average batch accuracy: 0.731063\n",
            "Validation average batch accuracy: 0.721533\n",
            "Epoch 148: Loss: 0.607763 \t\t Validation loss: 0.610260\n",
            "Training average batch accuracy: 0.730250\n",
            "Validation average batch accuracy: 0.723633\n",
            "Epoch 149: Loss: 0.609094 \t\t Validation loss: 0.611986\n",
            "Training average batch accuracy: 0.730375\n",
            "Validation average batch accuracy: 0.722754\n",
            "Epoch 150: Loss: 0.611073 \t\t Validation loss: 0.611929\n",
            "Training average batch accuracy: 0.726750\n",
            "Validation average batch accuracy: 0.722461\n",
            "Epoch 151: Loss: 0.608246 \t\t Validation loss: 0.611119\n",
            "Training average batch accuracy: 0.734250\n",
            "Validation average batch accuracy: 0.726123\n",
            "Epoch 152: Loss: 0.609055 \t\t Validation loss: 0.613090\n",
            "Training average batch accuracy: 0.731563\n",
            "Validation average batch accuracy: 0.722168\n",
            "Epoch 153: Loss: 0.608647 \t\t Validation loss: 0.611149\n",
            "Training average batch accuracy: 0.732813\n",
            "Validation average batch accuracy: 0.725244\n",
            "Epoch 154: Loss: 0.609105 \t\t Validation loss: 0.613177\n",
            "Training average batch accuracy: 0.732063\n",
            "Validation average batch accuracy: 0.720996\n",
            "Epoch 155: Loss: 0.611856 \t\t Validation loss: 0.612222\n",
            "Training average batch accuracy: 0.724938\n",
            "Validation average batch accuracy: 0.726367\n",
            "Epoch 156: Loss: 0.608845 \t\t Validation loss: 0.611343\n",
            "Training average batch accuracy: 0.730000\n",
            "Validation average batch accuracy: 0.720947\n",
            "Epoch 157: Loss: 0.609112 \t\t Validation loss: 0.610016\n",
            "Training average batch accuracy: 0.732938\n",
            "Epoch   158: reducing learning rate of group 0 to 5.3144e-05.\n",
            "Validation average batch accuracy: 0.726416\n",
            "Epoch 158: Loss: 0.608564 \t\t Validation loss: 0.611964\n",
            "Training average batch accuracy: 0.730188\n",
            "Validation average batch accuracy: 0.719385\n",
            "Epoch 159: Loss: 0.610704 \t\t Validation loss: 0.610746\n",
            "Training average batch accuracy: 0.729063\n",
            "Validation average batch accuracy: 0.725684\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-118-a9da54d384a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m       \u001b[0mcontext_train_step_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m       \u001b[0mcontext_eval_step_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m       300, best_model, scheduler=scheduler)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-96-1f9c84f2a5f8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data_loader, valid_data_loader, model, optimizer, train_step, eval_step, epochs, best_model, best_model_mode, hist, scheduler)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;31m#optimizer.zero_grad()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-fcc4730d61cd>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mrand_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mtoken_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<masked>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'masked_word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r04ZvAv-_hnn"
      },
      "source": [
        "#torch.save({\n",
        "            'epoch': 1000,\n",
        "            'model_state_dict': model_context.state_dict(),\n",
        "            'optimizer_state_dict': optim_context.state_dict(),\n",
        "            }, \n",
        "           #'model_context_9.pth'\n",
        "           \"/content/drive/MyDrive/Sapienza/model_context_GloVE300_cosine_2.pth\"\n",
        "           )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "ocfDp66z_kjA",
        "outputId": "d315f422-8cce-409b-aa52-f99acbaf3bf6"
      },
      "source": [
        "plot_hist(hist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_o2mTXdmlUn"
      },
      "source": [
        "#### Classification using cosine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-O5fpo0JA_zr",
        "outputId": "bbe97b06-caaa-4380-8ec5-f1f5afca961d"
      },
      "source": [
        "model_context.eval()\n",
        "cosine_sim = nn.CosineSimilarity()\n",
        "trashold = 0.69\n",
        "accuracy = []\n",
        "for batch  in valid_loader:\n",
        "    where_lemma, tokens, pos, tags, y = batch\n",
        "    contexts = []\n",
        "    for i in range(2):\n",
        "        (c, trans_c), _, _ = model_context(tokens[i], where_lemma[i])\n",
        "        contexts.append(trans_c)\n",
        "    \n",
        "    preds = (cosine_sim(contexts[0], contexts[1]) + 1)/2 > trashold\n",
        "    accuracy.append(binary_accuracy(preds, y))\n",
        "\n",
        "accuracy = sum(accuracy) / len(accuracy)\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.7117, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7snbBLkCjqZ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5jhCPl2CkF5"
      },
      "source": [
        "### WITH STOP WORDS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcenvoVSKtsf"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb7086b9KuKu",
        "outputId": "5ddea992-95fc-4d0d-a862-a30d4c33a159"
      },
      "source": [
        "def context_train_step_2(model, batch):\n",
        "    (unk_context, rnn_context), preds, loss = model(*list(batch))\n",
        "    return {'loss': loss, 'batch_accuracy': binary_accuracy(preds, batch[-1])}\n",
        "\n",
        "def context_eval_step_2(model, batch):\n",
        "    (unk_context, rnn_context), preds, loss = model(*list(batch))\n",
        "    return loss, binary_accuracy(preds, batch[-1])\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, eval_step):\n",
        "    model.eval()\n",
        "    results = []\n",
        "    losses = []\n",
        "    \n",
        "    for k in range(10):\n",
        "        for i, batch in enumerate(data_loader):\n",
        "            loss, metric = eval_step(model, batch)\n",
        "            losses.append(loss.item())\n",
        "            results.append(metric)\n",
        "\n",
        "    return sum(losses) / len(losses), sum(results) / len(results)\n",
        "\n",
        "\n",
        "\n",
        "model_context = ContextEncoder(ContextParams(), vectors, \n",
        "                               train_dataset_context.get_used_tokens(True), \n",
        "                               binary_mode=True,\n",
        "                               #cosine_mode=True,\n",
        "                               with_pos_tags=False,\n",
        "                               ).to('cuda')\n",
        "optim_context = torch.optim.Adam(model_context.parameters(), lr=0.0001)\n",
        "\n",
        "\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(optim_context, 5000, 0.5)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim_context, factor=0.9, verbose=True)\n",
        "\n",
        "\n",
        "#scheduler=None\n",
        "best_model = {}\n",
        "\n",
        "best_state_dict, _ = train(train_loader_context, valid_loader_context, \n",
        "      model_context, optim_context, \n",
        "      context_train_step_2, \n",
        "      context_eval_step_2,\n",
        "      300, best_model, \n",
        "      best_model_mode='accuracy', \n",
        "      scheduler=scheduler)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss: 0.753318 \t\t Validation loss: 0.719353\n",
            "BEST SCORE: tensor(0.5050, device='cuda:0')\n",
            "Training average batch accuracy: 0.502250\n",
            "Validation average batch accuracy: 0.505029\n",
            "Epoch 1: Loss: 0.734051 \t\t Validation loss: 0.692494\n",
            "BEST SCORE: tensor(0.5508, device='cuda:0')\n",
            "Training average batch accuracy: 0.524000\n",
            "Validation average batch accuracy: 0.550781\n",
            "Epoch 2: Loss: 0.706558 \t\t Validation loss: 0.667323\n",
            "BEST SCORE: tensor(0.5857, device='cuda:0')\n",
            "Training average batch accuracy: 0.552125\n",
            "Validation average batch accuracy: 0.585693\n",
            "Epoch 3: Loss: 0.685875 \t\t Validation loss: 0.654890\n",
            "BEST SCORE: tensor(0.6052, device='cuda:0')\n",
            "Training average batch accuracy: 0.575438\n",
            "Validation average batch accuracy: 0.605176\n",
            "Epoch 4: Loss: 0.675505 \t\t Validation loss: 0.650742\n",
            "BEST SCORE: tensor(0.6123, device='cuda:0')\n",
            "Training average batch accuracy: 0.587438\n",
            "Validation average batch accuracy: 0.612305\n",
            "Epoch 5: Loss: 0.669580 \t\t Validation loss: 0.645241\n",
            "BEST SCORE: tensor(0.6179, device='cuda:0')\n",
            "Training average batch accuracy: 0.592563\n",
            "Validation average batch accuracy: 0.617871\n",
            "Epoch 6: Loss: 0.658387 \t\t Validation loss: 0.652513\n",
            "Training average batch accuracy: 0.609875\n",
            "Validation average batch accuracy: 0.609522\n",
            "Epoch 7: Loss: 0.656301 \t\t Validation loss: 0.644061\n",
            "BEST SCORE: tensor(0.6233, device='cuda:0')\n",
            "Training average batch accuracy: 0.609688\n",
            "Validation average batch accuracy: 0.623340\n",
            "Epoch 8: Loss: 0.651194 \t\t Validation loss: 0.632576\n",
            "BEST SCORE: tensor(0.6388, device='cuda:0')\n",
            "Training average batch accuracy: 0.617063\n",
            "Validation average batch accuracy: 0.638770\n",
            "Epoch 9: Loss: 0.652437 \t\t Validation loss: 0.636284\n",
            "Training average batch accuracy: 0.614375\n",
            "Validation average batch accuracy: 0.636963\n",
            "Epoch 10: Loss: 0.641084 \t\t Validation loss: 0.624780\n",
            "BEST SCORE: tensor(0.6469, device='cuda:0')\n",
            "Training average batch accuracy: 0.630063\n",
            "Validation average batch accuracy: 0.646875\n",
            "Epoch 11: Loss: 0.639118 \t\t Validation loss: 0.620365\n",
            "BEST SCORE: tensor(0.6484, device='cuda:0')\n",
            "Training average batch accuracy: 0.630563\n",
            "Validation average batch accuracy: 0.648438\n",
            "Epoch 12: Loss: 0.636988 \t\t Validation loss: 0.614654\n",
            "BEST SCORE: tensor(0.6568, device='cuda:0')\n",
            "Training average batch accuracy: 0.638063\n",
            "Validation average batch accuracy: 0.656836\n",
            "Epoch 13: Loss: 0.634398 \t\t Validation loss: 0.611225\n",
            "BEST SCORE: tensor(0.6610, device='cuda:0')\n",
            "Training average batch accuracy: 0.638188\n",
            "Validation average batch accuracy: 0.661035\n",
            "Epoch 14: Loss: 0.621838 \t\t Validation loss: 0.609236\n",
            "BEST SCORE: tensor(0.6657, device='cuda:0')\n",
            "Training average batch accuracy: 0.651313\n",
            "Validation average batch accuracy: 0.665674\n",
            "Epoch 15: Loss: 0.624763 \t\t Validation loss: 0.604849\n",
            "BEST SCORE: tensor(0.6718, device='cuda:0')\n",
            "Training average batch accuracy: 0.648188\n",
            "Validation average batch accuracy: 0.671777\n",
            "Epoch 16: Loss: 0.621135 \t\t Validation loss: 0.592867\n",
            "BEST SCORE: tensor(0.6806, device='cuda:0')\n",
            "Training average batch accuracy: 0.648250\n",
            "Validation average batch accuracy: 0.680615\n",
            "Epoch 17: Loss: 0.612198 \t\t Validation loss: 0.609587\n",
            "Training average batch accuracy: 0.662188\n",
            "Validation average batch accuracy: 0.663184\n",
            "Epoch 18: Loss: 0.618938 \t\t Validation loss: 0.587821\n",
            "BEST SCORE: tensor(0.6878, device='cuda:0')\n",
            "Training average batch accuracy: 0.654688\n",
            "Validation average batch accuracy: 0.687793\n",
            "Epoch 19: Loss: 0.605468 \t\t Validation loss: 0.588942\n",
            "Training average batch accuracy: 0.668563\n",
            "Validation average batch accuracy: 0.684619\n",
            "Epoch 20: Loss: 0.618652 \t\t Validation loss: 0.578705\n",
            "BEST SCORE: tensor(0.6966, device='cuda:0')\n",
            "Training average batch accuracy: 0.655563\n",
            "Validation average batch accuracy: 0.696631\n",
            "Epoch 21: Loss: 0.608043 \t\t Validation loss: 0.577421\n",
            "Training average batch accuracy: 0.667938\n",
            "Validation average batch accuracy: 0.695312\n",
            "Epoch 22: Loss: 0.605997 \t\t Validation loss: 0.578229\n",
            "Training average batch accuracy: 0.666000\n",
            "Validation average batch accuracy: 0.692090\n",
            "Epoch 23: Loss: 0.600279 \t\t Validation loss: 0.577044\n",
            "Training average batch accuracy: 0.673375\n",
            "Validation average batch accuracy: 0.687695\n",
            "Epoch 24: Loss: 0.596706 \t\t Validation loss: 0.570400\n",
            "BEST SCORE: tensor(0.7002, device='cuda:0')\n",
            "Training average batch accuracy: 0.677813\n",
            "Validation average batch accuracy: 0.700195\n",
            "Epoch 25: Loss: 0.593434 \t\t Validation loss: 0.572418\n",
            "Training average batch accuracy: 0.679563\n",
            "Validation average batch accuracy: 0.698389\n",
            "Epoch 26: Loss: 0.596160 \t\t Validation loss: 0.563423\n",
            "BEST SCORE: tensor(0.7077, device='cuda:0')\n",
            "Training average batch accuracy: 0.682000\n",
            "Validation average batch accuracy: 0.707666\n",
            "Epoch 27: Loss: 0.584915 \t\t Validation loss: 0.558563\n",
            "BEST SCORE: tensor(0.7078, device='cuda:0')\n",
            "Training average batch accuracy: 0.690563\n",
            "Validation average batch accuracy: 0.707764\n",
            "Epoch 28: Loss: 0.586992 \t\t Validation loss: 0.562401\n",
            "BEST SCORE: tensor(0.7102, device='cuda:0')\n",
            "Training average batch accuracy: 0.690063\n",
            "Validation average batch accuracy: 0.710205\n",
            "Epoch 29: Loss: 0.588974 \t\t Validation loss: 0.552601\n",
            "BEST SCORE: tensor(0.7169, device='cuda:0')\n",
            "Training average batch accuracy: 0.685063\n",
            "Validation average batch accuracy: 0.716943\n",
            "Epoch 30: Loss: 0.587563 \t\t Validation loss: 0.560907\n",
            "Training average batch accuracy: 0.684750\n",
            "Validation average batch accuracy: 0.708057\n",
            "Epoch 31: Loss: 0.581371 \t\t Validation loss: 0.552595\n",
            "Training average batch accuracy: 0.695000\n",
            "Validation average batch accuracy: 0.714893\n",
            "Epoch 32: Loss: 0.579557 \t\t Validation loss: 0.547960\n",
            "BEST SCORE: tensor(0.7227, device='cuda:0')\n",
            "Training average batch accuracy: 0.692000\n",
            "Validation average batch accuracy: 0.722656\n",
            "Epoch 33: Loss: 0.582511 \t\t Validation loss: 0.550247\n",
            "Training average batch accuracy: 0.690125\n",
            "Validation average batch accuracy: 0.720313\n",
            "Epoch 34: Loss: 0.579337 \t\t Validation loss: 0.545284\n",
            "BEST SCORE: tensor(0.7271, device='cuda:0')\n",
            "Training average batch accuracy: 0.694438\n",
            "Validation average batch accuracy: 0.727148\n",
            "Epoch 35: Loss: 0.575813 \t\t Validation loss: 0.539099\n",
            "BEST SCORE: tensor(0.7276, device='cuda:0')\n",
            "Training average batch accuracy: 0.699625\n",
            "Validation average batch accuracy: 0.727588\n",
            "Epoch 36: Loss: 0.566921 \t\t Validation loss: 0.541760\n",
            "Training average batch accuracy: 0.706063\n",
            "Validation average batch accuracy: 0.727490\n",
            "Epoch 37: Loss: 0.575055 \t\t Validation loss: 0.545114\n",
            "Training average batch accuracy: 0.699438\n",
            "Validation average batch accuracy: 0.721338\n",
            "Epoch 38: Loss: 0.571676 \t\t Validation loss: 0.539520\n",
            "BEST SCORE: tensor(0.7299, device='cuda:0')\n",
            "Training average batch accuracy: 0.700750\n",
            "Validation average batch accuracy: 0.729932\n",
            "Epoch 39: Loss: 0.576638 \t\t Validation loss: 0.531357\n",
            "BEST SCORE: tensor(0.7342, device='cuda:0')\n",
            "Training average batch accuracy: 0.698250\n",
            "Validation average batch accuracy: 0.734229\n",
            "Epoch 40: Loss: 0.571196 \t\t Validation loss: 0.531414\n",
            "BEST SCORE: tensor(0.7377, device='cuda:0')\n",
            "Training average batch accuracy: 0.700750\n",
            "Validation average batch accuracy: 0.737695\n",
            "Epoch 41: Loss: 0.563788 \t\t Validation loss: 0.533387\n",
            "Training average batch accuracy: 0.710188\n",
            "Validation average batch accuracy: 0.734522\n",
            "Epoch 42: Loss: 0.569857 \t\t Validation loss: 0.542673\n",
            "Training average batch accuracy: 0.706000\n",
            "Validation average batch accuracy: 0.729248\n",
            "Epoch 43: Loss: 0.564863 \t\t Validation loss: 0.529945\n",
            "BEST SCORE: tensor(0.7412, device='cuda:0')\n",
            "Training average batch accuracy: 0.708938\n",
            "Validation average batch accuracy: 0.741211\n",
            "Epoch 44: Loss: 0.561370 \t\t Validation loss: 0.526954\n",
            "Training average batch accuracy: 0.708625\n",
            "Validation average batch accuracy: 0.738867\n",
            "Epoch 45: Loss: 0.562910 \t\t Validation loss: 0.528132\n",
            "Training average batch accuracy: 0.705250\n",
            "Validation average batch accuracy: 0.739062\n",
            "Epoch 46: Loss: 0.553875 \t\t Validation loss: 0.522006\n",
            "BEST SCORE: tensor(0.7417, device='cuda:0')\n",
            "Training average batch accuracy: 0.720563\n",
            "Validation average batch accuracy: 0.741748\n",
            "Epoch 47: Loss: 0.557422 \t\t Validation loss: 0.524554\n",
            "Training average batch accuracy: 0.716063\n",
            "Validation average batch accuracy: 0.739746\n",
            "Epoch 48: Loss: 0.555588 \t\t Validation loss: 0.523916\n",
            "BEST SCORE: tensor(0.7429, device='cuda:0')\n",
            "Training average batch accuracy: 0.717000\n",
            "Validation average batch accuracy: 0.742920\n",
            "Epoch 49: Loss: 0.552245 \t\t Validation loss: 0.526013\n",
            "Training average batch accuracy: 0.718000\n",
            "Validation average batch accuracy: 0.742627\n",
            "Epoch 50: Loss: 0.553016 \t\t Validation loss: 0.516777\n",
            "BEST SCORE: tensor(0.7465, device='cuda:0')\n",
            "Training average batch accuracy: 0.716000\n",
            "Validation average batch accuracy: 0.746484\n",
            "Epoch 51: Loss: 0.557517 \t\t Validation loss: 0.525848\n",
            "Training average batch accuracy: 0.714000\n",
            "Validation average batch accuracy: 0.741162\n",
            "Epoch 52: Loss: 0.549285 \t\t Validation loss: 0.520929\n",
            "Training average batch accuracy: 0.720688\n",
            "Validation average batch accuracy: 0.744482\n",
            "Epoch 53: Loss: 0.551917 \t\t Validation loss: 0.517871\n",
            "BEST SCORE: tensor(0.7501, device='cuda:0')\n",
            "Training average batch accuracy: 0.717000\n",
            "Validation average batch accuracy: 0.750098\n",
            "Epoch 54: Loss: 0.546680 \t\t Validation loss: 0.513087\n",
            "BEST SCORE: tensor(0.7504, device='cuda:0')\n",
            "Training average batch accuracy: 0.725813\n",
            "Validation average batch accuracy: 0.750391\n",
            "Epoch 55: Loss: 0.542365 \t\t Validation loss: 0.510325\n",
            "BEST SCORE: tensor(0.7508, device='cuda:0')\n",
            "Training average batch accuracy: 0.727625\n",
            "Validation average batch accuracy: 0.750781\n",
            "Epoch 56: Loss: 0.547337 \t\t Validation loss: 0.519211\n",
            "Training average batch accuracy: 0.723938\n",
            "Validation average batch accuracy: 0.749170\n",
            "Epoch 57: Loss: 0.545295 \t\t Validation loss: 0.507800\n",
            "BEST SCORE: tensor(0.7524, device='cuda:0')\n",
            "Training average batch accuracy: 0.722375\n",
            "Validation average batch accuracy: 0.752441\n",
            "Epoch 58: Loss: 0.542902 \t\t Validation loss: 0.515850\n",
            "Training average batch accuracy: 0.723688\n",
            "Validation average batch accuracy: 0.745850\n",
            "Epoch 59: Loss: 0.547746 \t\t Validation loss: 0.514403\n",
            "Training average batch accuracy: 0.721188\n",
            "Validation average batch accuracy: 0.746826\n",
            "Epoch 60: Loss: 0.546128 \t\t Validation loss: 0.507969\n",
            "BEST SCORE: tensor(0.7541, device='cuda:0')\n",
            "Training average batch accuracy: 0.721875\n",
            "Validation average batch accuracy: 0.754053\n",
            "Epoch 61: Loss: 0.542762 \t\t Validation loss: 0.500770\n",
            "BEST SCORE: tensor(0.7568, device='cuda:0')\n",
            "Training average batch accuracy: 0.722375\n",
            "Validation average batch accuracy: 0.756836\n",
            "Epoch 62: Loss: 0.543102 \t\t Validation loss: 0.502010\n",
            "BEST SCORE: tensor(0.7591, device='cuda:0')\n",
            "Training average batch accuracy: 0.729188\n",
            "Validation average batch accuracy: 0.759082\n",
            "Epoch 63: Loss: 0.544713 \t\t Validation loss: 0.504725\n",
            "Training average batch accuracy: 0.725688\n",
            "Validation average batch accuracy: 0.758105\n",
            "Epoch 64: Loss: 0.537416 \t\t Validation loss: 0.509321\n",
            "Training average batch accuracy: 0.730313\n",
            "Validation average batch accuracy: 0.751465\n",
            "Epoch 65: Loss: 0.537201 \t\t Validation loss: 0.506514\n",
            "Training average batch accuracy: 0.730875\n",
            "Validation average batch accuracy: 0.757031\n",
            "Epoch 66: Loss: 0.536110 \t\t Validation loss: 0.502871\n",
            "BEST SCORE: tensor(0.7598, device='cuda:0')\n",
            "Training average batch accuracy: 0.731625\n",
            "Validation average batch accuracy: 0.759814\n",
            "Epoch 67: Loss: 0.531286 \t\t Validation loss: 0.499684\n",
            "BEST SCORE: tensor(0.7619, device='cuda:0')\n",
            "Training average batch accuracy: 0.737563\n",
            "Validation average batch accuracy: 0.761914\n",
            "Epoch 68: Loss: 0.542378 \t\t Validation loss: 0.496269\n",
            "Training average batch accuracy: 0.723250\n",
            "Validation average batch accuracy: 0.761914\n",
            "Epoch 69: Loss: 0.527491 \t\t Validation loss: 0.499688\n",
            "Training average batch accuracy: 0.738688\n",
            "Validation average batch accuracy: 0.759668\n",
            "Epoch 70: Loss: 0.543048 \t\t Validation loss: 0.499007\n",
            "Training average batch accuracy: 0.727125\n",
            "Validation average batch accuracy: 0.759521\n",
            "Epoch 71: Loss: 0.537461 \t\t Validation loss: 0.495356\n",
            "BEST SCORE: tensor(0.7655, device='cuda:0')\n",
            "Training average batch accuracy: 0.731375\n",
            "Validation average batch accuracy: 0.765527\n",
            "Epoch 72: Loss: 0.536757 \t\t Validation loss: 0.502671\n",
            "Training average batch accuracy: 0.733125\n",
            "Validation average batch accuracy: 0.760498\n",
            "Epoch 73: Loss: 0.533723 \t\t Validation loss: 0.498315\n",
            "Training average batch accuracy: 0.733625\n",
            "Validation average batch accuracy: 0.762451\n",
            "Epoch 74: Loss: 0.534489 \t\t Validation loss: 0.497435\n",
            "Training average batch accuracy: 0.732875\n",
            "Validation average batch accuracy: 0.760791\n",
            "Epoch 75: Loss: 0.533884 \t\t Validation loss: 0.496142\n",
            "Training average batch accuracy: 0.730250\n",
            "Validation average batch accuracy: 0.763477\n",
            "Epoch 76: Loss: 0.527769 \t\t Validation loss: 0.492918\n",
            "Training average batch accuracy: 0.737000\n",
            "Validation average batch accuracy: 0.763135\n",
            "Epoch 77: Loss: 0.537582 \t\t Validation loss: 0.488405\n",
            "BEST SCORE: tensor(0.7668, device='cuda:0')\n",
            "Training average batch accuracy: 0.727688\n",
            "Validation average batch accuracy: 0.766797\n",
            "Epoch 78: Loss: 0.533826 \t\t Validation loss: 0.493756\n",
            "Training average batch accuracy: 0.733063\n",
            "Validation average batch accuracy: 0.764746\n",
            "Epoch 79: Loss: 0.533062 \t\t Validation loss: 0.497909\n",
            "Training average batch accuracy: 0.734813\n",
            "Validation average batch accuracy: 0.764502\n",
            "Epoch 80: Loss: 0.529337 \t\t Validation loss: 0.485019\n",
            "BEST SCORE: tensor(0.7693, device='cuda:0')\n",
            "Training average batch accuracy: 0.741000\n",
            "Validation average batch accuracy: 0.769287\n",
            "Epoch 81: Loss: 0.523857 \t\t Validation loss: 0.489701\n",
            "Training average batch accuracy: 0.739000\n",
            "Validation average batch accuracy: 0.762939\n",
            "Epoch 82: Loss: 0.531248 \t\t Validation loss: 0.483511\n",
            "BEST SCORE: tensor(0.7706, device='cuda:0')\n",
            "Training average batch accuracy: 0.734250\n",
            "Validation average batch accuracy: 0.770606\n",
            "Epoch 83: Loss: 0.525174 \t\t Validation loss: 0.483691\n",
            "BEST SCORE: tensor(0.7707, device='cuda:0')\n",
            "Training average batch accuracy: 0.738875\n",
            "Validation average batch accuracy: 0.770654\n",
            "Epoch 84: Loss: 0.524940 \t\t Validation loss: 0.483221\n",
            "Training average batch accuracy: 0.740313\n",
            "Validation average batch accuracy: 0.770508\n",
            "Epoch 85: Loss: 0.518272 \t\t Validation loss: 0.484140\n",
            "Training average batch accuracy: 0.749688\n",
            "Validation average batch accuracy: 0.770068\n",
            "Epoch 86: Loss: 0.517945 \t\t Validation loss: 0.485065\n",
            "Training average batch accuracy: 0.742563\n",
            "Validation average batch accuracy: 0.766797\n",
            "Epoch 87: Loss: 0.520477 \t\t Validation loss: 0.479630\n",
            "BEST SCORE: tensor(0.7719, device='cuda:0')\n",
            "Training average batch accuracy: 0.745000\n",
            "Validation average batch accuracy: 0.771875\n",
            "Epoch 88: Loss: 0.523449 \t\t Validation loss: 0.487898\n",
            "Training average batch accuracy: 0.740563\n",
            "Validation average batch accuracy: 0.765479\n",
            "Epoch 89: Loss: 0.527007 \t\t Validation loss: 0.482073\n",
            "Training average batch accuracy: 0.737250\n",
            "Validation average batch accuracy: 0.770117\n",
            "Epoch 90: Loss: 0.513784 \t\t Validation loss: 0.482259\n",
            "BEST SCORE: tensor(0.7728, device='cuda:0')\n",
            "Training average batch accuracy: 0.749688\n",
            "Validation average batch accuracy: 0.772754\n",
            "Epoch 91: Loss: 0.518864 \t\t Validation loss: 0.494133\n",
            "Training average batch accuracy: 0.742500\n",
            "Validation average batch accuracy: 0.762793\n",
            "Epoch 92: Loss: 0.521549 \t\t Validation loss: 0.485055\n",
            "Training average batch accuracy: 0.745188\n",
            "Validation average batch accuracy: 0.768897\n",
            "Epoch 93: Loss: 0.513603 \t\t Validation loss: 0.477775\n",
            "Training average batch accuracy: 0.747063\n",
            "Validation average batch accuracy: 0.772461\n",
            "Epoch 94: Loss: 0.511392 \t\t Validation loss: 0.482031\n",
            "Training average batch accuracy: 0.750625\n",
            "Validation average batch accuracy: 0.772412\n",
            "Epoch 95: Loss: 0.514218 \t\t Validation loss: 0.485643\n",
            "Training average batch accuracy: 0.750813\n",
            "Validation average batch accuracy: 0.768359\n",
            "Epoch 96: Loss: 0.517492 \t\t Validation loss: 0.474684\n",
            "BEST SCORE: tensor(0.7740, device='cuda:0')\n",
            "Training average batch accuracy: 0.747063\n",
            "Validation average batch accuracy: 0.774023\n",
            "Epoch 97: Loss: 0.515819 \t\t Validation loss: 0.477094\n",
            "Training average batch accuracy: 0.745375\n",
            "Validation average batch accuracy: 0.771289\n",
            "Epoch 98: Loss: 0.516677 \t\t Validation loss: 0.474958\n",
            "Training average batch accuracy: 0.747000\n",
            "Validation average batch accuracy: 0.773047\n",
            "Epoch 99: Loss: 0.516481 \t\t Validation loss: 0.474587\n",
            "BEST SCORE: tensor(0.7743, device='cuda:0')\n",
            "Training average batch accuracy: 0.745375\n",
            "Validation average batch accuracy: 0.774268\n",
            "Epoch 100: Loss: 0.513392 \t\t Validation loss: 0.483291\n",
            "Training average batch accuracy: 0.748500\n",
            "Validation average batch accuracy: 0.771094\n",
            "Epoch 101: Loss: 0.513599 \t\t Validation loss: 0.474054\n",
            "BEST SCORE: tensor(0.7752, device='cuda:0')\n",
            "Training average batch accuracy: 0.746563\n",
            "Validation average batch accuracy: 0.775244\n",
            "Epoch 102: Loss: 0.523101 \t\t Validation loss: 0.468760\n",
            "BEST SCORE: tensor(0.7776, device='cuda:0')\n",
            "Training average batch accuracy: 0.744000\n",
            "Validation average batch accuracy: 0.777637\n",
            "Epoch 103: Loss: 0.514865 \t\t Validation loss: 0.473651\n",
            "Training average batch accuracy: 0.751000\n",
            "Validation average batch accuracy: 0.773779\n",
            "Epoch 104: Loss: 0.519880 \t\t Validation loss: 0.474139\n",
            "Training average batch accuracy: 0.743375\n",
            "Validation average batch accuracy: 0.774707\n",
            "Epoch 105: Loss: 0.511113 \t\t Validation loss: 0.472719\n",
            "Training average batch accuracy: 0.748250\n",
            "Validation average batch accuracy: 0.777100\n",
            "Epoch 106: Loss: 0.518541 \t\t Validation loss: 0.474670\n",
            "BEST SCORE: tensor(0.7783, device='cuda:0')\n",
            "Training average batch accuracy: 0.745188\n",
            "Validation average batch accuracy: 0.778271\n",
            "Epoch 107: Loss: 0.506084 \t\t Validation loss: 0.467986\n",
            "BEST SCORE: tensor(0.7833, device='cuda:0')\n",
            "Training average batch accuracy: 0.751563\n",
            "Validation average batch accuracy: 0.783252\n",
            "Epoch 108: Loss: 0.509471 \t\t Validation loss: 0.473230\n",
            "Training average batch accuracy: 0.753375\n",
            "Validation average batch accuracy: 0.777930\n",
            "Epoch 109: Loss: 0.511645 \t\t Validation loss: 0.470359\n",
            "Training average batch accuracy: 0.750375\n",
            "Validation average batch accuracy: 0.776855\n",
            "Epoch 110: Loss: 0.503558 \t\t Validation loss: 0.468011\n",
            "Training average batch accuracy: 0.755313\n",
            "Validation average batch accuracy: 0.779199\n",
            "Epoch 111: Loss: 0.507387 \t\t Validation loss: 0.469355\n",
            "Training average batch accuracy: 0.750938\n",
            "Validation average batch accuracy: 0.781006\n",
            "Epoch 112: Loss: 0.506716 \t\t Validation loss: 0.467880\n",
            "Training average batch accuracy: 0.749875\n",
            "Validation average batch accuracy: 0.779590\n",
            "Epoch 113: Loss: 0.508930 \t\t Validation loss: 0.470948\n",
            "Training average batch accuracy: 0.749938\n",
            "Validation average batch accuracy: 0.775977\n",
            "Epoch 114: Loss: 0.506180 \t\t Validation loss: 0.472181\n",
            "Training average batch accuracy: 0.753938\n",
            "Validation average batch accuracy: 0.777002\n",
            "Epoch 115: Loss: 0.510996 \t\t Validation loss: 0.465120\n",
            "BEST SCORE: tensor(0.7839, device='cuda:0')\n",
            "Training average batch accuracy: 0.752688\n",
            "Validation average batch accuracy: 0.783936\n",
            "Epoch 116: Loss: 0.508621 \t\t Validation loss: 0.461136\n",
            "Training average batch accuracy: 0.754625\n",
            "Validation average batch accuracy: 0.782764\n",
            "Epoch 117: Loss: 0.503242 \t\t Validation loss: 0.464045\n",
            "Training average batch accuracy: 0.757250\n",
            "Validation average batch accuracy: 0.782422\n",
            "Epoch 118: Loss: 0.509401 \t\t Validation loss: 0.468632\n",
            "Training average batch accuracy: 0.747875\n",
            "Validation average batch accuracy: 0.778662\n",
            "Epoch 119: Loss: 0.500690 \t\t Validation loss: 0.454159\n",
            "BEST SCORE: tensor(0.7892, device='cuda:0')\n",
            "Training average batch accuracy: 0.757813\n",
            "Validation average batch accuracy: 0.789209\n",
            "Epoch 120: Loss: 0.508356 \t\t Validation loss: 0.463427\n",
            "Training average batch accuracy: 0.752188\n",
            "Validation average batch accuracy: 0.782373\n",
            "Epoch 121: Loss: 0.501655 \t\t Validation loss: 0.466871\n",
            "Training average batch accuracy: 0.754000\n",
            "Validation average batch accuracy: 0.780713\n",
            "Epoch 122: Loss: 0.503535 \t\t Validation loss: 0.458735\n",
            "Training average batch accuracy: 0.755313\n",
            "Validation average batch accuracy: 0.783105\n",
            "Epoch 123: Loss: 0.505265 \t\t Validation loss: 0.455179\n",
            "Training average batch accuracy: 0.754125\n",
            "Validation average batch accuracy: 0.788379\n",
            "Epoch 124: Loss: 0.501587 \t\t Validation loss: 0.453368\n",
            "Training average batch accuracy: 0.755938\n",
            "Validation average batch accuracy: 0.788574\n",
            "Epoch 125: Loss: 0.493106 \t\t Validation loss: 0.456746\n",
            "Training average batch accuracy: 0.763500\n",
            "Validation average batch accuracy: 0.786279\n",
            "Epoch 126: Loss: 0.503481 \t\t Validation loss: 0.458450\n",
            "Training average batch accuracy: 0.754438\n",
            "Validation average batch accuracy: 0.786963\n",
            "Epoch 127: Loss: 0.495729 \t\t Validation loss: 0.464043\n",
            "Training average batch accuracy: 0.765438\n",
            "Validation average batch accuracy: 0.781494\n",
            "Epoch 128: Loss: 0.491758 \t\t Validation loss: 0.459258\n",
            "Training average batch accuracy: 0.764438\n",
            "Validation average batch accuracy: 0.784814\n",
            "Epoch 129: Loss: 0.490589 \t\t Validation loss: 0.457700\n",
            "Training average batch accuracy: 0.766563\n",
            "Validation average batch accuracy: 0.786035\n",
            "Epoch 130: Loss: 0.500580 \t\t Validation loss: 0.451420\n",
            "Training average batch accuracy: 0.758813\n",
            "Validation average batch accuracy: 0.788672\n",
            "Epoch 131: Loss: 0.491994 \t\t Validation loss: 0.462193\n",
            "Training average batch accuracy: 0.766625\n",
            "Validation average batch accuracy: 0.783789\n",
            "Epoch 132: Loss: 0.500126 \t\t Validation loss: 0.452778\n",
            "BEST SCORE: tensor(0.7903, device='cuda:0')\n",
            "Training average batch accuracy: 0.757625\n",
            "Validation average batch accuracy: 0.790332\n",
            "Epoch 133: Loss: 0.490929 \t\t Validation loss: 0.448147\n",
            "BEST SCORE: tensor(0.7924, device='cuda:0')\n",
            "Training average batch accuracy: 0.763813\n",
            "Validation average batch accuracy: 0.792383\n",
            "Epoch 134: Loss: 0.498052 \t\t Validation loss: 0.455142\n",
            "Training average batch accuracy: 0.754625\n",
            "Validation average batch accuracy: 0.785986\n",
            "Epoch 135: Loss: 0.500210 \t\t Validation loss: 0.453550\n",
            "Training average batch accuracy: 0.755188\n",
            "Validation average batch accuracy: 0.789648\n",
            "Epoch 136: Loss: 0.497026 \t\t Validation loss: 0.440976\n",
            "BEST SCORE: tensor(0.7933, device='cuda:0')\n",
            "Training average batch accuracy: 0.764563\n",
            "Validation average batch accuracy: 0.793311\n",
            "Epoch 137: Loss: 0.494789 \t\t Validation loss: 0.451593\n",
            "Training average batch accuracy: 0.763000\n",
            "Validation average batch accuracy: 0.791455\n",
            "Epoch 138: Loss: 0.486157 \t\t Validation loss: 0.454490\n",
            "Training average batch accuracy: 0.769313\n",
            "Validation average batch accuracy: 0.788330\n",
            "Epoch 139: Loss: 0.491099 \t\t Validation loss: 0.457927\n",
            "Training average batch accuracy: 0.764313\n",
            "Validation average batch accuracy: 0.787158\n",
            "Epoch 140: Loss: 0.492645 \t\t Validation loss: 0.442065\n",
            "BEST SCORE: tensor(0.7944, device='cuda:0')\n",
            "Training average batch accuracy: 0.762000\n",
            "Validation average batch accuracy: 0.794434\n",
            "Epoch 141: Loss: 0.491991 \t\t Validation loss: 0.449705\n",
            "Training average batch accuracy: 0.760250\n",
            "Validation average batch accuracy: 0.788721\n",
            "Epoch 142: Loss: 0.492553 \t\t Validation loss: 0.451165\n",
            "Training average batch accuracy: 0.760813\n",
            "Validation average batch accuracy: 0.792090\n",
            "Epoch 143: Loss: 0.493147 \t\t Validation loss: 0.442040\n",
            "BEST SCORE: tensor(0.7965, device='cuda:0')\n",
            "Training average batch accuracy: 0.761250\n",
            "Validation average batch accuracy: 0.796484\n",
            "Epoch 144: Loss: 0.489132 \t\t Validation loss: 0.440135\n",
            "Training average batch accuracy: 0.766938\n",
            "Validation average batch accuracy: 0.793994\n",
            "Epoch 145: Loss: 0.492030 \t\t Validation loss: 0.450317\n",
            "Training average batch accuracy: 0.765563\n",
            "Validation average batch accuracy: 0.792139\n",
            "Epoch 146: Loss: 0.493608 \t\t Validation loss: 0.447099\n",
            "Training average batch accuracy: 0.763000\n",
            "Validation average batch accuracy: 0.790234\n",
            "Epoch 147: Loss: 0.494449 \t\t Validation loss: 0.444065\n",
            "Training average batch accuracy: 0.765313\n",
            "Validation average batch accuracy: 0.795605\n",
            "Epoch 148: Loss: 0.490054 \t\t Validation loss: 0.448865\n",
            "Training average batch accuracy: 0.765500\n",
            "Validation average batch accuracy: 0.791943\n",
            "Epoch 149: Loss: 0.488789 \t\t Validation loss: 0.447739\n",
            "Training average batch accuracy: 0.766625\n",
            "Validation average batch accuracy: 0.791943\n",
            "Epoch 150: Loss: 0.488020 \t\t Validation loss: 0.445002\n",
            "Training average batch accuracy: 0.765750\n",
            "Validation average batch accuracy: 0.793848\n",
            "Epoch 151: Loss: 0.481729 \t\t Validation loss: 0.441843\n",
            "BEST SCORE: tensor(0.7993, device='cuda:0')\n",
            "Training average batch accuracy: 0.772125\n",
            "Validation average batch accuracy: 0.799316\n",
            "Epoch 152: Loss: 0.488284 \t\t Validation loss: 0.446237\n",
            "Training average batch accuracy: 0.765063\n",
            "Validation average batch accuracy: 0.793555\n",
            "Epoch 153: Loss: 0.488241 \t\t Validation loss: 0.437397\n",
            "BEST SCORE: tensor(0.8021, device='cuda:0')\n",
            "Training average batch accuracy: 0.764938\n",
            "Validation average batch accuracy: 0.802148\n",
            "Epoch 154: Loss: 0.477946 \t\t Validation loss: 0.442030\n",
            "Training average batch accuracy: 0.773250\n",
            "Validation average batch accuracy: 0.797461\n",
            "Epoch 155: Loss: 0.484791 \t\t Validation loss: 0.450507\n",
            "Training average batch accuracy: 0.766250\n",
            "Validation average batch accuracy: 0.790576\n",
            "Epoch 156: Loss: 0.481918 \t\t Validation loss: 0.439658\n",
            "Training average batch accuracy: 0.770375\n",
            "Validation average batch accuracy: 0.798779\n",
            "Epoch 157: Loss: 0.477382 \t\t Validation loss: 0.440440\n",
            "Training average batch accuracy: 0.770313\n",
            "Validation average batch accuracy: 0.792627\n",
            "Epoch 158: Loss: 0.489990 \t\t Validation loss: 0.438018\n",
            "Training average batch accuracy: 0.766625\n",
            "Validation average batch accuracy: 0.797217\n",
            "Epoch 159: Loss: 0.481827 \t\t Validation loss: 0.441579\n",
            "Training average batch accuracy: 0.771938\n",
            "Validation average batch accuracy: 0.797070\n",
            "Epoch 160: Loss: 0.482385 \t\t Validation loss: 0.439911\n",
            "Training average batch accuracy: 0.772875\n",
            "Validation average batch accuracy: 0.797705\n",
            "Epoch 161: Loss: 0.483938 \t\t Validation loss: 0.444782\n",
            "Training average batch accuracy: 0.769500\n",
            "Validation average batch accuracy: 0.792578\n",
            "Epoch 162: Loss: 0.487509 \t\t Validation loss: 0.449031\n",
            "Training average batch accuracy: 0.770500\n",
            "Validation average batch accuracy: 0.792773\n",
            "Epoch 163: Loss: 0.480260 \t\t Validation loss: 0.432152\n",
            "Training average batch accuracy: 0.773813\n",
            "Validation average batch accuracy: 0.798584\n",
            "Epoch 164: Loss: 0.478397 \t\t Validation loss: 0.442165\n",
            "Training average batch accuracy: 0.770813\n",
            "Validation average batch accuracy: 0.795166\n",
            "Epoch 165: Loss: 0.479481 \t\t Validation loss: 0.436527\n",
            "Training average batch accuracy: 0.772750\n",
            "Validation average batch accuracy: 0.797949\n",
            "Epoch 166: Loss: 0.487614 \t\t Validation loss: 0.440132\n",
            "Training average batch accuracy: 0.767438\n",
            "Validation average batch accuracy: 0.798633\n",
            "Epoch 167: Loss: 0.474431 \t\t Validation loss: 0.433563\n",
            "Training average batch accuracy: 0.774563\n",
            "Validation average batch accuracy: 0.801270\n",
            "Epoch 168: Loss: 0.476374 \t\t Validation loss: 0.438743\n",
            "Training average batch accuracy: 0.772563\n",
            "Validation average batch accuracy: 0.796582\n",
            "Epoch 169: Loss: 0.473545 \t\t Validation loss: 0.430697\n",
            "Training average batch accuracy: 0.779625\n",
            "Validation average batch accuracy: 0.800147\n",
            "Epoch 170: Loss: 0.480304 \t\t Validation loss: 0.431367\n",
            "Training average batch accuracy: 0.774875\n",
            "Validation average batch accuracy: 0.800928\n",
            "Epoch 171: Loss: 0.479172 \t\t Validation loss: 0.434199\n",
            "Training average batch accuracy: 0.777188\n",
            "Validation average batch accuracy: 0.799170\n",
            "Epoch 172: Loss: 0.473685 \t\t Validation loss: 0.436576\n",
            "Training average batch accuracy: 0.775063\n",
            "Validation average batch accuracy: 0.796387\n",
            "Epoch 173: Loss: 0.482192 \t\t Validation loss: 0.427950\n",
            "BEST SCORE: tensor(0.8062, device='cuda:0')\n",
            "Training average batch accuracy: 0.773688\n",
            "Validation average batch accuracy: 0.806152\n",
            "Epoch 174: Loss: 0.483582 \t\t Validation loss: 0.431417\n",
            "BEST SCORE: tensor(0.8071, device='cuda:0')\n",
            "Training average batch accuracy: 0.770125\n",
            "Validation average batch accuracy: 0.807080\n",
            "Epoch 175: Loss: 0.476506 \t\t Validation loss: 0.433384\n",
            "Training average batch accuracy: 0.774438\n",
            "Validation average batch accuracy: 0.801807\n",
            "Epoch 176: Loss: 0.470965 \t\t Validation loss: 0.435243\n",
            "Training average batch accuracy: 0.774500\n",
            "Validation average batch accuracy: 0.801709\n",
            "Epoch 177: Loss: 0.472007 \t\t Validation loss: 0.430748\n",
            "Training average batch accuracy: 0.783125\n",
            "Validation average batch accuracy: 0.804541\n",
            "Epoch 178: Loss: 0.470571 \t\t Validation loss: 0.436188\n",
            "Training average batch accuracy: 0.780813\n",
            "Validation average batch accuracy: 0.801953\n",
            "Epoch 179: Loss: 0.474049 \t\t Validation loss: 0.427605\n",
            "BEST SCORE: tensor(0.8082, device='cuda:0')\n",
            "Training average batch accuracy: 0.776938\n",
            "Validation average batch accuracy: 0.808203\n",
            "Epoch 180: Loss: 0.486225 \t\t Validation loss: 0.428748\n",
            "Training average batch accuracy: 0.768063\n",
            "Validation average batch accuracy: 0.805664\n",
            "Epoch 181: Loss: 0.477640 \t\t Validation loss: 0.429074\n",
            "Training average batch accuracy: 0.776625\n",
            "Validation average batch accuracy: 0.805371\n",
            "Epoch 182: Loss: 0.471960 \t\t Validation loss: 0.428678\n",
            "Training average batch accuracy: 0.776438\n",
            "Validation average batch accuracy: 0.805420\n",
            "Epoch 183: Loss: 0.470699 \t\t Validation loss: 0.423407\n",
            "BEST SCORE: tensor(0.8094, device='cuda:0')\n",
            "Training average batch accuracy: 0.779375\n",
            "Validation average batch accuracy: 0.809375\n",
            "Epoch 184: Loss: 0.472869 \t\t Validation loss: 0.425913\n",
            "Training average batch accuracy: 0.774563\n",
            "Validation average batch accuracy: 0.804053\n",
            "Epoch 185: Loss: 0.469996 \t\t Validation loss: 0.430070\n",
            "Training average batch accuracy: 0.781000\n",
            "Validation average batch accuracy: 0.804248\n",
            "Epoch 186: Loss: 0.474364 \t\t Validation loss: 0.429789\n",
            "Training average batch accuracy: 0.777688\n",
            "Validation average batch accuracy: 0.806006\n",
            "Epoch 187: Loss: 0.472923 \t\t Validation loss: 0.429676\n",
            "Training average batch accuracy: 0.780375\n",
            "Validation average batch accuracy: 0.804443\n",
            "Epoch 188: Loss: 0.475397 \t\t Validation loss: 0.420408\n",
            "Training average batch accuracy: 0.777438\n",
            "Validation average batch accuracy: 0.809229\n",
            "Epoch 189: Loss: 0.473568 \t\t Validation loss: 0.424460\n",
            "Training average batch accuracy: 0.772500\n",
            "Validation average batch accuracy: 0.807520\n",
            "Epoch 190: Loss: 0.470550 \t\t Validation loss: 0.421261\n",
            "BEST SCORE: tensor(0.8107, device='cuda:0')\n",
            "Training average batch accuracy: 0.780938\n",
            "Validation average batch accuracy: 0.810693\n",
            "Epoch 191: Loss: 0.472888 \t\t Validation loss: 0.428747\n",
            "Training average batch accuracy: 0.780438\n",
            "Validation average batch accuracy: 0.803467\n",
            "Epoch 192: Loss: 0.472503 \t\t Validation loss: 0.417791\n",
            "BEST SCORE: tensor(0.8120, device='cuda:0')\n",
            "Training average batch accuracy: 0.776063\n",
            "Validation average batch accuracy: 0.812012\n",
            "Epoch 193: Loss: 0.468248 \t\t Validation loss: 0.426631\n",
            "Training average batch accuracy: 0.783438\n",
            "Validation average batch accuracy: 0.807080\n",
            "Epoch 194: Loss: 0.468819 \t\t Validation loss: 0.422605\n",
            "Training average batch accuracy: 0.776563\n",
            "Validation average batch accuracy: 0.810254\n",
            "Epoch 195: Loss: 0.478809 \t\t Validation loss: 0.428250\n",
            "Training average batch accuracy: 0.775688\n",
            "Validation average batch accuracy: 0.805566\n",
            "Epoch 196: Loss: 0.471582 \t\t Validation loss: 0.425021\n",
            "Training average batch accuracy: 0.779313\n",
            "Validation average batch accuracy: 0.805273\n",
            "Epoch 197: Loss: 0.474637 \t\t Validation loss: 0.434068\n",
            "Training average batch accuracy: 0.778250\n",
            "Validation average batch accuracy: 0.802734\n",
            "Epoch 198: Loss: 0.465920 \t\t Validation loss: 0.422618\n",
            "Training average batch accuracy: 0.782063\n",
            "Validation average batch accuracy: 0.806250\n",
            "Epoch 199: Loss: 0.469518 \t\t Validation loss: 0.425845\n",
            "Training average batch accuracy: 0.780938\n",
            "Validation average batch accuracy: 0.804980\n",
            "Epoch 200: Loss: 0.470307 \t\t Validation loss: 0.425878\n",
            "Training average batch accuracy: 0.776875\n",
            "Validation average batch accuracy: 0.805273\n",
            "Epoch 201: Loss: 0.474130 \t\t Validation loss: 0.433292\n",
            "Training average batch accuracy: 0.775125\n",
            "Validation average batch accuracy: 0.799072\n",
            "Epoch 202: Loss: 0.463435 \t\t Validation loss: 0.419572\n",
            "Training average batch accuracy: 0.782438\n",
            "Validation average batch accuracy: 0.808740\n",
            "Epoch 203: Loss: 0.461472 \t\t Validation loss: 0.423883\n",
            "Training average batch accuracy: 0.781625\n",
            "Epoch   204: reducing learning rate of group 0 to 9.0000e-05.\n",
            "Validation average batch accuracy: 0.804736\n",
            "Epoch 204: Loss: 0.466993 \t\t Validation loss: 0.419627\n",
            "Training average batch accuracy: 0.780813\n",
            "Validation average batch accuracy: 0.811475\n",
            "Epoch 205: Loss: 0.467325 \t\t Validation loss: 0.416743\n",
            "Training average batch accuracy: 0.780938\n",
            "Validation average batch accuracy: 0.811523\n",
            "Epoch 206: Loss: 0.459256 \t\t Validation loss: 0.425326\n",
            "Training average batch accuracy: 0.782688\n",
            "Validation average batch accuracy: 0.805664\n",
            "Epoch 207: Loss: 0.469959 \t\t Validation loss: 0.420724\n",
            "Training average batch accuracy: 0.780813\n",
            "Validation average batch accuracy: 0.808545\n",
            "Epoch 208: Loss: 0.463381 \t\t Validation loss: 0.425319\n",
            "Training average batch accuracy: 0.785375\n",
            "Validation average batch accuracy: 0.807471\n",
            "Epoch 209: Loss: 0.461599 \t\t Validation loss: 0.417041\n",
            "Training average batch accuracy: 0.785375\n",
            "Validation average batch accuracy: 0.811621\n",
            "Epoch 210: Loss: 0.463598 \t\t Validation loss: 0.414494\n",
            "BEST SCORE: tensor(0.8151, device='cuda:0')\n",
            "Training average batch accuracy: 0.784938\n",
            "Validation average batch accuracy: 0.815088\n",
            "Epoch 211: Loss: 0.463434 \t\t Validation loss: 0.410766\n",
            "Training average batch accuracy: 0.780500\n",
            "Validation average batch accuracy: 0.814502\n",
            "Epoch 212: Loss: 0.461655 \t\t Validation loss: 0.420511\n",
            "Training average batch accuracy: 0.786250\n",
            "Validation average batch accuracy: 0.808691\n",
            "Epoch 213: Loss: 0.453709 \t\t Validation loss: 0.412234\n",
            "Training average batch accuracy: 0.789938\n",
            "Validation average batch accuracy: 0.814648\n",
            "Epoch 214: Loss: 0.463242 \t\t Validation loss: 0.415908\n",
            "Training average batch accuracy: 0.784125\n",
            "Validation average batch accuracy: 0.813232\n",
            "Epoch 215: Loss: 0.445933 \t\t Validation loss: 0.421082\n",
            "Training average batch accuracy: 0.795688\n",
            "Validation average batch accuracy: 0.808887\n",
            "Epoch 216: Loss: 0.456334 \t\t Validation loss: 0.416870\n",
            "Training average batch accuracy: 0.787188\n",
            "Validation average batch accuracy: 0.812256\n",
            "Epoch 217: Loss: 0.461450 \t\t Validation loss: 0.412666\n",
            "Training average batch accuracy: 0.783938\n",
            "Validation average batch accuracy: 0.808936\n",
            "Epoch 218: Loss: 0.451329 \t\t Validation loss: 0.414470\n",
            "Training average batch accuracy: 0.793625\n",
            "Validation average batch accuracy: 0.813232\n",
            "Epoch 219: Loss: 0.443930 \t\t Validation loss: 0.406958\n",
            "BEST SCORE: tensor(0.8177, device='cuda:0')\n",
            "Training average batch accuracy: 0.796750\n",
            "Validation average batch accuracy: 0.817676\n",
            "Epoch 220: Loss: 0.449723 \t\t Validation loss: 0.415722\n",
            "Training average batch accuracy: 0.790938\n",
            "Validation average batch accuracy: 0.811426\n",
            "Epoch 221: Loss: 0.458702 \t\t Validation loss: 0.421027\n",
            "Training average batch accuracy: 0.784563\n",
            "Validation average batch accuracy: 0.807031\n",
            "Epoch 222: Loss: 0.457010 \t\t Validation loss: 0.413865\n",
            "Training average batch accuracy: 0.789688\n",
            "Validation average batch accuracy: 0.810791\n",
            "Epoch 223: Loss: 0.460054 \t\t Validation loss: 0.409421\n",
            "Training average batch accuracy: 0.783063\n",
            "Validation average batch accuracy: 0.815332\n",
            "Epoch 224: Loss: 0.462357 \t\t Validation loss: 0.409314\n",
            "Training average batch accuracy: 0.784563\n",
            "Validation average batch accuracy: 0.812500\n",
            "Epoch 225: Loss: 0.463445 \t\t Validation loss: 0.416714\n",
            "Training average batch accuracy: 0.784750\n",
            "Validation average batch accuracy: 0.808154\n",
            "Epoch 226: Loss: 0.456806 \t\t Validation loss: 0.418362\n",
            "Training average batch accuracy: 0.784375\n",
            "Validation average batch accuracy: 0.807520\n",
            "Epoch 227: Loss: 0.456910 \t\t Validation loss: 0.413996\n",
            "Training average batch accuracy: 0.785750\n",
            "Validation average batch accuracy: 0.813818\n",
            "Epoch 228: Loss: 0.448226 \t\t Validation loss: 0.421725\n",
            "Training average batch accuracy: 0.792188\n",
            "Validation average batch accuracy: 0.807080\n",
            "Epoch 229: Loss: 0.457684 \t\t Validation loss: 0.414866\n",
            "Training average batch accuracy: 0.781563\n",
            "Validation average batch accuracy: 0.811670\n",
            "Epoch 230: Loss: 0.458457 \t\t Validation loss: 0.408434\n",
            "Training average batch accuracy: 0.786250\n",
            "Epoch   231: reducing learning rate of group 0 to 8.1000e-05.\n",
            "Validation average batch accuracy: 0.817285\n",
            "Epoch 231: Loss: 0.458416 \t\t Validation loss: 0.409278\n",
            "Training average batch accuracy: 0.786125\n",
            "Validation average batch accuracy: 0.814697\n",
            "Epoch 232: Loss: 0.449824 \t\t Validation loss: 0.409907\n",
            "Training average batch accuracy: 0.793188\n",
            "Validation average batch accuracy: 0.815820\n",
            "Epoch 233: Loss: 0.452059 \t\t Validation loss: 0.406772\n",
            "Training average batch accuracy: 0.790250\n",
            "Validation average batch accuracy: 0.815869\n",
            "Epoch 234: Loss: 0.452341 \t\t Validation loss: 0.408190\n",
            "Training average batch accuracy: 0.788563\n",
            "Validation average batch accuracy: 0.815137\n",
            "Epoch 235: Loss: 0.443586 \t\t Validation loss: 0.408401\n",
            "Training average batch accuracy: 0.793813\n",
            "Validation average batch accuracy: 0.816553\n",
            "Epoch 236: Loss: 0.450933 \t\t Validation loss: 0.411808\n",
            "Training average batch accuracy: 0.791250\n",
            "Validation average batch accuracy: 0.812939\n",
            "Epoch 237: Loss: 0.442349 \t\t Validation loss: 0.406939\n",
            "BEST SCORE: tensor(0.8182, device='cuda:0')\n",
            "Training average batch accuracy: 0.796688\n",
            "Validation average batch accuracy: 0.818164\n",
            "Epoch 238: Loss: 0.451837 \t\t Validation loss: 0.404214\n",
            "BEST SCORE: tensor(0.8188, device='cuda:0')\n",
            "Training average batch accuracy: 0.790813\n",
            "Validation average batch accuracy: 0.818750\n",
            "Epoch 239: Loss: 0.449982 \t\t Validation loss: 0.402617\n",
            "BEST SCORE: tensor(0.8221, device='cuda:0')\n",
            "Training average batch accuracy: 0.789625\n",
            "Validation average batch accuracy: 0.822119\n",
            "Epoch 240: Loss: 0.453443 \t\t Validation loss: 0.406032\n",
            "Training average batch accuracy: 0.789875\n",
            "Validation average batch accuracy: 0.819727\n",
            "Epoch 241: Loss: 0.442816 \t\t Validation loss: 0.401125\n",
            "Training average batch accuracy: 0.793063\n",
            "Validation average batch accuracy: 0.820850\n",
            "Epoch 242: Loss: 0.454486 \t\t Validation loss: 0.399466\n",
            "BEST SCORE: tensor(0.8227, device='cuda:0')\n",
            "Training average batch accuracy: 0.788813\n",
            "Validation average batch accuracy: 0.822705\n",
            "Epoch 243: Loss: 0.441494 \t\t Validation loss: 0.402916\n",
            "Training average batch accuracy: 0.797875\n",
            "Validation average batch accuracy: 0.819092\n",
            "Epoch 244: Loss: 0.449071 \t\t Validation loss: 0.398430\n",
            "Training average batch accuracy: 0.792125\n",
            "Validation average batch accuracy: 0.821240\n",
            "Epoch 245: Loss: 0.448670 \t\t Validation loss: 0.400811\n",
            "Training average batch accuracy: 0.791438\n",
            "Validation average batch accuracy: 0.821729\n",
            "Epoch 246: Loss: 0.447838 \t\t Validation loss: 0.406209\n",
            "Training average batch accuracy: 0.796938\n",
            "Validation average batch accuracy: 0.816309\n",
            "Epoch 247: Loss: 0.446776 \t\t Validation loss: 0.405181\n",
            "Training average batch accuracy: 0.794875\n",
            "Validation average batch accuracy: 0.819531\n",
            "Epoch 248: Loss: 0.444351 \t\t Validation loss: 0.400990\n",
            "Training average batch accuracy: 0.797375\n",
            "Validation average batch accuracy: 0.821777\n",
            "Epoch 249: Loss: 0.439713 \t\t Validation loss: 0.405075\n",
            "Training average batch accuracy: 0.798688\n",
            "Validation average batch accuracy: 0.818604\n",
            "Epoch 250: Loss: 0.444331 \t\t Validation loss: 0.406535\n",
            "Training average batch accuracy: 0.798563\n",
            "Validation average batch accuracy: 0.819385\n",
            "Epoch 251: Loss: 0.450452 \t\t Validation loss: 0.403548\n",
            "Training average batch accuracy: 0.791813\n",
            "Validation average batch accuracy: 0.819434\n",
            "Epoch 252: Loss: 0.442221 \t\t Validation loss: 0.405516\n",
            "Training average batch accuracy: 0.795438\n",
            "Validation average batch accuracy: 0.820215\n",
            "Epoch 253: Loss: 0.450000 \t\t Validation loss: 0.407555\n",
            "Training average batch accuracy: 0.790125\n",
            "Validation average batch accuracy: 0.815723\n",
            "Epoch 254: Loss: 0.442418 \t\t Validation loss: 0.409631\n",
            "Training average batch accuracy: 0.796750\n",
            "Validation average batch accuracy: 0.815088\n",
            "Epoch 255: Loss: 0.449340 \t\t Validation loss: 0.400352\n",
            "Training average batch accuracy: 0.793875\n",
            "Epoch   256: reducing learning rate of group 0 to 7.2900e-05.\n",
            "Validation average batch accuracy: 0.821533\n",
            "Epoch 256: Loss: 0.442559 \t\t Validation loss: 0.399269\n",
            "BEST SCORE: tensor(0.8242, device='cuda:0')\n",
            "Training average batch accuracy: 0.793438\n",
            "Validation average batch accuracy: 0.824170\n",
            "Epoch 257: Loss: 0.442653 \t\t Validation loss: 0.404458\n",
            "Training average batch accuracy: 0.796688\n",
            "Validation average batch accuracy: 0.816650\n",
            "Epoch 258: Loss: 0.440149 \t\t Validation loss: 0.404028\n",
            "Training average batch accuracy: 0.796313\n",
            "Validation average batch accuracy: 0.820508\n",
            "Epoch 259: Loss: 0.432881 \t\t Validation loss: 0.398628\n",
            "Training average batch accuracy: 0.802188\n",
            "Validation average batch accuracy: 0.819336\n",
            "Epoch 260: Loss: 0.433251 \t\t Validation loss: 0.402537\n",
            "Training average batch accuracy: 0.801688\n",
            "Validation average batch accuracy: 0.816943\n",
            "Epoch 261: Loss: 0.437766 \t\t Validation loss: 0.396440\n",
            "Training average batch accuracy: 0.798875\n",
            "Validation average batch accuracy: 0.823096\n",
            "Epoch 262: Loss: 0.446403 \t\t Validation loss: 0.402401\n",
            "Training average batch accuracy: 0.792500\n",
            "Validation average batch accuracy: 0.820117\n",
            "Epoch 263: Loss: 0.438668 \t\t Validation loss: 0.400099\n",
            "Training average batch accuracy: 0.799063\n",
            "Validation average batch accuracy: 0.819385\n",
            "Epoch 264: Loss: 0.444905 \t\t Validation loss: 0.398020\n",
            "Training average batch accuracy: 0.793313\n",
            "Validation average batch accuracy: 0.819531\n",
            "Epoch 265: Loss: 0.448064 \t\t Validation loss: 0.392751\n",
            "Training average batch accuracy: 0.794938\n",
            "Validation average batch accuracy: 0.823535\n",
            "Epoch 266: Loss: 0.436284 \t\t Validation loss: 0.400128\n",
            "Training average batch accuracy: 0.800688\n",
            "Validation average batch accuracy: 0.823877\n",
            "Epoch 267: Loss: 0.441912 \t\t Validation loss: 0.399659\n",
            "Training average batch accuracy: 0.801438\n",
            "Validation average batch accuracy: 0.821631\n",
            "Epoch 268: Loss: 0.438544 \t\t Validation loss: 0.398271\n",
            "Training average batch accuracy: 0.800188\n",
            "Validation average batch accuracy: 0.821484\n",
            "Epoch 269: Loss: 0.435770 \t\t Validation loss: 0.399299\n",
            "Training average batch accuracy: 0.802625\n",
            "Validation average batch accuracy: 0.820215\n",
            "Epoch 270: Loss: 0.434522 \t\t Validation loss: 0.400970\n",
            "Training average batch accuracy: 0.798250\n",
            "Validation average batch accuracy: 0.821240\n",
            "Epoch 271: Loss: 0.428749 \t\t Validation loss: 0.394666\n",
            "BEST SCORE: tensor(0.8271, device='cuda:0')\n",
            "Training average batch accuracy: 0.803625\n",
            "Validation average batch accuracy: 0.827148\n",
            "Epoch 272: Loss: 0.439747 \t\t Validation loss: 0.394958\n",
            "Training average batch accuracy: 0.797125\n",
            "Validation average batch accuracy: 0.825244\n",
            "Epoch 273: Loss: 0.437459 \t\t Validation loss: 0.394514\n",
            "Training average batch accuracy: 0.797500\n",
            "Validation average batch accuracy: 0.823340\n",
            "Epoch 274: Loss: 0.429722 \t\t Validation loss: 0.393714\n",
            "Training average batch accuracy: 0.805438\n",
            "Validation average batch accuracy: 0.823242\n",
            "Epoch 275: Loss: 0.439647 \t\t Validation loss: 0.394129\n",
            "Training average batch accuracy: 0.797750\n",
            "Validation average batch accuracy: 0.824756\n",
            "Epoch 276: Loss: 0.429833 \t\t Validation loss: 0.398004\n",
            "Training average batch accuracy: 0.803625\n",
            "Epoch   277: reducing learning rate of group 0 to 6.5610e-05.\n",
            "Validation average batch accuracy: 0.820166\n",
            "Epoch 277: Loss: 0.433256 \t\t Validation loss: 0.396283\n",
            "Training average batch accuracy: 0.801875\n",
            "Validation average batch accuracy: 0.823975\n",
            "Epoch 278: Loss: 0.435875 \t\t Validation loss: 0.397966\n",
            "Training average batch accuracy: 0.802375\n",
            "Validation average batch accuracy: 0.822461\n",
            "Epoch 279: Loss: 0.430540 \t\t Validation loss: 0.396851\n",
            "Training average batch accuracy: 0.804750\n",
            "Validation average batch accuracy: 0.820508\n",
            "Epoch 280: Loss: 0.426150 \t\t Validation loss: 0.398450\n",
            "Training average batch accuracy: 0.809125\n",
            "Validation average batch accuracy: 0.824414\n",
            "Epoch 281: Loss: 0.436640 \t\t Validation loss: 0.392845\n",
            "Training average batch accuracy: 0.800625\n",
            "Validation average batch accuracy: 0.825635\n",
            "Epoch 282: Loss: 0.425602 \t\t Validation loss: 0.393226\n",
            "Training average batch accuracy: 0.805688\n",
            "Validation average batch accuracy: 0.824365\n",
            "Epoch 283: Loss: 0.427991 \t\t Validation loss: 0.393899\n",
            "Training average batch accuracy: 0.804875\n",
            "Validation average batch accuracy: 0.823730\n",
            "Epoch 284: Loss: 0.427663 \t\t Validation loss: 0.389555\n",
            "Training average batch accuracy: 0.803500\n",
            "Validation average batch accuracy: 0.824219\n",
            "Epoch 285: Loss: 0.439390 \t\t Validation loss: 0.390698\n",
            "BEST SCORE: tensor(0.8286, device='cuda:0')\n",
            "Training average batch accuracy: 0.802438\n",
            "Validation average batch accuracy: 0.828564\n",
            "Epoch 286: Loss: 0.431461 \t\t Validation loss: 0.389204\n",
            "Training average batch accuracy: 0.803813\n",
            "Validation average batch accuracy: 0.827051\n",
            "Epoch 287: Loss: 0.427512 \t\t Validation loss: 0.397838\n",
            "Training average batch accuracy: 0.805313\n",
            "Validation average batch accuracy: 0.824170\n",
            "Epoch 288: Loss: 0.424761 \t\t Validation loss: 0.388786\n",
            "Training average batch accuracy: 0.807500\n",
            "Validation average batch accuracy: 0.827344\n",
            "Epoch 289: Loss: 0.433786 \t\t Validation loss: 0.388860\n",
            "Training average batch accuracy: 0.806813\n",
            "Validation average batch accuracy: 0.828272\n",
            "Epoch 290: Loss: 0.433804 \t\t Validation loss: 0.390580\n",
            "Training average batch accuracy: 0.802375\n",
            "Validation average batch accuracy: 0.824219\n",
            "Epoch 291: Loss: 0.421309 \t\t Validation loss: 0.393969\n",
            "Training average batch accuracy: 0.808250\n",
            "Validation average batch accuracy: 0.822559\n",
            "Epoch 292: Loss: 0.426046 \t\t Validation loss: 0.393055\n",
            "Training average batch accuracy: 0.807625\n",
            "Validation average batch accuracy: 0.826367\n",
            "Epoch 293: Loss: 0.424943 \t\t Validation loss: 0.383785\n",
            "Training average batch accuracy: 0.807688\n",
            "Validation average batch accuracy: 0.827051\n",
            "Epoch 294: Loss: 0.437062 \t\t Validation loss: 0.386616\n",
            "BEST SCORE: tensor(0.8312, device='cuda:0')\n",
            "Training average batch accuracy: 0.802438\n",
            "Validation average batch accuracy: 0.831201\n",
            "Epoch 295: Loss: 0.425784 \t\t Validation loss: 0.390180\n",
            "Training average batch accuracy: 0.806250\n",
            "Validation average batch accuracy: 0.822998\n",
            "Epoch 296: Loss: 0.425724 \t\t Validation loss: 0.393672\n",
            "Training average batch accuracy: 0.805313\n",
            "Validation average batch accuracy: 0.824512\n",
            "Epoch 297: Loss: 0.421389 \t\t Validation loss: 0.388535\n",
            "Training average batch accuracy: 0.808438\n",
            "Validation average batch accuracy: 0.828662\n",
            "Epoch 298: Loss: 0.426409 \t\t Validation loss: 0.387545\n",
            "BEST SCORE: tensor(0.8318, device='cuda:0')\n",
            "Training average batch accuracy: 0.809813\n",
            "Validation average batch accuracy: 0.831787\n",
            "Epoch 299: Loss: 0.429826 \t\t Validation loss: 0.390729\n",
            "Training average batch accuracy: 0.803813\n",
            "Validation average batch accuracy: 0.827539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KV3xUpgKuKv"
      },
      "source": [
        "\n",
        "torch.save({\n",
        "            'epoch': 300,\n",
        "            'model_state_dict': best_model['state_dict'],\n",
        "            'optimizer_state_dict': optim_context.state_dict()\n",
        "}, \"/content/drive/MyDrive/Sapienza/model_context_GloVE300_with_stopwords.pth\" )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO_3rqd36B4N"
      },
      "source": [
        "## WiC Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8lQmdYm6EGK"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsx7pg1JFco4"
      },
      "source": [
        "### WiC no original POS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tYJgT0IFgjk"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGYk7XcvFgze",
        "outputId": "04e27aab-469d-41d4-ec5f-a68117a47015"
      },
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, eval_step):\n",
        "    model.eval()\n",
        "    results = []\n",
        "    losses = []\n",
        "    \n",
        "    for i, batch in enumerate(data_loader):\n",
        "        loss, metric = eval_step(model, batch)\n",
        "        losses.append(loss.item())\n",
        "        results.append(metric)\n",
        "\n",
        "    return sum(losses) / len(losses), sum(results) / len(results)\n",
        "\n",
        "model_wic = WiCClassifier(HypParams(), vectors, model_context, \n",
        "                            predict_pos=False).to('cuda')\n",
        "\n",
        "optim_wic = torch.optim.Adam(model_wic.parameters())\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim_wic, factor=0.5, verbose=True)\n",
        "#scheduler=None\n",
        "best_model = {}\n",
        "hist = {}\n",
        "\n",
        "_ = train(train_loader, valid_loader, \n",
        "      model_wic, optim_wic, \n",
        "      train_step_3, \n",
        "      eval_step_3,\n",
        "      260,\n",
        "      scheduler=scheduler, \n",
        "      best_model_mode='accuracy', \n",
        "      best_model=best_model, hist=hist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss: 0.891143 \t\t Validation loss: 0.666134\n",
            "BEST SCORE: tensor(0.5865, device='cuda:0')\n",
            "Training average batch accuracy: 0.513500\n",
            "Validation average batch accuracy: 0.586523\n",
            "Epoch 1: Loss: 0.750880 \t\t Validation loss: 0.655895\n",
            "BEST SCORE: tensor(0.6369, device='cuda:0')\n",
            "Training average batch accuracy: 0.537750\n",
            "Validation average batch accuracy: 0.636914\n",
            "Epoch 2: Loss: 0.742333 \t\t Validation loss: 0.657814\n",
            "Training average batch accuracy: 0.533000\n",
            "Validation average batch accuracy: 0.620117\n",
            "Epoch 3: Loss: 0.730122 \t\t Validation loss: 0.648991\n",
            "BEST SCORE: tensor(0.6451, device='cuda:0')\n",
            "Training average batch accuracy: 0.541625\n",
            "Validation average batch accuracy: 0.645117\n",
            "Epoch 4: Loss: 0.729580 \t\t Validation loss: 0.644153\n",
            "Training average batch accuracy: 0.543375\n",
            "Validation average batch accuracy: 0.637695\n",
            "Epoch 5: Loss: 0.726669 \t\t Validation loss: 0.642298\n",
            "Training average batch accuracy: 0.548500\n",
            "Validation average batch accuracy: 0.636914\n",
            "Epoch 6: Loss: 0.714525 \t\t Validation loss: 0.632643\n",
            "BEST SCORE: tensor(0.6766, device='cuda:0')\n",
            "Training average batch accuracy: 0.556875\n",
            "Validation average batch accuracy: 0.676562\n",
            "Epoch 7: Loss: 0.715613 \t\t Validation loss: 0.627708\n",
            "Training average batch accuracy: 0.563375\n",
            "Validation average batch accuracy: 0.673633\n",
            "Epoch 8: Loss: 0.713454 \t\t Validation loss: 0.626077\n",
            "Training average batch accuracy: 0.560875\n",
            "Validation average batch accuracy: 0.675000\n",
            "Epoch 9: Loss: 0.710981 \t\t Validation loss: 0.628026\n",
            "Training average batch accuracy: 0.566250\n",
            "Validation average batch accuracy: 0.640234\n",
            "Epoch 10: Loss: 0.705568 \t\t Validation loss: 0.621661\n",
            "Training average batch accuracy: 0.573500\n",
            "Validation average batch accuracy: 0.667773\n",
            "Epoch 11: Loss: 0.702575 \t\t Validation loss: 0.615668\n",
            "BEST SCORE: tensor(0.6777, device='cuda:0')\n",
            "Training average batch accuracy: 0.583250\n",
            "Validation average batch accuracy: 0.677734\n",
            "Epoch 12: Loss: 0.705049 \t\t Validation loss: 0.612564\n",
            "Training average batch accuracy: 0.576750\n",
            "Validation average batch accuracy: 0.672266\n",
            "Epoch 13: Loss: 0.694219 \t\t Validation loss: 0.605045\n",
            "BEST SCORE: tensor(0.6947, device='cuda:0')\n",
            "Training average batch accuracy: 0.580750\n",
            "Validation average batch accuracy: 0.694727\n",
            "Epoch 14: Loss: 0.694120 \t\t Validation loss: 0.602929\n",
            "BEST SCORE: tensor(0.7039, device='cuda:0')\n",
            "Training average batch accuracy: 0.582250\n",
            "Validation average batch accuracy: 0.703906\n",
            "Epoch 15: Loss: 0.691542 \t\t Validation loss: 0.595791\n",
            "BEST SCORE: tensor(0.7172, device='cuda:0')\n",
            "Training average batch accuracy: 0.593750\n",
            "Validation average batch accuracy: 0.717188\n",
            "Epoch 16: Loss: 0.685378 \t\t Validation loss: 0.598782\n",
            "Training average batch accuracy: 0.592125\n",
            "Validation average batch accuracy: 0.680273\n",
            "Epoch 17: Loss: 0.688091 \t\t Validation loss: 0.600103\n",
            "Training average batch accuracy: 0.590375\n",
            "Validation average batch accuracy: 0.691016\n",
            "Epoch 18: Loss: 0.682324 \t\t Validation loss: 0.597723\n",
            "Training average batch accuracy: 0.593875\n",
            "Validation average batch accuracy: 0.699219\n",
            "Epoch 19: Loss: 0.676112 \t\t Validation loss: 0.598359\n",
            "Training average batch accuracy: 0.602875\n",
            "Validation average batch accuracy: 0.673242\n",
            "Epoch 20: Loss: 0.673555 \t\t Validation loss: 0.591600\n",
            "Training average batch accuracy: 0.611625\n",
            "Validation average batch accuracy: 0.693750\n",
            "Epoch 21: Loss: 0.671907 \t\t Validation loss: 0.588218\n",
            "Training average batch accuracy: 0.605750\n",
            "Validation average batch accuracy: 0.697461\n",
            "Epoch 22: Loss: 0.682064 \t\t Validation loss: 0.593887\n",
            "Training average batch accuracy: 0.590875\n",
            "Validation average batch accuracy: 0.704492\n",
            "Epoch 23: Loss: 0.665253 \t\t Validation loss: 0.584876\n",
            "Training average batch accuracy: 0.608625\n",
            "Validation average batch accuracy: 0.711719\n",
            "Epoch 24: Loss: 0.675204 \t\t Validation loss: 0.590419\n",
            "Training average batch accuracy: 0.603500\n",
            "Validation average batch accuracy: 0.693945\n",
            "Epoch 25: Loss: 0.662610 \t\t Validation loss: 0.584692\n",
            "Training average batch accuracy: 0.616000\n",
            "Validation average batch accuracy: 0.702148\n",
            "Epoch 26: Loss: 0.662867 \t\t Validation loss: 0.582113\n",
            "Training average batch accuracy: 0.615625\n",
            "Validation average batch accuracy: 0.712305\n",
            "Epoch 27: Loss: 0.665965 \t\t Validation loss: 0.581926\n",
            "Training average batch accuracy: 0.611000\n",
            "Validation average batch accuracy: 0.708398\n",
            "Epoch 28: Loss: 0.661759 \t\t Validation loss: 0.580823\n",
            "Training average batch accuracy: 0.612000\n",
            "Validation average batch accuracy: 0.704687\n",
            "Epoch 29: Loss: 0.658075 \t\t Validation loss: 0.577162\n",
            "Training average batch accuracy: 0.617375\n",
            "Validation average batch accuracy: 0.713281\n",
            "Epoch 30: Loss: 0.657520 \t\t Validation loss: 0.574280\n",
            "Training average batch accuracy: 0.618500\n",
            "Validation average batch accuracy: 0.715625\n",
            "Epoch 31: Loss: 0.652418 \t\t Validation loss: 0.579085\n",
            "Training average batch accuracy: 0.624875\n",
            "Validation average batch accuracy: 0.706055\n",
            "Epoch 32: Loss: 0.658640 \t\t Validation loss: 0.576506\n",
            "Training average batch accuracy: 0.619750\n",
            "Validation average batch accuracy: 0.713672\n",
            "Epoch 33: Loss: 0.650240 \t\t Validation loss: 0.572993\n",
            "Training average batch accuracy: 0.623375\n",
            "Validation average batch accuracy: 0.700391\n",
            "Epoch 34: Loss: 0.650030 \t\t Validation loss: 0.572000\n",
            "Training average batch accuracy: 0.627625\n",
            "Validation average batch accuracy: 0.705078\n",
            "Epoch 35: Loss: 0.650655 \t\t Validation loss: 0.572507\n",
            "Training average batch accuracy: 0.621250\n",
            "Validation average batch accuracy: 0.701563\n",
            "Epoch 36: Loss: 0.644304 \t\t Validation loss: 0.570211\n",
            "Training average batch accuracy: 0.633375\n",
            "Validation average batch accuracy: 0.712305\n",
            "Epoch 37: Loss: 0.644543 \t\t Validation loss: 0.569053\n",
            "Training average batch accuracy: 0.633125\n",
            "Validation average batch accuracy: 0.711328\n",
            "Epoch 38: Loss: 0.637892 \t\t Validation loss: 0.569677\n",
            "Training average batch accuracy: 0.643000\n",
            "Validation average batch accuracy: 0.708398\n",
            "Epoch 39: Loss: 0.637740 \t\t Validation loss: 0.568293\n",
            "Training average batch accuracy: 0.639750\n",
            "Validation average batch accuracy: 0.712695\n",
            "Epoch 40: Loss: 0.638882 \t\t Validation loss: 0.567971\n",
            "BEST SCORE: tensor(0.7182, device='cuda:0')\n",
            "Training average batch accuracy: 0.633500\n",
            "Validation average batch accuracy: 0.718164\n",
            "Epoch 41: Loss: 0.645001 \t\t Validation loss: 0.567230\n",
            "BEST SCORE: tensor(0.7270, device='cuda:0')\n",
            "Training average batch accuracy: 0.633125\n",
            "Validation average batch accuracy: 0.726953\n",
            "Epoch 42: Loss: 0.625551 \t\t Validation loss: 0.564599\n",
            "Training average batch accuracy: 0.647750\n",
            "Validation average batch accuracy: 0.721484\n",
            "Epoch 43: Loss: 0.633252 \t\t Validation loss: 0.563055\n",
            "BEST SCORE: tensor(0.7289, device='cuda:0')\n",
            "Training average batch accuracy: 0.643375\n",
            "Validation average batch accuracy: 0.728906\n",
            "Epoch 44: Loss: 0.636658 \t\t Validation loss: 0.564202\n",
            "Training average batch accuracy: 0.640375\n",
            "Validation average batch accuracy: 0.711328\n",
            "Epoch 45: Loss: 0.630590 \t\t Validation loss: 0.562282\n",
            "Training average batch accuracy: 0.646875\n",
            "Validation average batch accuracy: 0.720508\n",
            "Epoch 46: Loss: 0.632921 \t\t Validation loss: 0.565663\n",
            "Training average batch accuracy: 0.638125\n",
            "Validation average batch accuracy: 0.719531\n",
            "Epoch 47: Loss: 0.635288 \t\t Validation loss: 0.561020\n",
            "Training average batch accuracy: 0.650125\n",
            "Validation average batch accuracy: 0.719531\n",
            "Epoch 48: Loss: 0.634381 \t\t Validation loss: 0.563909\n",
            "Training average batch accuracy: 0.644875\n",
            "Validation average batch accuracy: 0.714063\n",
            "Epoch 49: Loss: 0.629825 \t\t Validation loss: 0.562410\n",
            "Training average batch accuracy: 0.649125\n",
            "Validation average batch accuracy: 0.712695\n",
            "Epoch 50: Loss: 0.623870 \t\t Validation loss: 0.562879\n",
            "Training average batch accuracy: 0.655625\n",
            "Validation average batch accuracy: 0.707227\n",
            "Epoch 51: Loss: 0.621576 \t\t Validation loss: 0.561503\n",
            "Training average batch accuracy: 0.655625\n",
            "Validation average batch accuracy: 0.715820\n",
            "Epoch 52: Loss: 0.621249 \t\t Validation loss: 0.558060\n",
            "Training average batch accuracy: 0.649125\n",
            "Validation average batch accuracy: 0.717188\n",
            "Epoch 53: Loss: 0.618261 \t\t Validation loss: 0.555263\n",
            "Training average batch accuracy: 0.651750\n",
            "Validation average batch accuracy: 0.720703\n",
            "Epoch 54: Loss: 0.623326 \t\t Validation loss: 0.557381\n",
            "Training average batch accuracy: 0.650500\n",
            "Validation average batch accuracy: 0.720117\n",
            "Epoch 55: Loss: 0.624386 \t\t Validation loss: 0.558007\n",
            "Training average batch accuracy: 0.657750\n",
            "Validation average batch accuracy: 0.720117\n",
            "Epoch 56: Loss: 0.610447 \t\t Validation loss: 0.554785\n",
            "Training average batch accuracy: 0.663375\n",
            "Validation average batch accuracy: 0.724609\n",
            "Epoch 57: Loss: 0.614443 \t\t Validation loss: 0.553502\n",
            "Training average batch accuracy: 0.658625\n",
            "Validation average batch accuracy: 0.719727\n",
            "Epoch 58: Loss: 0.614482 \t\t Validation loss: 0.554910\n",
            "Training average batch accuracy: 0.664125\n",
            "Validation average batch accuracy: 0.722656\n",
            "Epoch 59: Loss: 0.613656 \t\t Validation loss: 0.554314\n",
            "Training average batch accuracy: 0.665500\n",
            "Validation average batch accuracy: 0.718750\n",
            "Epoch 60: Loss: 0.617777 \t\t Validation loss: 0.555850\n",
            "Training average batch accuracy: 0.665250\n",
            "Validation average batch accuracy: 0.725977\n",
            "Epoch 61: Loss: 0.618819 \t\t Validation loss: 0.555804\n",
            "Training average batch accuracy: 0.656875\n",
            "Validation average batch accuracy: 0.718164\n",
            "Epoch 62: Loss: 0.608080 \t\t Validation loss: 0.554406\n",
            "Training average batch accuracy: 0.665875\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 63: Loss: 0.617872 \t\t Validation loss: 0.555077\n",
            "Training average batch accuracy: 0.660875\n",
            "Validation average batch accuracy: 0.721680\n",
            "Epoch 64: Loss: 0.610405 \t\t Validation loss: 0.554729\n",
            "Training average batch accuracy: 0.665625\n",
            "Validation average batch accuracy: 0.723633\n",
            "Epoch 65: Loss: 0.613901 \t\t Validation loss: 0.555582\n",
            "Training average batch accuracy: 0.661750\n",
            "Validation average batch accuracy: 0.720703\n",
            "Epoch 66: Loss: 0.607111 \t\t Validation loss: 0.557572\n",
            "Training average batch accuracy: 0.667375\n",
            "Validation average batch accuracy: 0.720117\n",
            "Epoch 67: Loss: 0.603218 \t\t Validation loss: 0.551701\n",
            "BEST SCORE: tensor(0.7324, device='cuda:0')\n",
            "Training average batch accuracy: 0.672875\n",
            "Validation average batch accuracy: 0.732422\n",
            "Epoch 68: Loss: 0.607906 \t\t Validation loss: 0.551243\n",
            "Training average batch accuracy: 0.669000\n",
            "Validation average batch accuracy: 0.730469\n",
            "Epoch 69: Loss: 0.604025 \t\t Validation loss: 0.552259\n",
            "Training average batch accuracy: 0.665125\n",
            "Validation average batch accuracy: 0.730859\n",
            "Epoch 70: Loss: 0.607959 \t\t Validation loss: 0.553095\n",
            "Training average batch accuracy: 0.668750\n",
            "Validation average batch accuracy: 0.726953\n",
            "Epoch 71: Loss: 0.604682 \t\t Validation loss: 0.553701\n",
            "Training average batch accuracy: 0.672625\n",
            "Validation average batch accuracy: 0.725000\n",
            "Epoch 72: Loss: 0.600049 \t\t Validation loss: 0.550579\n",
            "Training average batch accuracy: 0.675375\n",
            "Validation average batch accuracy: 0.732422\n",
            "Epoch 73: Loss: 0.599914 \t\t Validation loss: 0.550531\n",
            "Training average batch accuracy: 0.677250\n",
            "Validation average batch accuracy: 0.719727\n",
            "Epoch 74: Loss: 0.600510 \t\t Validation loss: 0.549948\n",
            "Training average batch accuracy: 0.672500\n",
            "Validation average batch accuracy: 0.724023\n",
            "Epoch 75: Loss: 0.604775 \t\t Validation loss: 0.552346\n",
            "Training average batch accuracy: 0.669000\n",
            "Validation average batch accuracy: 0.723047\n",
            "Epoch 76: Loss: 0.593451 \t\t Validation loss: 0.551545\n",
            "Training average batch accuracy: 0.688500\n",
            "Validation average batch accuracy: 0.720703\n",
            "Epoch 77: Loss: 0.599012 \t\t Validation loss: 0.550439\n",
            "Training average batch accuracy: 0.679500\n",
            "Validation average batch accuracy: 0.722656\n",
            "Epoch 78: Loss: 0.598420 \t\t Validation loss: 0.551217\n",
            "Training average batch accuracy: 0.679875\n",
            "Validation average batch accuracy: 0.720703\n",
            "Epoch 79: Loss: 0.597993 \t\t Validation loss: 0.548735\n",
            "Training average batch accuracy: 0.676625\n",
            "Validation average batch accuracy: 0.726562\n",
            "Epoch 80: Loss: 0.600864 \t\t Validation loss: 0.547849\n",
            "Training average batch accuracy: 0.679000\n",
            "Validation average batch accuracy: 0.721680\n",
            "Epoch 81: Loss: 0.594468 \t\t Validation loss: 0.547736\n",
            "Training average batch accuracy: 0.681500\n",
            "Validation average batch accuracy: 0.721680\n",
            "Epoch 82: Loss: 0.592256 \t\t Validation loss: 0.545414\n",
            "Training average batch accuracy: 0.682375\n",
            "Validation average batch accuracy: 0.730469\n",
            "Epoch 83: Loss: 0.598216 \t\t Validation loss: 0.546236\n",
            "Training average batch accuracy: 0.681125\n",
            "Validation average batch accuracy: 0.726562\n",
            "Epoch 84: Loss: 0.595415 \t\t Validation loss: 0.546439\n",
            "Training average batch accuracy: 0.683125\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 85: Loss: 0.597494 \t\t Validation loss: 0.546605\n",
            "Training average batch accuracy: 0.682500\n",
            "Validation average batch accuracy: 0.725586\n",
            "Epoch 86: Loss: 0.591560 \t\t Validation loss: 0.545594\n",
            "Training average batch accuracy: 0.688375\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 87: Loss: 0.591068 \t\t Validation loss: 0.546059\n",
            "Training average batch accuracy: 0.688750\n",
            "Validation average batch accuracy: 0.725586\n",
            "Epoch 88: Loss: 0.591899 \t\t Validation loss: 0.545288\n",
            "Training average batch accuracy: 0.685250\n",
            "Validation average batch accuracy: 0.725586\n",
            "Epoch 89: Loss: 0.588922 \t\t Validation loss: 0.543721\n",
            "Training average batch accuracy: 0.690750\n",
            "Validation average batch accuracy: 0.729492\n",
            "Epoch 90: Loss: 0.586497 \t\t Validation loss: 0.547213\n",
            "Training average batch accuracy: 0.682500\n",
            "Validation average batch accuracy: 0.723633\n",
            "Epoch 91: Loss: 0.594855 \t\t Validation loss: 0.548747\n",
            "Training average batch accuracy: 0.683000\n",
            "Validation average batch accuracy: 0.724609\n",
            "Epoch 92: Loss: 0.588213 \t\t Validation loss: 0.545854\n",
            "Training average batch accuracy: 0.683000\n",
            "Validation average batch accuracy: 0.724023\n",
            "Epoch 93: Loss: 0.584527 \t\t Validation loss: 0.543623\n",
            "Training average batch accuracy: 0.689750\n",
            "Validation average batch accuracy: 0.727930\n",
            "Epoch 94: Loss: 0.590405 \t\t Validation loss: 0.547391\n",
            "Training average batch accuracy: 0.683750\n",
            "Validation average batch accuracy: 0.721680\n",
            "Epoch 95: Loss: 0.576511 \t\t Validation loss: 0.544680\n",
            "Training average batch accuracy: 0.695625\n",
            "Validation average batch accuracy: 0.725586\n",
            "Epoch 96: Loss: 0.582889 \t\t Validation loss: 0.546423\n",
            "Training average batch accuracy: 0.685375\n",
            "Validation average batch accuracy: 0.725000\n",
            "Epoch 97: Loss: 0.583125 \t\t Validation loss: 0.544282\n",
            "Training average batch accuracy: 0.687875\n",
            "Validation average batch accuracy: 0.725391\n",
            "Epoch 98: Loss: 0.588517 \t\t Validation loss: 0.547686\n",
            "Training average batch accuracy: 0.693125\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 99: Loss: 0.584305 \t\t Validation loss: 0.545869\n",
            "Training average batch accuracy: 0.691000\n",
            "Validation average batch accuracy: 0.726562\n",
            "Epoch 100: Loss: 0.580740 \t\t Validation loss: 0.547199\n",
            "Training average batch accuracy: 0.699375\n",
            "Validation average batch accuracy: 0.728125\n",
            "Epoch 101: Loss: 0.574909 \t\t Validation loss: 0.547990\n",
            "Training average batch accuracy: 0.702000\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 102: Loss: 0.577986 \t\t Validation loss: 0.545725\n",
            "Training average batch accuracy: 0.700750\n",
            "Validation average batch accuracy: 0.727148\n",
            "Epoch 103: Loss: 0.574119 \t\t Validation loss: 0.544463\n",
            "Training average batch accuracy: 0.699375\n",
            "Validation average batch accuracy: 0.726562\n",
            "Epoch 104: Loss: 0.569222 \t\t Validation loss: 0.543042\n",
            "Training average batch accuracy: 0.704000\n",
            "Validation average batch accuracy: 0.723633\n",
            "Epoch 105: Loss: 0.580136 \t\t Validation loss: 0.542637\n",
            "BEST SCORE: tensor(0.7340, device='cuda:0')\n",
            "Training average batch accuracy: 0.696500\n",
            "Validation average batch accuracy: 0.733984\n",
            "Epoch 106: Loss: 0.574943 \t\t Validation loss: 0.543330\n",
            "Training average batch accuracy: 0.697375\n",
            "Validation average batch accuracy: 0.731445\n",
            "Epoch 107: Loss: 0.574162 \t\t Validation loss: 0.542289\n",
            "Training average batch accuracy: 0.700250\n",
            "Validation average batch accuracy: 0.729492\n",
            "Epoch 108: Loss: 0.573475 \t\t Validation loss: 0.542101\n",
            "Training average batch accuracy: 0.700250\n",
            "Validation average batch accuracy: 0.732422\n",
            "Epoch 109: Loss: 0.573014 \t\t Validation loss: 0.542202\n",
            "Training average batch accuracy: 0.704250\n",
            "Validation average batch accuracy: 0.729492\n",
            "Epoch 110: Loss: 0.567935 \t\t Validation loss: 0.543606\n",
            "BEST SCORE: tensor(0.7344, device='cuda:0')\n",
            "Training average batch accuracy: 0.703750\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 111: Loss: 0.578915 \t\t Validation loss: 0.544820\n",
            "Training average batch accuracy: 0.695000\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 112: Loss: 0.577927 \t\t Validation loss: 0.543012\n",
            "Training average batch accuracy: 0.693250\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 113: Loss: 0.573210 \t\t Validation loss: 0.543887\n",
            "Training average batch accuracy: 0.703250\n",
            "Validation average batch accuracy: 0.731445\n",
            "Epoch 114: Loss: 0.572764 \t\t Validation loss: 0.546217\n",
            "Training average batch accuracy: 0.700500\n",
            "Validation average batch accuracy: 0.722656\n",
            "Epoch 115: Loss: 0.574351 \t\t Validation loss: 0.545506\n",
            "Training average batch accuracy: 0.700375\n",
            "Validation average batch accuracy: 0.731445\n",
            "Epoch 116: Loss: 0.569964 \t\t Validation loss: 0.543753\n",
            "Training average batch accuracy: 0.703125\n",
            "Validation average batch accuracy: 0.729492\n",
            "Epoch 117: Loss: 0.568402 \t\t Validation loss: 0.543770\n",
            "Training average batch accuracy: 0.705875\n",
            "Validation average batch accuracy: 0.731836\n",
            "Epoch 118: Loss: 0.563647 \t\t Validation loss: 0.544162\n",
            "Training average batch accuracy: 0.708750\n",
            "Validation average batch accuracy: 0.724023\n",
            "Epoch 119: Loss: 0.567268 \t\t Validation loss: 0.544928\n",
            "Training average batch accuracy: 0.708750\n",
            "Epoch   120: reducing learning rate of group 0 to 5.0000e-04.\n",
            "Validation average batch accuracy: 0.724609\n",
            "Epoch 120: Loss: 0.557531 \t\t Validation loss: 0.543816\n",
            "Training average batch accuracy: 0.713750\n",
            "Validation average batch accuracy: 0.724609\n",
            "Epoch 121: Loss: 0.568454 \t\t Validation loss: 0.543261\n",
            "Training average batch accuracy: 0.704250\n",
            "Validation average batch accuracy: 0.720703\n",
            "Epoch 122: Loss: 0.550045 \t\t Validation loss: 0.541008\n",
            "BEST SCORE: tensor(0.7354, device='cuda:0')\n",
            "Training average batch accuracy: 0.725625\n",
            "Validation average batch accuracy: 0.735352\n",
            "Epoch 123: Loss: 0.562584 \t\t Validation loss: 0.541777\n",
            "Training average batch accuracy: 0.710875\n",
            "Validation average batch accuracy: 0.729492\n",
            "Epoch 124: Loss: 0.556966 \t\t Validation loss: 0.541480\n",
            "Training average batch accuracy: 0.710875\n",
            "Validation average batch accuracy: 0.725586\n",
            "Epoch 125: Loss: 0.554225 \t\t Validation loss: 0.542271\n",
            "Training average batch accuracy: 0.722250\n",
            "Validation average batch accuracy: 0.723633\n",
            "Epoch 126: Loss: 0.546617 \t\t Validation loss: 0.539463\n",
            "Training average batch accuracy: 0.721750\n",
            "Validation average batch accuracy: 0.730469\n",
            "Epoch 127: Loss: 0.552335 \t\t Validation loss: 0.541390\n",
            "Training average batch accuracy: 0.714875\n",
            "Validation average batch accuracy: 0.733398\n",
            "Epoch 128: Loss: 0.551688 \t\t Validation loss: 0.541075\n",
            "Training average batch accuracy: 0.721625\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 129: Loss: 0.555983 \t\t Validation loss: 0.539281\n",
            "BEST SCORE: tensor(0.7393, device='cuda:0')\n",
            "Training average batch accuracy: 0.710625\n",
            "Validation average batch accuracy: 0.739258\n",
            "Epoch 130: Loss: 0.549691 \t\t Validation loss: 0.540351\n",
            "Training average batch accuracy: 0.716750\n",
            "Validation average batch accuracy: 0.733398\n",
            "Epoch 131: Loss: 0.550144 \t\t Validation loss: 0.540480\n",
            "Training average batch accuracy: 0.721625\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 132: Loss: 0.553108 \t\t Validation loss: 0.539652\n",
            "Training average batch accuracy: 0.719000\n",
            "Validation average batch accuracy: 0.737305\n",
            "Epoch 133: Loss: 0.545333 \t\t Validation loss: 0.539340\n",
            "Training average batch accuracy: 0.728625\n",
            "Validation average batch accuracy: 0.730469\n",
            "Epoch 134: Loss: 0.541952 \t\t Validation loss: 0.539396\n",
            "Training average batch accuracy: 0.722250\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 135: Loss: 0.551035 \t\t Validation loss: 0.539772\n",
            "Training average batch accuracy: 0.718000\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 136: Loss: 0.538618 \t\t Validation loss: 0.540280\n",
            "Training average batch accuracy: 0.729875\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 137: Loss: 0.548790 \t\t Validation loss: 0.538859\n",
            "Training average batch accuracy: 0.718125\n",
            "Validation average batch accuracy: 0.734766\n",
            "Epoch 138: Loss: 0.551181 \t\t Validation loss: 0.539671\n",
            "Training average batch accuracy: 0.714750\n",
            "Validation average batch accuracy: 0.737305\n",
            "Epoch 139: Loss: 0.538487 \t\t Validation loss: 0.538888\n",
            "Training average batch accuracy: 0.725875\n",
            "Validation average batch accuracy: 0.733398\n",
            "Epoch 140: Loss: 0.542401 \t\t Validation loss: 0.539611\n",
            "Training average batch accuracy: 0.731250\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 141: Loss: 0.542554 \t\t Validation loss: 0.538551\n",
            "Training average batch accuracy: 0.727625\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 142: Loss: 0.540991 \t\t Validation loss: 0.537213\n",
            "Training average batch accuracy: 0.727375\n",
            "Validation average batch accuracy: 0.738672\n",
            "Epoch 143: Loss: 0.531399 \t\t Validation loss: 0.538292\n",
            "Training average batch accuracy: 0.731250\n",
            "Validation average batch accuracy: 0.737305\n",
            "Epoch 144: Loss: 0.546616 \t\t Validation loss: 0.538269\n",
            "Training average batch accuracy: 0.719625\n",
            "Validation average batch accuracy: 0.733789\n",
            "Epoch 145: Loss: 0.542328 \t\t Validation loss: 0.538118\n",
            "Training average batch accuracy: 0.726000\n",
            "Validation average batch accuracy: 0.734766\n",
            "Epoch 146: Loss: 0.537592 \t\t Validation loss: 0.538338\n",
            "BEST SCORE: tensor(0.7412, device='cuda:0')\n",
            "Training average batch accuracy: 0.725875\n",
            "Validation average batch accuracy: 0.741211\n",
            "Epoch 147: Loss: 0.536626 \t\t Validation loss: 0.538936\n",
            "Training average batch accuracy: 0.732875\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 148: Loss: 0.543171 \t\t Validation loss: 0.538227\n",
            "Training average batch accuracy: 0.725250\n",
            "Validation average batch accuracy: 0.739844\n",
            "Epoch 149: Loss: 0.536241 \t\t Validation loss: 0.538989\n",
            "Training average batch accuracy: 0.730250\n",
            "Validation average batch accuracy: 0.735352\n",
            "Epoch 150: Loss: 0.537348 \t\t Validation loss: 0.536613\n",
            "Training average batch accuracy: 0.733500\n",
            "Validation average batch accuracy: 0.739258\n",
            "Epoch 151: Loss: 0.545349 \t\t Validation loss: 0.536746\n",
            "BEST SCORE: tensor(0.7428, device='cuda:0')\n",
            "Training average batch accuracy: 0.727625\n",
            "Validation average batch accuracy: 0.742773\n",
            "Epoch 152: Loss: 0.532993 \t\t Validation loss: 0.538404\n",
            "Training average batch accuracy: 0.735625\n",
            "Validation average batch accuracy: 0.733008\n",
            "Epoch 153: Loss: 0.537871 \t\t Validation loss: 0.536224\n",
            "Training average batch accuracy: 0.731375\n",
            "Validation average batch accuracy: 0.740234\n",
            "Epoch 154: Loss: 0.535926 \t\t Validation loss: 0.537892\n",
            "Training average batch accuracy: 0.727625\n",
            "Validation average batch accuracy: 0.730469\n",
            "Epoch 155: Loss: 0.527084 \t\t Validation loss: 0.537988\n",
            "Training average batch accuracy: 0.744875\n",
            "Validation average batch accuracy: 0.735352\n",
            "Epoch 156: Loss: 0.535327 \t\t Validation loss: 0.537044\n",
            "Training average batch accuracy: 0.731375\n",
            "Validation average batch accuracy: 0.737305\n",
            "Epoch 157: Loss: 0.539618 \t\t Validation loss: 0.537094\n",
            "Training average batch accuracy: 0.727000\n",
            "Validation average batch accuracy: 0.740625\n",
            "Epoch 158: Loss: 0.529319 \t\t Validation loss: 0.537291\n",
            "Training average batch accuracy: 0.731875\n",
            "Validation average batch accuracy: 0.742188\n",
            "Epoch 159: Loss: 0.527280 \t\t Validation loss: 0.539431\n",
            "Training average batch accuracy: 0.737750\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 160: Loss: 0.523303 \t\t Validation loss: 0.538953\n",
            "Training average batch accuracy: 0.737875\n",
            "Validation average batch accuracy: 0.737305\n",
            "Epoch 161: Loss: 0.534122 \t\t Validation loss: 0.538467\n",
            "Training average batch accuracy: 0.730625\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 162: Loss: 0.531586 \t\t Validation loss: 0.538556\n",
            "Training average batch accuracy: 0.733625\n",
            "Validation average batch accuracy: 0.735352\n",
            "Epoch 163: Loss: 0.529480 \t\t Validation loss: 0.537406\n",
            "Training average batch accuracy: 0.742750\n",
            "Validation average batch accuracy: 0.740234\n",
            "Epoch 164: Loss: 0.527195 \t\t Validation loss: 0.538172\n",
            "Training average batch accuracy: 0.727500\n",
            "Epoch   165: reducing learning rate of group 0 to 2.5000e-04.\n",
            "Validation average batch accuracy: 0.736914\n",
            "Epoch 165: Loss: 0.530217 \t\t Validation loss: 0.538236\n",
            "Training average batch accuracy: 0.734000\n",
            "Validation average batch accuracy: 0.742188\n",
            "Epoch 166: Loss: 0.524699 \t\t Validation loss: 0.538931\n",
            "Training average batch accuracy: 0.733750\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 167: Loss: 0.526214 \t\t Validation loss: 0.538430\n",
            "Training average batch accuracy: 0.735375\n",
            "Validation average batch accuracy: 0.739258\n",
            "Epoch 168: Loss: 0.525938 \t\t Validation loss: 0.538231\n",
            "Training average batch accuracy: 0.739125\n",
            "Validation average batch accuracy: 0.738281\n",
            "Epoch 169: Loss: 0.517349 \t\t Validation loss: 0.540614\n",
            "Training average batch accuracy: 0.744500\n",
            "Validation average batch accuracy: 0.728125\n",
            "Epoch 170: Loss: 0.521720 \t\t Validation loss: 0.538847\n",
            "Training average batch accuracy: 0.737625\n",
            "Validation average batch accuracy: 0.733789\n",
            "Epoch 171: Loss: 0.522595 \t\t Validation loss: 0.538811\n",
            "Training average batch accuracy: 0.737000\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 172: Loss: 0.526157 \t\t Validation loss: 0.539403\n",
            "Training average batch accuracy: 0.735750\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 173: Loss: 0.529237 \t\t Validation loss: 0.539227\n",
            "Training average batch accuracy: 0.739125\n",
            "Validation average batch accuracy: 0.734766\n",
            "Epoch 174: Loss: 0.521865 \t\t Validation loss: 0.539128\n",
            "Training average batch accuracy: 0.740250\n",
            "Validation average batch accuracy: 0.729883\n",
            "Epoch 175: Loss: 0.521975 \t\t Validation loss: 0.538060\n",
            "Training average batch accuracy: 0.738625\n",
            "Epoch   176: reducing learning rate of group 0 to 1.2500e-04.\n",
            "Validation average batch accuracy: 0.731836\n",
            "Epoch 176: Loss: 0.515380 \t\t Validation loss: 0.539324\n",
            "Training average batch accuracy: 0.748125\n",
            "Validation average batch accuracy: 0.733398\n",
            "Epoch 177: Loss: 0.509864 \t\t Validation loss: 0.538629\n",
            "Training average batch accuracy: 0.749500\n",
            "Validation average batch accuracy: 0.729492\n",
            "Epoch 178: Loss: 0.527739 \t\t Validation loss: 0.539316\n",
            "Training average batch accuracy: 0.734625\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 179: Loss: 0.513461 \t\t Validation loss: 0.537816\n",
            "Training average batch accuracy: 0.750500\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 180: Loss: 0.515137 \t\t Validation loss: 0.538343\n",
            "Training average batch accuracy: 0.740750\n",
            "Validation average batch accuracy: 0.739258\n",
            "Epoch 181: Loss: 0.516820 \t\t Validation loss: 0.538436\n",
            "Training average batch accuracy: 0.743375\n",
            "Validation average batch accuracy: 0.737695\n",
            "Epoch 182: Loss: 0.522335 \t\t Validation loss: 0.538658\n",
            "Training average batch accuracy: 0.739125\n",
            "Validation average batch accuracy: 0.732813\n",
            "Epoch 183: Loss: 0.520038 \t\t Validation loss: 0.538839\n",
            "Training average batch accuracy: 0.746500\n",
            "Validation average batch accuracy: 0.737695\n",
            "Epoch 184: Loss: 0.522318 \t\t Validation loss: 0.539929\n",
            "Training average batch accuracy: 0.739375\n",
            "Validation average batch accuracy: 0.732422\n",
            "Epoch 185: Loss: 0.520856 \t\t Validation loss: 0.538843\n",
            "Training average batch accuracy: 0.737125\n",
            "Validation average batch accuracy: 0.733398\n",
            "Epoch 186: Loss: 0.509766 \t\t Validation loss: 0.538361\n",
            "Training average batch accuracy: 0.743750\n",
            "Epoch   187: reducing learning rate of group 0 to 6.2500e-05.\n",
            "Validation average batch accuracy: 0.735352\n",
            "Epoch 187: Loss: 0.507892 \t\t Validation loss: 0.539813\n",
            "Training average batch accuracy: 0.752375\n",
            "Validation average batch accuracy: 0.732422\n",
            "Epoch 188: Loss: 0.518121 \t\t Validation loss: 0.538875\n",
            "Training average batch accuracy: 0.742625\n",
            "Validation average batch accuracy: 0.740820\n",
            "Epoch 189: Loss: 0.516339 \t\t Validation loss: 0.539019\n",
            "Training average batch accuracy: 0.744750\n",
            "Validation average batch accuracy: 0.733398\n",
            "Epoch 190: Loss: 0.511272 \t\t Validation loss: 0.539244\n",
            "Training average batch accuracy: 0.746875\n",
            "Validation average batch accuracy: 0.736914\n",
            "Epoch 191: Loss: 0.506902 \t\t Validation loss: 0.538568\n",
            "Training average batch accuracy: 0.751250\n",
            "Validation average batch accuracy: 0.733398\n",
            "Epoch 192: Loss: 0.518599 \t\t Validation loss: 0.539576\n",
            "Training average batch accuracy: 0.742750\n",
            "Validation average batch accuracy: 0.740234\n",
            "Epoch 193: Loss: 0.516397 \t\t Validation loss: 0.538292\n",
            "Training average batch accuracy: 0.748625\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 194: Loss: 0.515857 \t\t Validation loss: 0.538576\n",
            "Training average batch accuracy: 0.741125\n",
            "Validation average batch accuracy: 0.740234\n",
            "Epoch 195: Loss: 0.516000 \t\t Validation loss: 0.540199\n",
            "Training average batch accuracy: 0.749625\n",
            "Validation average batch accuracy: 0.735937\n",
            "Epoch 196: Loss: 0.512886 \t\t Validation loss: 0.539246\n",
            "Training average batch accuracy: 0.744125\n",
            "Validation average batch accuracy: 0.739258\n",
            "Epoch 197: Loss: 0.513829 \t\t Validation loss: 0.539055\n",
            "Training average batch accuracy: 0.748750\n",
            "Epoch   198: reducing learning rate of group 0 to 3.1250e-05.\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 198: Loss: 0.513809 \t\t Validation loss: 0.538284\n",
            "Training average batch accuracy: 0.750875\n",
            "Validation average batch accuracy: 0.735352\n",
            "Epoch 199: Loss: 0.515791 \t\t Validation loss: 0.538082\n",
            "Training average batch accuracy: 0.742000\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 200: Loss: 0.514856 \t\t Validation loss: 0.540452\n",
            "Training average batch accuracy: 0.749875\n",
            "Validation average batch accuracy: 0.739258\n",
            "Epoch 201: Loss: 0.512206 \t\t Validation loss: 0.539760\n",
            "Training average batch accuracy: 0.744125\n",
            "Validation average batch accuracy: 0.733789\n",
            "Epoch 202: Loss: 0.511378 \t\t Validation loss: 0.539575\n",
            "Training average batch accuracy: 0.745875\n",
            "Validation average batch accuracy: 0.741797\n",
            "Epoch 203: Loss: 0.513913 \t\t Validation loss: 0.539217\n",
            "Training average batch accuracy: 0.743375\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 204: Loss: 0.502076 \t\t Validation loss: 0.539352\n",
            "Training average batch accuracy: 0.754500\n",
            "Validation average batch accuracy: 0.741211\n",
            "Epoch 205: Loss: 0.519659 \t\t Validation loss: 0.538868\n",
            "Training average batch accuracy: 0.740000\n",
            "Validation average batch accuracy: 0.735352\n",
            "Epoch 206: Loss: 0.519559 \t\t Validation loss: 0.540468\n",
            "Training average batch accuracy: 0.742625\n",
            "Validation average batch accuracy: 0.732031\n",
            "Epoch 207: Loss: 0.518349 \t\t Validation loss: 0.539445\n",
            "Training average batch accuracy: 0.744375\n",
            "Validation average batch accuracy: 0.735352\n",
            "Epoch 208: Loss: 0.514956 \t\t Validation loss: 0.538876\n",
            "Training average batch accuracy: 0.750750\n",
            "Epoch   209: reducing learning rate of group 0 to 1.5625e-05.\n",
            "Validation average batch accuracy: 0.739258\n",
            "Epoch 209: Loss: 0.511308 \t\t Validation loss: 0.538840\n",
            "Training average batch accuracy: 0.747500\n",
            "Validation average batch accuracy: 0.735352\n",
            "Epoch 210: Loss: 0.511353 \t\t Validation loss: 0.540803\n",
            "Training average batch accuracy: 0.743750\n",
            "Validation average batch accuracy: 0.731445\n",
            "Epoch 211: Loss: 0.504131 \t\t Validation loss: 0.539720\n",
            "Training average batch accuracy: 0.756375\n",
            "Validation average batch accuracy: 0.730859\n",
            "Epoch 212: Loss: 0.512327 \t\t Validation loss: 0.539618\n",
            "Training average batch accuracy: 0.750625\n",
            "Validation average batch accuracy: 0.737305\n",
            "Epoch 213: Loss: 0.510387 \t\t Validation loss: 0.539127\n",
            "Training average batch accuracy: 0.746875\n",
            "Validation average batch accuracy: 0.740234\n",
            "Epoch 214: Loss: 0.518155 \t\t Validation loss: 0.539029\n",
            "Training average batch accuracy: 0.745750\n",
            "Validation average batch accuracy: 0.730469\n",
            "Epoch 215: Loss: 0.507830 \t\t Validation loss: 0.538228\n",
            "Training average batch accuracy: 0.750875\n",
            "Validation average batch accuracy: 0.737305\n",
            "Epoch 216: Loss: 0.515223 \t\t Validation loss: 0.541722\n",
            "Training average batch accuracy: 0.746625\n",
            "Validation average batch accuracy: 0.729492\n",
            "Epoch 217: Loss: 0.502562 \t\t Validation loss: 0.538539\n",
            "Training average batch accuracy: 0.750000\n",
            "Validation average batch accuracy: 0.732422\n",
            "Epoch 218: Loss: 0.514860 \t\t Validation loss: 0.538808\n",
            "Training average batch accuracy: 0.746375\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 219: Loss: 0.506555 \t\t Validation loss: 0.539309\n",
            "Training average batch accuracy: 0.752500\n",
            "Epoch   220: reducing learning rate of group 0 to 7.8125e-06.\n",
            "Validation average batch accuracy: 0.730469\n",
            "Epoch 220: Loss: 0.516164 \t\t Validation loss: 0.538408\n",
            "Training average batch accuracy: 0.751500\n",
            "Validation average batch accuracy: 0.735352\n",
            "Epoch 221: Loss: 0.506993 \t\t Validation loss: 0.541383\n",
            "Training average batch accuracy: 0.748250\n",
            "Validation average batch accuracy: 0.730469\n",
            "Epoch 222: Loss: 0.506511 \t\t Validation loss: 0.540905\n",
            "Training average batch accuracy: 0.751000\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 223: Loss: 0.514341 \t\t Validation loss: 0.539473\n",
            "Training average batch accuracy: 0.746375\n",
            "Validation average batch accuracy: 0.738281\n",
            "Epoch 224: Loss: 0.509412 \t\t Validation loss: 0.539470\n",
            "Training average batch accuracy: 0.755000\n",
            "Validation average batch accuracy: 0.732422\n",
            "Epoch 225: Loss: 0.508513 \t\t Validation loss: 0.540301\n",
            "Training average batch accuracy: 0.754250\n",
            "Validation average batch accuracy: 0.734961\n",
            "Epoch 226: Loss: 0.511542 \t\t Validation loss: 0.540965\n",
            "Training average batch accuracy: 0.748750\n",
            "Validation average batch accuracy: 0.730859\n",
            "Epoch 227: Loss: 0.509516 \t\t Validation loss: 0.538389\n",
            "Training average batch accuracy: 0.749625\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 228: Loss: 0.519768 \t\t Validation loss: 0.538334\n",
            "Training average batch accuracy: 0.743125\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 229: Loss: 0.509077 \t\t Validation loss: 0.538432\n",
            "Training average batch accuracy: 0.746250\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 230: Loss: 0.502842 \t\t Validation loss: 0.538821\n",
            "Training average batch accuracy: 0.752500\n",
            "Epoch   231: reducing learning rate of group 0 to 3.9063e-06.\n",
            "Validation average batch accuracy: 0.741797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEf-0feEF9aY",
        "outputId": "d976dc88-08da-4ad4-ef23-51f5283218a4"
      },
      "source": [
        "best_model['best_score']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7428, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "D6tfZQ5YFpaO",
        "outputId": "77cd1597-2d16-4547-b902-68d0ea0d2136"
      },
      "source": [
        "plot_hist(hist, 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC0HnowibGsC"
      },
      "source": [
        "### WiC POS = 30"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsqToGtobLx8"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hZV0pM8bL_X",
        "outputId": "87e20c6f-3cde-414d-da41-4aeeb60fdd63"
      },
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, eval_step):\n",
        "    model.eval()\n",
        "    results = []\n",
        "    losses = []\n",
        "    \n",
        "    for i, batch in enumerate(data_loader):\n",
        "        loss, metric = eval_step(model, batch)\n",
        "        losses.append(loss.item())\n",
        "        results.append(metric)\n",
        "\n",
        "    return sum(losses) / len(losses), sum(results) / len(results)\n",
        "\n",
        "model_wic = WiCClassifier(HypParams(), vectors, model_context, \n",
        "                            predict_pos=False).to('cuda')\n",
        "\n",
        "optim_wic = torch.optim.Adam(model_wic.parameters())\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim_wic, factor=0.5, verbose=True)\n",
        "#scheduler=None\n",
        "best_model = {}\n",
        "hist = {}\n",
        "\n",
        "_ = train(train_loader, valid_loader, \n",
        "      model_wic, optim_wic, \n",
        "      train_step_3, \n",
        "      eval_step_3,\n",
        "      260,\n",
        "      scheduler=scheduler, \n",
        "      best_model_mode='accuracy', \n",
        "      best_model=best_model, hist=hist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss: 0.895941 \t\t Validation loss: 0.666299\n",
            "BEST SCORE: tensor(0.5959, device='cuda:0')\n",
            "Training average batch accuracy: 0.514125\n",
            "Validation average batch accuracy: 0.595898\n",
            "Epoch 1: Loss: 0.757352 \t\t Validation loss: 0.676078\n",
            "Training average batch accuracy: 0.534250\n",
            "Validation average batch accuracy: 0.580664\n",
            "Epoch 2: Loss: 0.752785 \t\t Validation loss: 0.664498\n",
            "BEST SCORE: tensor(0.6285, device='cuda:0')\n",
            "Training average batch accuracy: 0.519750\n",
            "Validation average batch accuracy: 0.628516\n",
            "Epoch 3: Loss: 0.744010 \t\t Validation loss: 0.665782\n",
            "Training average batch accuracy: 0.515375\n",
            "Validation average batch accuracy: 0.595117\n",
            "Epoch 4: Loss: 0.733827 \t\t Validation loss: 0.665823\n",
            "Training average batch accuracy: 0.534750\n",
            "Validation average batch accuracy: 0.597656\n",
            "Epoch 5: Loss: 0.735531 \t\t Validation loss: 0.658017\n",
            "Training average batch accuracy: 0.529625\n",
            "Validation average batch accuracy: 0.628516\n",
            "Epoch 6: Loss: 0.727760 \t\t Validation loss: 0.651869\n",
            "BEST SCORE: tensor(0.6428, device='cuda:0')\n",
            "Training average batch accuracy: 0.543125\n",
            "Validation average batch accuracy: 0.642773\n",
            "Epoch 7: Loss: 0.723748 \t\t Validation loss: 0.651082\n",
            "Training average batch accuracy: 0.546000\n",
            "Validation average batch accuracy: 0.642383\n",
            "Epoch 8: Loss: 0.720385 \t\t Validation loss: 0.643830\n",
            "BEST SCORE: tensor(0.6607, device='cuda:0')\n",
            "Training average batch accuracy: 0.552750\n",
            "Validation average batch accuracy: 0.660742\n",
            "Epoch 9: Loss: 0.715547 \t\t Validation loss: 0.647966\n",
            "Training average batch accuracy: 0.560125\n",
            "Validation average batch accuracy: 0.613477\n",
            "Epoch 10: Loss: 0.721780 \t\t Validation loss: 0.638183\n",
            "Training average batch accuracy: 0.552000\n",
            "Validation average batch accuracy: 0.658398\n",
            "Epoch 11: Loss: 0.713249 \t\t Validation loss: 0.638472\n",
            "Training average batch accuracy: 0.563875\n",
            "Validation average batch accuracy: 0.646875\n",
            "Epoch 12: Loss: 0.713268 \t\t Validation loss: 0.632150\n",
            "BEST SCORE: tensor(0.6740, device='cuda:0')\n",
            "Training average batch accuracy: 0.555625\n",
            "Validation average batch accuracy: 0.674023\n",
            "Epoch 13: Loss: 0.710602 \t\t Validation loss: 0.628849\n",
            "BEST SCORE: tensor(0.6775, device='cuda:0')\n",
            "Training average batch accuracy: 0.559125\n",
            "Validation average batch accuracy: 0.677539\n",
            "Epoch 14: Loss: 0.701578 \t\t Validation loss: 0.627181\n",
            "Training average batch accuracy: 0.571875\n",
            "Validation average batch accuracy: 0.659180\n",
            "Epoch 15: Loss: 0.703267 \t\t Validation loss: 0.622807\n",
            "Training average batch accuracy: 0.565625\n",
            "Validation average batch accuracy: 0.671484\n",
            "Epoch 16: Loss: 0.699314 \t\t Validation loss: 0.622269\n",
            "BEST SCORE: tensor(0.6809, device='cuda:0')\n",
            "Training average batch accuracy: 0.569250\n",
            "Validation average batch accuracy: 0.680859\n",
            "Epoch 17: Loss: 0.696115 \t\t Validation loss: 0.621118\n",
            "Training average batch accuracy: 0.573500\n",
            "Validation average batch accuracy: 0.675977\n",
            "Epoch 18: Loss: 0.697040 \t\t Validation loss: 0.611209\n",
            "BEST SCORE: tensor(0.7121, device='cuda:0')\n",
            "Training average batch accuracy: 0.577375\n",
            "Validation average batch accuracy: 0.712109\n",
            "Epoch 19: Loss: 0.691586 \t\t Validation loss: 0.612228\n",
            "Training average batch accuracy: 0.573375\n",
            "Validation average batch accuracy: 0.688672\n",
            "Epoch 20: Loss: 0.687347 \t\t Validation loss: 0.607774\n",
            "Training average batch accuracy: 0.581625\n",
            "Validation average batch accuracy: 0.690625\n",
            "Epoch 21: Loss: 0.682325 \t\t Validation loss: 0.602907\n",
            "Training average batch accuracy: 0.591875\n",
            "Validation average batch accuracy: 0.698633\n",
            "Epoch 22: Loss: 0.685107 \t\t Validation loss: 0.601818\n",
            "Training average batch accuracy: 0.584375\n",
            "Validation average batch accuracy: 0.700781\n",
            "Epoch 23: Loss: 0.676240 \t\t Validation loss: 0.598963\n",
            "Training average batch accuracy: 0.594375\n",
            "Validation average batch accuracy: 0.701953\n",
            "Epoch 24: Loss: 0.682918 \t\t Validation loss: 0.597372\n",
            "Training average batch accuracy: 0.592500\n",
            "Validation average batch accuracy: 0.705469\n",
            "Epoch 25: Loss: 0.677034 \t\t Validation loss: 0.596138\n",
            "Training average batch accuracy: 0.599125\n",
            "Validation average batch accuracy: 0.703711\n",
            "Epoch 26: Loss: 0.667930 \t\t Validation loss: 0.594681\n",
            "BEST SCORE: tensor(0.7139, device='cuda:0')\n",
            "Training average batch accuracy: 0.608500\n",
            "Validation average batch accuracy: 0.713867\n",
            "Epoch 27: Loss: 0.675414 \t\t Validation loss: 0.593092\n",
            "BEST SCORE: tensor(0.7215, device='cuda:0')\n",
            "Training average batch accuracy: 0.600375\n",
            "Validation average batch accuracy: 0.721484\n",
            "Epoch 28: Loss: 0.674766 \t\t Validation loss: 0.593286\n",
            "Training average batch accuracy: 0.598625\n",
            "Validation average batch accuracy: 0.708398\n",
            "Epoch 29: Loss: 0.660431 \t\t Validation loss: 0.585584\n",
            "Training average batch accuracy: 0.618875\n",
            "Validation average batch accuracy: 0.715039\n",
            "Epoch 30: Loss: 0.663498 \t\t Validation loss: 0.584565\n",
            "Training average batch accuracy: 0.608125\n",
            "Validation average batch accuracy: 0.709375\n",
            "Epoch 31: Loss: 0.651637 \t\t Validation loss: 0.578523\n",
            "Training average batch accuracy: 0.626750\n",
            "Validation average batch accuracy: 0.716016\n",
            "Epoch 32: Loss: 0.662117 \t\t Validation loss: 0.582248\n",
            "Training average batch accuracy: 0.615875\n",
            "Validation average batch accuracy: 0.698438\n",
            "Epoch 33: Loss: 0.658409 \t\t Validation loss: 0.579426\n",
            "Training average batch accuracy: 0.619750\n",
            "Validation average batch accuracy: 0.719141\n",
            "Epoch 34: Loss: 0.656272 \t\t Validation loss: 0.582629\n",
            "Training average batch accuracy: 0.614500\n",
            "Validation average batch accuracy: 0.711719\n",
            "Epoch 35: Loss: 0.653758 \t\t Validation loss: 0.579103\n",
            "Training average batch accuracy: 0.616250\n",
            "Validation average batch accuracy: 0.714258\n",
            "Epoch 36: Loss: 0.653010 \t\t Validation loss: 0.581085\n",
            "Training average batch accuracy: 0.623000\n",
            "Validation average batch accuracy: 0.712305\n",
            "Epoch 37: Loss: 0.648243 \t\t Validation loss: 0.576497\n",
            "Training average batch accuracy: 0.632125\n",
            "Validation average batch accuracy: 0.711328\n",
            "Epoch 38: Loss: 0.656520 \t\t Validation loss: 0.575707\n",
            "Training average batch accuracy: 0.617250\n",
            "Validation average batch accuracy: 0.716797\n",
            "Epoch 39: Loss: 0.652540 \t\t Validation loss: 0.575171\n",
            "Training average batch accuracy: 0.625625\n",
            "Validation average batch accuracy: 0.718164\n",
            "Epoch 40: Loss: 0.647000 \t\t Validation loss: 0.578435\n",
            "Training average batch accuracy: 0.620250\n",
            "Validation average batch accuracy: 0.712891\n",
            "Epoch 41: Loss: 0.649711 \t\t Validation loss: 0.579502\n",
            "Training average batch accuracy: 0.629125\n",
            "Validation average batch accuracy: 0.714258\n",
            "Epoch 42: Loss: 0.638763 \t\t Validation loss: 0.573939\n",
            "Training average batch accuracy: 0.637750\n",
            "Validation average batch accuracy: 0.720117\n",
            "Epoch 43: Loss: 0.633360 \t\t Validation loss: 0.569684\n",
            "Training average batch accuracy: 0.633250\n",
            "Validation average batch accuracy: 0.717969\n",
            "Epoch 44: Loss: 0.640573 \t\t Validation loss: 0.568759\n",
            "Training average batch accuracy: 0.637125\n",
            "Validation average batch accuracy: 0.720508\n",
            "Epoch 45: Loss: 0.632883 \t\t Validation loss: 0.565219\n",
            "Training average batch accuracy: 0.647250\n",
            "Validation average batch accuracy: 0.719531\n",
            "Epoch 46: Loss: 0.631949 \t\t Validation loss: 0.567070\n",
            "BEST SCORE: tensor(0.7240, device='cuda:0')\n",
            "Training average batch accuracy: 0.643625\n",
            "Validation average batch accuracy: 0.724023\n",
            "Epoch 47: Loss: 0.629261 \t\t Validation loss: 0.564595\n",
            "Training average batch accuracy: 0.648125\n",
            "Validation average batch accuracy: 0.715625\n",
            "Epoch 48: Loss: 0.622554 \t\t Validation loss: 0.564115\n",
            "BEST SCORE: tensor(0.7250, device='cuda:0')\n",
            "Training average batch accuracy: 0.656000\n",
            "Validation average batch accuracy: 0.725000\n",
            "Epoch 49: Loss: 0.631975 \t\t Validation loss: 0.563555\n",
            "Training average batch accuracy: 0.642500\n",
            "Validation average batch accuracy: 0.721680\n",
            "Epoch 50: Loss: 0.633220 \t\t Validation loss: 0.563171\n",
            "BEST SCORE: tensor(0.7260, device='cuda:0')\n",
            "Training average batch accuracy: 0.646250\n",
            "Validation average batch accuracy: 0.725977\n",
            "Epoch 51: Loss: 0.625862 \t\t Validation loss: 0.565431\n",
            "Training average batch accuracy: 0.643250\n",
            "Validation average batch accuracy: 0.722656\n",
            "Epoch 52: Loss: 0.627782 \t\t Validation loss: 0.563154\n",
            "BEST SCORE: tensor(0.7266, device='cuda:0')\n",
            "Training average batch accuracy: 0.649625\n",
            "Validation average batch accuracy: 0.726562\n",
            "Epoch 53: Loss: 0.620250 \t\t Validation loss: 0.563485\n",
            "BEST SCORE: tensor(0.7275, device='cuda:0')\n",
            "Training average batch accuracy: 0.660000\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 54: Loss: 0.634885 \t\t Validation loss: 0.565006\n",
            "Training average batch accuracy: 0.644500\n",
            "Validation average batch accuracy: 0.725977\n",
            "Epoch 55: Loss: 0.625987 \t\t Validation loss: 0.563929\n",
            "Training average batch accuracy: 0.653875\n",
            "Validation average batch accuracy: 0.717188\n",
            "Epoch 56: Loss: 0.627453 \t\t Validation loss: 0.563941\n",
            "Training average batch accuracy: 0.645250\n",
            "Validation average batch accuracy: 0.719141\n",
            "Epoch 57: Loss: 0.624479 \t\t Validation loss: 0.562590\n",
            "BEST SCORE: tensor(0.7299, device='cuda:0')\n",
            "Training average batch accuracy: 0.653750\n",
            "Validation average batch accuracy: 0.729883\n",
            "Epoch 58: Loss: 0.621132 \t\t Validation loss: 0.559382\n",
            "Training average batch accuracy: 0.656250\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 59: Loss: 0.620513 \t\t Validation loss: 0.558842\n",
            "Training average batch accuracy: 0.649625\n",
            "Validation average batch accuracy: 0.729492\n",
            "Epoch 60: Loss: 0.610882 \t\t Validation loss: 0.560692\n",
            "Training average batch accuracy: 0.663750\n",
            "Validation average batch accuracy: 0.717188\n",
            "Epoch 61: Loss: 0.623301 \t\t Validation loss: 0.561787\n",
            "Training average batch accuracy: 0.655125\n",
            "Validation average batch accuracy: 0.725000\n",
            "Epoch 62: Loss: 0.614600 \t\t Validation loss: 0.560923\n",
            "Training average batch accuracy: 0.662000\n",
            "Validation average batch accuracy: 0.723633\n",
            "Epoch 63: Loss: 0.612068 \t\t Validation loss: 0.557842\n",
            "Training average batch accuracy: 0.665125\n",
            "Validation average batch accuracy: 0.724609\n",
            "Epoch 64: Loss: 0.606830 \t\t Validation loss: 0.557724\n",
            "Training average batch accuracy: 0.669500\n",
            "Validation average batch accuracy: 0.717188\n",
            "Epoch 65: Loss: 0.614136 \t\t Validation loss: 0.556445\n",
            "Training average batch accuracy: 0.669250\n",
            "Validation average batch accuracy: 0.725000\n",
            "Epoch 66: Loss: 0.606347 \t\t Validation loss: 0.553735\n",
            "Training average batch accuracy: 0.664750\n",
            "Validation average batch accuracy: 0.728320\n",
            "Epoch 67: Loss: 0.606529 \t\t Validation loss: 0.554808\n",
            "Training average batch accuracy: 0.669500\n",
            "Validation average batch accuracy: 0.725977\n",
            "Epoch 68: Loss: 0.608469 \t\t Validation loss: 0.553576\n",
            "BEST SCORE: tensor(0.7379, device='cuda:0')\n",
            "Training average batch accuracy: 0.673625\n",
            "Validation average batch accuracy: 0.737891\n",
            "Epoch 69: Loss: 0.605299 \t\t Validation loss: 0.555707\n",
            "Training average batch accuracy: 0.668125\n",
            "Validation average batch accuracy: 0.717773\n",
            "Epoch 70: Loss: 0.600487 \t\t Validation loss: 0.556814\n",
            "Training average batch accuracy: 0.668625\n",
            "Validation average batch accuracy: 0.726562\n",
            "Epoch 71: Loss: 0.602699 \t\t Validation loss: 0.550725\n",
            "Training average batch accuracy: 0.676500\n",
            "Validation average batch accuracy: 0.725977\n",
            "Epoch 72: Loss: 0.610425 \t\t Validation loss: 0.554021\n",
            "Training average batch accuracy: 0.672125\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 73: Loss: 0.601328 \t\t Validation loss: 0.555054\n",
            "Training average batch accuracy: 0.670750\n",
            "Validation average batch accuracy: 0.720117\n",
            "Epoch 74: Loss: 0.601876 \t\t Validation loss: 0.552382\n",
            "Training average batch accuracy: 0.676875\n",
            "Validation average batch accuracy: 0.721680\n",
            "Epoch 75: Loss: 0.595530 \t\t Validation loss: 0.553976\n",
            "Training average batch accuracy: 0.676250\n",
            "Validation average batch accuracy: 0.719727\n",
            "Epoch 76: Loss: 0.602131 \t\t Validation loss: 0.555892\n",
            "Training average batch accuracy: 0.677000\n",
            "Validation average batch accuracy: 0.719727\n",
            "Epoch 77: Loss: 0.599486 \t\t Validation loss: 0.555574\n",
            "Training average batch accuracy: 0.676250\n",
            "Validation average batch accuracy: 0.724609\n",
            "Epoch 78: Loss: 0.593672 \t\t Validation loss: 0.554319\n",
            "Training average batch accuracy: 0.682625\n",
            "Validation average batch accuracy: 0.715234\n",
            "Epoch 79: Loss: 0.594368 \t\t Validation loss: 0.558878\n",
            "Training average batch accuracy: 0.680875\n",
            "Validation average batch accuracy: 0.709961\n",
            "Epoch 80: Loss: 0.592624 \t\t Validation loss: 0.550703\n",
            "Training average batch accuracy: 0.679875\n",
            "Validation average batch accuracy: 0.723047\n",
            "Epoch 81: Loss: 0.586016 \t\t Validation loss: 0.549962\n",
            "Training average batch accuracy: 0.689500\n",
            "Validation average batch accuracy: 0.720117\n",
            "Epoch 82: Loss: 0.588677 \t\t Validation loss: 0.550176\n",
            "Training average batch accuracy: 0.685500\n",
            "Validation average batch accuracy: 0.719727\n",
            "Epoch 83: Loss: 0.589906 \t\t Validation loss: 0.552625\n",
            "Training average batch accuracy: 0.685125\n",
            "Validation average batch accuracy: 0.713867\n",
            "Epoch 84: Loss: 0.587339 \t\t Validation loss: 0.548928\n",
            "Training average batch accuracy: 0.683750\n",
            "Validation average batch accuracy: 0.714844\n",
            "Epoch 85: Loss: 0.594678 \t\t Validation loss: 0.550128\n",
            "Training average batch accuracy: 0.687000\n",
            "Validation average batch accuracy: 0.715820\n",
            "Epoch 86: Loss: 0.587389 \t\t Validation loss: 0.548743\n",
            "Training average batch accuracy: 0.689750\n",
            "Validation average batch accuracy: 0.720703\n",
            "Epoch 87: Loss: 0.582757 \t\t Validation loss: 0.546631\n",
            "Training average batch accuracy: 0.689250\n",
            "Validation average batch accuracy: 0.724023\n",
            "Epoch 88: Loss: 0.580416 \t\t Validation loss: 0.549944\n",
            "Training average batch accuracy: 0.689750\n",
            "Validation average batch accuracy: 0.712891\n",
            "Epoch 89: Loss: 0.592455 \t\t Validation loss: 0.547715\n",
            "Training average batch accuracy: 0.688125\n",
            "Validation average batch accuracy: 0.723633\n",
            "Epoch 90: Loss: 0.587109 \t\t Validation loss: 0.546949\n",
            "Training average batch accuracy: 0.690375\n",
            "Validation average batch accuracy: 0.730469\n",
            "Epoch 91: Loss: 0.588047 \t\t Validation loss: 0.546911\n",
            "Training average batch accuracy: 0.685125\n",
            "Validation average batch accuracy: 0.731055\n",
            "Epoch 92: Loss: 0.582059 \t\t Validation loss: 0.548875\n",
            "Training average batch accuracy: 0.693375\n",
            "Validation average batch accuracy: 0.720703\n",
            "Epoch 93: Loss: 0.581075 \t\t Validation loss: 0.546799\n",
            "Training average batch accuracy: 0.688125\n",
            "Validation average batch accuracy: 0.724609\n",
            "Epoch 94: Loss: 0.572300 \t\t Validation loss: 0.544465\n",
            "Training average batch accuracy: 0.697875\n",
            "Validation average batch accuracy: 0.733398\n",
            "Epoch 95: Loss: 0.581026 \t\t Validation loss: 0.547262\n",
            "Training average batch accuracy: 0.696750\n",
            "Validation average batch accuracy: 0.728906\n",
            "Epoch 96: Loss: 0.574259 \t\t Validation loss: 0.544581\n",
            "Training average batch accuracy: 0.696500\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 97: Loss: 0.573742 \t\t Validation loss: 0.544796\n",
            "Training average batch accuracy: 0.697875\n",
            "Validation average batch accuracy: 0.730859\n",
            "Epoch 98: Loss: 0.577916 \t\t Validation loss: 0.549075\n",
            "Training average batch accuracy: 0.697625\n",
            "Validation average batch accuracy: 0.730469\n",
            "Epoch 99: Loss: 0.573136 \t\t Validation loss: 0.546203\n",
            "Training average batch accuracy: 0.692875\n",
            "Validation average batch accuracy: 0.726562\n",
            "Epoch 100: Loss: 0.575455 \t\t Validation loss: 0.545467\n",
            "Training average batch accuracy: 0.702125\n",
            "Validation average batch accuracy: 0.726953\n",
            "Epoch 101: Loss: 0.589776 \t\t Validation loss: 0.548969\n",
            "Training average batch accuracy: 0.689875\n",
            "Validation average batch accuracy: 0.718164\n",
            "Epoch 102: Loss: 0.579928 \t\t Validation loss: 0.548669\n",
            "Training average batch accuracy: 0.696750\n",
            "Validation average batch accuracy: 0.722461\n",
            "Epoch 103: Loss: 0.569756 \t\t Validation loss: 0.546096\n",
            "Training average batch accuracy: 0.709000\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 104: Loss: 0.578605 \t\t Validation loss: 0.548534\n",
            "Training average batch accuracy: 0.691625\n",
            "Validation average batch accuracy: 0.727930\n",
            "Epoch 105: Loss: 0.561996 \t\t Validation loss: 0.544531\n",
            "Training average batch accuracy: 0.714625\n",
            "Epoch   106: reducing learning rate of group 0 to 5.0000e-04.\n",
            "Validation average batch accuracy: 0.733398\n",
            "Epoch 106: Loss: 0.565214 \t\t Validation loss: 0.546070\n",
            "Training average batch accuracy: 0.706125\n",
            "Validation average batch accuracy: 0.728906\n",
            "Epoch 107: Loss: 0.563467 \t\t Validation loss: 0.545174\n",
            "Training average batch accuracy: 0.710125\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 108: Loss: 0.564630 \t\t Validation loss: 0.543841\n",
            "BEST SCORE: tensor(0.7402, device='cuda:0')\n",
            "Training average batch accuracy: 0.706375\n",
            "Validation average batch accuracy: 0.740234\n",
            "Epoch 109: Loss: 0.563628 \t\t Validation loss: 0.545899\n",
            "Training average batch accuracy: 0.707125\n",
            "Validation average batch accuracy: 0.732422\n",
            "Epoch 110: Loss: 0.563927 \t\t Validation loss: 0.543722\n",
            "Training average batch accuracy: 0.705000\n",
            "Validation average batch accuracy: 0.738672\n",
            "Epoch 111: Loss: 0.555368 \t\t Validation loss: 0.543230\n",
            "Training average batch accuracy: 0.714875\n",
            "Validation average batch accuracy: 0.731836\n",
            "Epoch 112: Loss: 0.560296 \t\t Validation loss: 0.543503\n",
            "Training average batch accuracy: 0.711750\n",
            "Validation average batch accuracy: 0.737695\n",
            "Epoch 113: Loss: 0.553977 \t\t Validation loss: 0.543739\n",
            "Training average batch accuracy: 0.717250\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 114: Loss: 0.561337 \t\t Validation loss: 0.544441\n",
            "Training average batch accuracy: 0.715875\n",
            "Validation average batch accuracy: 0.733398\n",
            "Epoch 115: Loss: 0.554163 \t\t Validation loss: 0.544933\n",
            "Training average batch accuracy: 0.720250\n",
            "Validation average batch accuracy: 0.731250\n",
            "Epoch 116: Loss: 0.552869 \t\t Validation loss: 0.544431\n",
            "Training average batch accuracy: 0.716250\n",
            "Validation average batch accuracy: 0.736719\n",
            "Epoch 117: Loss: 0.560650 \t\t Validation loss: 0.543910\n",
            "Training average batch accuracy: 0.708250\n",
            "Validation average batch accuracy: 0.733789\n",
            "Epoch 118: Loss: 0.544530 \t\t Validation loss: 0.543553\n",
            "Training average batch accuracy: 0.721625\n",
            "Validation average batch accuracy: 0.728906\n",
            "Epoch 119: Loss: 0.558444 \t\t Validation loss: 0.542409\n",
            "Training average batch accuracy: 0.713375\n",
            "Validation average batch accuracy: 0.735937\n",
            "Epoch 120: Loss: 0.547424 \t\t Validation loss: 0.542451\n",
            "Training average batch accuracy: 0.718125\n",
            "Validation average batch accuracy: 0.733789\n",
            "Epoch 121: Loss: 0.544056 \t\t Validation loss: 0.542941\n",
            "Training average batch accuracy: 0.729500\n",
            "Validation average batch accuracy: 0.737305\n",
            "Epoch 122: Loss: 0.548917 \t\t Validation loss: 0.542496\n",
            "Training average batch accuracy: 0.723625\n",
            "Validation average batch accuracy: 0.730273\n",
            "Epoch 123: Loss: 0.548498 \t\t Validation loss: 0.545664\n",
            "Training average batch accuracy: 0.723000\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 124: Loss: 0.547308 \t\t Validation loss: 0.542719\n",
            "Training average batch accuracy: 0.719750\n",
            "Validation average batch accuracy: 0.737305\n",
            "Epoch 125: Loss: 0.543711 \t\t Validation loss: 0.542639\n",
            "BEST SCORE: tensor(0.7412, device='cuda:0')\n",
            "Training average batch accuracy: 0.724500\n",
            "Validation average batch accuracy: 0.741211\n",
            "Epoch 126: Loss: 0.544568 \t\t Validation loss: 0.543102\n",
            "Training average batch accuracy: 0.727875\n",
            "Validation average batch accuracy: 0.738281\n",
            "Epoch 127: Loss: 0.546195 \t\t Validation loss: 0.542625\n",
            "Training average batch accuracy: 0.724375\n",
            "Validation average batch accuracy: 0.737305\n",
            "Epoch 128: Loss: 0.543849 \t\t Validation loss: 0.545305\n",
            "Training average batch accuracy: 0.722000\n",
            "Validation average batch accuracy: 0.735937\n",
            "Epoch 129: Loss: 0.547125 \t\t Validation loss: 0.543309\n",
            "Training average batch accuracy: 0.721250\n",
            "Validation average batch accuracy: 0.733789\n",
            "Epoch 130: Loss: 0.545557 \t\t Validation loss: 0.543678\n",
            "Training average batch accuracy: 0.724875\n",
            "Epoch   131: reducing learning rate of group 0 to 2.5000e-04.\n",
            "Validation average batch accuracy: 0.736719\n",
            "Epoch 131: Loss: 0.540429 \t\t Validation loss: 0.544365\n",
            "Training average batch accuracy: 0.724625\n",
            "Validation average batch accuracy: 0.735742\n",
            "Epoch 132: Loss: 0.540328 \t\t Validation loss: 0.543904\n",
            "Training average batch accuracy: 0.722500\n",
            "Validation average batch accuracy: 0.733398\n",
            "Epoch 133: Loss: 0.532963 \t\t Validation loss: 0.543975\n",
            "Training average batch accuracy: 0.726125\n",
            "Validation average batch accuracy: 0.735352\n",
            "Epoch 134: Loss: 0.536474 \t\t Validation loss: 0.542898\n",
            "Training average batch accuracy: 0.723125\n",
            "Validation average batch accuracy: 0.729492\n",
            "Epoch 135: Loss: 0.540244 \t\t Validation loss: 0.546808\n",
            "Training average batch accuracy: 0.725750\n",
            "Validation average batch accuracy: 0.730859\n",
            "Epoch 136: Loss: 0.534561 \t\t Validation loss: 0.544555\n",
            "Training average batch accuracy: 0.727750\n",
            "Validation average batch accuracy: 0.732813\n",
            "Epoch 137: Loss: 0.537468 \t\t Validation loss: 0.546359\n",
            "Training average batch accuracy: 0.728875\n",
            "Validation average batch accuracy: 0.730469\n",
            "Epoch 138: Loss: 0.539900 \t\t Validation loss: 0.545298\n",
            "Training average batch accuracy: 0.726750\n",
            "Validation average batch accuracy: 0.731836\n",
            "Epoch 139: Loss: 0.534886 \t\t Validation loss: 0.545817\n",
            "Training average batch accuracy: 0.730125\n",
            "Validation average batch accuracy: 0.729883\n",
            "Epoch 140: Loss: 0.530435 \t\t Validation loss: 0.545355\n",
            "Training average batch accuracy: 0.735125\n",
            "Validation average batch accuracy: 0.735352\n",
            "Epoch 141: Loss: 0.530980 \t\t Validation loss: 0.544864\n",
            "Training average batch accuracy: 0.733250\n",
            "Epoch   142: reducing learning rate of group 0 to 1.2500e-04.\n",
            "Validation average batch accuracy: 0.733398\n",
            "Epoch 142: Loss: 0.524634 \t\t Validation loss: 0.544517\n",
            "Training average batch accuracy: 0.744375\n",
            "Validation average batch accuracy: 0.730859\n",
            "Epoch 143: Loss: 0.538264 \t\t Validation loss: 0.543970\n",
            "Training average batch accuracy: 0.731500\n",
            "Validation average batch accuracy: 0.733398\n",
            "Epoch 144: Loss: 0.524207 \t\t Validation loss: 0.547245\n",
            "Training average batch accuracy: 0.730250\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 145: Loss: 0.525874 \t\t Validation loss: 0.545372\n",
            "Training average batch accuracy: 0.738625\n",
            "Validation average batch accuracy: 0.737891\n",
            "Epoch 146: Loss: 0.529488 \t\t Validation loss: 0.544534\n",
            "Training average batch accuracy: 0.729875\n",
            "Validation average batch accuracy: 0.736914\n",
            "Epoch 147: Loss: 0.526257 \t\t Validation loss: 0.547049\n",
            "Training average batch accuracy: 0.735875\n",
            "Validation average batch accuracy: 0.732031\n",
            "Epoch 148: Loss: 0.533400 \t\t Validation loss: 0.544830\n",
            "Training average batch accuracy: 0.736875\n",
            "Validation average batch accuracy: 0.737305\n",
            "Epoch 149: Loss: 0.528947 \t\t Validation loss: 0.543176\n",
            "Training average batch accuracy: 0.733500\n",
            "Validation average batch accuracy: 0.737891\n",
            "Epoch 150: Loss: 0.528114 \t\t Validation loss: 0.547034\n",
            "Training average batch accuracy: 0.733875\n",
            "Validation average batch accuracy: 0.730469\n",
            "Epoch 151: Loss: 0.530452 \t\t Validation loss: 0.544875\n",
            "Training average batch accuracy: 0.739875\n",
            "Validation average batch accuracy: 0.738867\n",
            "Epoch 152: Loss: 0.523206 \t\t Validation loss: 0.543462\n",
            "Training average batch accuracy: 0.740375\n",
            "Epoch   153: reducing learning rate of group 0 to 6.2500e-05.\n",
            "Validation average batch accuracy: 0.737305\n",
            "Epoch 153: Loss: 0.526577 \t\t Validation loss: 0.546296\n",
            "Training average batch accuracy: 0.738375\n",
            "Validation average batch accuracy: 0.737305\n",
            "Epoch 154: Loss: 0.524159 \t\t Validation loss: 0.547251\n",
            "Training average batch accuracy: 0.739625\n",
            "Validation average batch accuracy: 0.735352\n",
            "Epoch 155: Loss: 0.519231 \t\t Validation loss: 0.545978\n",
            "Training average batch accuracy: 0.744875\n",
            "Validation average batch accuracy: 0.733398\n",
            "Epoch 156: Loss: 0.523433 \t\t Validation loss: 0.544593\n",
            "Training average batch accuracy: 0.741875\n",
            "Validation average batch accuracy: 0.732422\n",
            "Epoch 157: Loss: 0.525745 \t\t Validation loss: 0.546029\n",
            "Training average batch accuracy: 0.735375\n",
            "Validation average batch accuracy: 0.731836\n",
            "Epoch 158: Loss: 0.528078 \t\t Validation loss: 0.546196\n",
            "Training average batch accuracy: 0.745625\n",
            "Validation average batch accuracy: 0.739258\n",
            "Epoch 159: Loss: 0.533169 \t\t Validation loss: 0.545676\n",
            "Training average batch accuracy: 0.734000\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 160: Loss: 0.519685 \t\t Validation loss: 0.544184\n",
            "Training average batch accuracy: 0.746250\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 161: Loss: 0.529174 \t\t Validation loss: 0.545659\n",
            "Training average batch accuracy: 0.736000\n",
            "Validation average batch accuracy: 0.729883\n",
            "Epoch 162: Loss: 0.526880 \t\t Validation loss: 0.545926\n",
            "Training average batch accuracy: 0.735500\n",
            "Validation average batch accuracy: 0.738867\n",
            "Epoch 163: Loss: 0.530303 \t\t Validation loss: 0.544822\n",
            "Training average batch accuracy: 0.738500\n",
            "Epoch   164: reducing learning rate of group 0 to 3.1250e-05.\n",
            "Validation average batch accuracy: 0.738281\n",
            "Epoch 164: Loss: 0.524815 \t\t Validation loss: 0.544492\n",
            "Training average batch accuracy: 0.740125\n",
            "Validation average batch accuracy: 0.733984\n",
            "Epoch 165: Loss: 0.528081 \t\t Validation loss: 0.544621\n",
            "Training average batch accuracy: 0.734125\n",
            "Validation average batch accuracy: 0.739844\n",
            "Epoch 166: Loss: 0.530204 \t\t Validation loss: 0.544729\n",
            "Training average batch accuracy: 0.734250\n",
            "Validation average batch accuracy: 0.729883\n",
            "Epoch 167: Loss: 0.526277 \t\t Validation loss: 0.545511\n",
            "Training average batch accuracy: 0.739125\n",
            "Validation average batch accuracy: 0.737305\n",
            "Epoch 168: Loss: 0.527767 \t\t Validation loss: 0.545030\n",
            "Training average batch accuracy: 0.735250\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 169: Loss: 0.524449 \t\t Validation loss: 0.546444\n",
            "Training average batch accuracy: 0.737875\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 170: Loss: 0.526878 \t\t Validation loss: 0.545096\n",
            "Training average batch accuracy: 0.734750\n",
            "Validation average batch accuracy: 0.737891\n",
            "Epoch 171: Loss: 0.520498 \t\t Validation loss: 0.544439\n",
            "Training average batch accuracy: 0.738375\n",
            "Validation average batch accuracy: 0.734961\n",
            "Epoch 172: Loss: 0.520339 \t\t Validation loss: 0.547420\n",
            "Training average batch accuracy: 0.735875\n",
            "Validation average batch accuracy: 0.737305\n",
            "Epoch 173: Loss: 0.522822 \t\t Validation loss: 0.545977\n",
            "Training average batch accuracy: 0.739125\n",
            "Validation average batch accuracy: 0.730859\n",
            "Epoch 174: Loss: 0.524385 \t\t Validation loss: 0.544948\n",
            "Training average batch accuracy: 0.740875\n",
            "Epoch   175: reducing learning rate of group 0 to 1.5625e-05.\n",
            "Validation average batch accuracy: 0.732813\n",
            "Epoch 175: Loss: 0.521720 \t\t Validation loss: 0.545571\n",
            "Training average batch accuracy: 0.742000\n",
            "Validation average batch accuracy: 0.741211\n",
            "Epoch 176: Loss: 0.520263 \t\t Validation loss: 0.547922\n",
            "Training average batch accuracy: 0.747625\n",
            "Validation average batch accuracy: 0.738281\n",
            "Epoch 177: Loss: 0.521047 \t\t Validation loss: 0.543894\n",
            "Training average batch accuracy: 0.743250\n",
            "Validation average batch accuracy: 0.736914\n",
            "Epoch 178: Loss: 0.516955 \t\t Validation loss: 0.544828\n",
            "Training average batch accuracy: 0.746000\n",
            "Validation average batch accuracy: 0.739258\n",
            "Epoch 179: Loss: 0.531802 \t\t Validation loss: 0.547648\n",
            "Training average batch accuracy: 0.737125\n",
            "Validation average batch accuracy: 0.735352\n",
            "Epoch 180: Loss: 0.534653 \t\t Validation loss: 0.545694\n",
            "Training average batch accuracy: 0.737625\n",
            "Validation average batch accuracy: 0.731836\n",
            "Epoch 181: Loss: 0.520567 \t\t Validation loss: 0.544651\n",
            "Training average batch accuracy: 0.740750\n",
            "Validation average batch accuracy: 0.732422\n",
            "Epoch 182: Loss: 0.525137 \t\t Validation loss: 0.544149\n",
            "Training average batch accuracy: 0.746500\n",
            "Validation average batch accuracy: 0.735937\n",
            "Epoch 183: Loss: 0.521349 \t\t Validation loss: 0.544001\n",
            "Training average batch accuracy: 0.740625\n",
            "Validation average batch accuracy: 0.737305\n",
            "Epoch 184: Loss: 0.533189 \t\t Validation loss: 0.544223\n",
            "Training average batch accuracy: 0.736000\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 185: Loss: 0.521513 \t\t Validation loss: 0.544255\n",
            "Training average batch accuracy: 0.740125\n",
            "Epoch   186: reducing learning rate of group 0 to 7.8125e-06.\n",
            "Validation average batch accuracy: 0.735352\n",
            "Epoch 186: Loss: 0.524186 \t\t Validation loss: 0.543442\n",
            "Training average batch accuracy: 0.741375\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 187: Loss: 0.513549 \t\t Validation loss: 0.545165\n",
            "Training average batch accuracy: 0.745250\n",
            "Validation average batch accuracy: 0.737891\n",
            "Epoch 188: Loss: 0.519651 \t\t Validation loss: 0.544936\n",
            "Training average batch accuracy: 0.739125\n",
            "Validation average batch accuracy: 0.735352\n",
            "Epoch 189: Loss: 0.513312 \t\t Validation loss: 0.544794\n",
            "BEST SCORE: tensor(0.7418, device='cuda:0')\n",
            "Training average batch accuracy: 0.746500\n",
            "Validation average batch accuracy: 0.741797\n",
            "Epoch 190: Loss: 0.528621 \t\t Validation loss: 0.547440\n",
            "Training average batch accuracy: 0.741000\n",
            "Validation average batch accuracy: 0.738281\n",
            "Epoch 191: Loss: 0.518473 \t\t Validation loss: 0.548407\n",
            "Training average batch accuracy: 0.745000\n",
            "Validation average batch accuracy: 0.729883\n",
            "Epoch 192: Loss: 0.529726 \t\t Validation loss: 0.545291\n",
            "Training average batch accuracy: 0.740250\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 193: Loss: 0.530998 \t\t Validation loss: 0.545176\n",
            "Training average batch accuracy: 0.734125\n",
            "Validation average batch accuracy: 0.739258\n",
            "Epoch 194: Loss: 0.523794 \t\t Validation loss: 0.545201\n",
            "Training average batch accuracy: 0.741875\n",
            "Validation average batch accuracy: 0.739258\n",
            "Epoch 195: Loss: 0.520027 \t\t Validation loss: 0.544913\n",
            "Training average batch accuracy: 0.743000\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 196: Loss: 0.528215 \t\t Validation loss: 0.544880\n",
            "Training average batch accuracy: 0.733500\n",
            "Epoch   197: reducing learning rate of group 0 to 3.9063e-06.\n",
            "Validation average batch accuracy: 0.738867\n",
            "Epoch 197: Loss: 0.522714 \t\t Validation loss: 0.545223\n",
            "Training average batch accuracy: 0.741250\n",
            "Validation average batch accuracy: 0.737695\n",
            "Epoch 198: Loss: 0.519380 \t\t Validation loss: 0.545544\n",
            "Training average batch accuracy: 0.742500\n",
            "Validation average batch accuracy: 0.738281\n",
            "Epoch 199: Loss: 0.525349 \t\t Validation loss: 0.545969\n",
            "Training average batch accuracy: 0.744250\n",
            "Validation average batch accuracy: 0.739258\n",
            "Epoch 200: Loss: 0.519003 \t\t Validation loss: 0.543810\n",
            "Training average batch accuracy: 0.741625\n",
            "Validation average batch accuracy: 0.737305\n",
            "Epoch 201: Loss: 0.517052 \t\t Validation loss: 0.545353\n",
            "Training average batch accuracy: 0.743875\n",
            "Validation average batch accuracy: 0.731836\n",
            "Epoch 202: Loss: 0.524814 \t\t Validation loss: 0.547033\n",
            "Training average batch accuracy: 0.742750\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 203: Loss: 0.514812 \t\t Validation loss: 0.547761\n",
            "Training average batch accuracy: 0.744875\n",
            "Validation average batch accuracy: 0.731445\n",
            "Epoch 204: Loss: 0.526350 \t\t Validation loss: 0.544300\n",
            "Training average batch accuracy: 0.741875\n",
            "Validation average batch accuracy: 0.733789\n",
            "Epoch 205: Loss: 0.522704 \t\t Validation loss: 0.545682\n",
            "Training average batch accuracy: 0.747375\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 206: Loss: 0.527877 \t\t Validation loss: 0.546303\n",
            "Training average batch accuracy: 0.735250\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 207: Loss: 0.519616 \t\t Validation loss: 0.545197\n",
            "Training average batch accuracy: 0.741375\n",
            "Epoch   208: reducing learning rate of group 0 to 1.9531e-06.\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 208: Loss: 0.522821 \t\t Validation loss: 0.546739\n",
            "Training average batch accuracy: 0.739000\n",
            "Validation average batch accuracy: 0.739258\n",
            "Epoch 209: Loss: 0.522843 \t\t Validation loss: 0.544122\n",
            "Training average batch accuracy: 0.738625\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 210: Loss: 0.526257 \t\t Validation loss: 0.544133\n",
            "Training average batch accuracy: 0.739750\n",
            "Validation average batch accuracy: 0.735352\n",
            "Epoch 211: Loss: 0.525598 \t\t Validation loss: 0.544957\n",
            "Training average batch accuracy: 0.740250\n",
            "Validation average batch accuracy: 0.734766\n",
            "Epoch 212: Loss: 0.528990 \t\t Validation loss: 0.545414\n",
            "Training average batch accuracy: 0.739000\n",
            "Validation average batch accuracy: 0.733398\n",
            "Epoch 213: Loss: 0.529432 \t\t Validation loss: 0.546237\n",
            "Training average batch accuracy: 0.739375\n",
            "Validation average batch accuracy: 0.739258\n",
            "Epoch 214: Loss: 0.518036 \t\t Validation loss: 0.544332\n",
            "Training average batch accuracy: 0.740750\n",
            "Validation average batch accuracy: 0.734766\n",
            "Epoch 215: Loss: 0.523478 \t\t Validation loss: 0.544196\n",
            "Training average batch accuracy: 0.736875\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 216: Loss: 0.532084 \t\t Validation loss: 0.545440\n",
            "Training average batch accuracy: 0.734875\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 217: Loss: 0.524086 \t\t Validation loss: 0.544023\n",
            "Training average batch accuracy: 0.741375\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 218: Loss: 0.527074 \t\t Validation loss: 0.545059\n",
            "Training average batch accuracy: 0.736625\n",
            "Epoch   219: reducing learning rate of group 0 to 9.7656e-07.\n",
            "Validation average batch accuracy: 0.731836\n",
            "Epoch 219: Loss: 0.529849 \t\t Validation loss: 0.546740\n",
            "Training average batch accuracy: 0.745125\n",
            "Validation average batch accuracy: 0.739844\n",
            "Epoch 220: Loss: 0.524893 \t\t Validation loss: 0.546297\n",
            "Training average batch accuracy: 0.738500\n",
            "Validation average batch accuracy: 0.739258\n",
            "Epoch 221: Loss: 0.524822 \t\t Validation loss: 0.544087\n",
            "Training average batch accuracy: 0.737375\n",
            "Validation average batch accuracy: 0.735352\n",
            "Epoch 222: Loss: 0.524958 \t\t Validation loss: 0.545757\n",
            "Training average batch accuracy: 0.739625\n",
            "Validation average batch accuracy: 0.741211\n",
            "Epoch 223: Loss: 0.527034 \t\t Validation loss: 0.544342\n",
            "Training average batch accuracy: 0.739500\n",
            "Validation average batch accuracy: 0.732422\n",
            "Epoch 224: Loss: 0.523224 \t\t Validation loss: 0.545650\n",
            "Training average batch accuracy: 0.744125\n",
            "Validation average batch accuracy: 0.739258\n",
            "Epoch 225: Loss: 0.521481 \t\t Validation loss: 0.545064\n",
            "Training average batch accuracy: 0.743750\n",
            "Validation average batch accuracy: 0.735937\n",
            "Epoch 226: Loss: 0.523405 \t\t Validation loss: 0.543738\n",
            "Training average batch accuracy: 0.741750\n",
            "Validation average batch accuracy: 0.737305\n",
            "Epoch 227: Loss: 0.524449 \t\t Validation loss: 0.546554\n",
            "Training average batch accuracy: 0.736125\n",
            "Validation average batch accuracy: 0.739258\n",
            "Epoch 228: Loss: 0.524479 \t\t Validation loss: 0.543773\n",
            "Training average batch accuracy: 0.742875\n",
            "Validation average batch accuracy: 0.737305\n",
            "Epoch 229: Loss: 0.521531 \t\t Validation loss: 0.544473\n",
            "Training average batch accuracy: 0.741750\n",
            "Epoch   230: reducing learning rate of group 0 to 4.8828e-07.\n",
            "Validation average batch accuracy: 0.739844\n",
            "Epoch 230: Loss: 0.516486 \t\t Validation loss: 0.544665\n",
            "BEST SCORE: tensor(0.7422, device='cuda:0')\n",
            "Training average batch accuracy: 0.746000\n",
            "Validation average batch accuracy: 0.742188\n",
            "Epoch 231: Loss: 0.519600 \t\t Validation loss: 0.545964\n",
            "Training average batch accuracy: 0.739375\n",
            "Validation average batch accuracy: 0.734766\n",
            "Epoch 232: Loss: 0.530260 \t\t Validation loss: 0.545250\n",
            "Training average batch accuracy: 0.737750\n",
            "Validation average batch accuracy: 0.730859\n",
            "Epoch 233: Loss: 0.526242 \t\t Validation loss: 0.544617\n",
            "Training average batch accuracy: 0.739125\n",
            "Validation average batch accuracy: 0.730859\n",
            "Epoch 234: Loss: 0.522140 \t\t Validation loss: 0.545410\n",
            "Training average batch accuracy: 0.740250\n",
            "Validation average batch accuracy: 0.738281\n",
            "Epoch 235: Loss: 0.526387 \t\t Validation loss: 0.545072\n",
            "Training average batch accuracy: 0.738125\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 236: Loss: 0.518720 \t\t Validation loss: 0.544937\n",
            "Training average batch accuracy: 0.740125\n",
            "Validation average batch accuracy: 0.742188\n",
            "Epoch 237: Loss: 0.527855 \t\t Validation loss: 0.544597\n",
            "Training average batch accuracy: 0.743125\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 238: Loss: 0.520653 \t\t Validation loss: 0.546062\n",
            "Training average batch accuracy: 0.738750\n",
            "Validation average batch accuracy: 0.733398\n",
            "Epoch 239: Loss: 0.526119 \t\t Validation loss: 0.545306\n",
            "Training average batch accuracy: 0.740250\n",
            "Validation average batch accuracy: 0.734766\n",
            "Epoch 240: Loss: 0.523841 \t\t Validation loss: 0.545162\n",
            "Training average batch accuracy: 0.738125\n",
            "Epoch   241: reducing learning rate of group 0 to 2.4414e-07.\n",
            "Validation average batch accuracy: 0.733398\n",
            "Epoch 241: Loss: 0.528904 \t\t Validation loss: 0.543858\n",
            "Training average batch accuracy: 0.740625\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 242: Loss: 0.528838 \t\t Validation loss: 0.545275\n",
            "Training average batch accuracy: 0.741750\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 243: Loss: 0.525181 \t\t Validation loss: 0.545935\n",
            "Training average batch accuracy: 0.742375\n",
            "Validation average batch accuracy: 0.736328\n",
            "Epoch 244: Loss: 0.520479 \t\t Validation loss: 0.544988\n",
            "Training average batch accuracy: 0.742750\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 245: Loss: 0.524769 \t\t Validation loss: 0.544102\n",
            "Training average batch accuracy: 0.742375\n",
            "Validation average batch accuracy: 0.727930\n",
            "Epoch 246: Loss: 0.516494 \t\t Validation loss: 0.547235\n",
            "Training average batch accuracy: 0.745250\n",
            "Validation average batch accuracy: 0.738281\n",
            "Epoch 247: Loss: 0.521819 \t\t Validation loss: 0.545065\n",
            "Training average batch accuracy: 0.738375\n",
            "Validation average batch accuracy: 0.739258\n",
            "Epoch 248: Loss: 0.522520 \t\t Validation loss: 0.545059\n",
            "Training average batch accuracy: 0.742250\n",
            "Validation average batch accuracy: 0.735937\n",
            "Epoch 249: Loss: 0.530992 \t\t Validation loss: 0.546902\n",
            "Training average batch accuracy: 0.734375\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 250: Loss: 0.521693 \t\t Validation loss: 0.544273\n",
            "Training average batch accuracy: 0.740375\n",
            "Validation average batch accuracy: 0.738672\n",
            "Epoch 251: Loss: 0.529121 \t\t Validation loss: 0.545844\n",
            "Training average batch accuracy: 0.734000\n",
            "Epoch   252: reducing learning rate of group 0 to 1.2207e-07.\n",
            "Validation average batch accuracy: 0.732422\n",
            "Epoch 252: Loss: 0.525869 \t\t Validation loss: 0.544848\n",
            "Training average batch accuracy: 0.742625\n",
            "Validation average batch accuracy: 0.737305\n",
            "Epoch 253: Loss: 0.521709 \t\t Validation loss: 0.546796\n",
            "Training average batch accuracy: 0.740000\n",
            "Validation average batch accuracy: 0.737305\n",
            "Epoch 254: Loss: 0.522460 \t\t Validation loss: 0.546033\n",
            "Training average batch accuracy: 0.738000\n",
            "Validation average batch accuracy: 0.734375\n",
            "Epoch 255: Loss: 0.518389 \t\t Validation loss: 0.544993\n",
            "Training average batch accuracy: 0.746250\n",
            "Validation average batch accuracy: 0.738281\n",
            "Epoch 256: Loss: 0.523432 \t\t Validation loss: 0.543825\n",
            "Training average batch accuracy: 0.739625\n",
            "Validation average batch accuracy: 0.739258\n",
            "Epoch 257: Loss: 0.527604 \t\t Validation loss: 0.543907\n",
            "Training average batch accuracy: 0.736000\n",
            "Validation average batch accuracy: 0.735352\n",
            "Epoch 258: Loss: 0.516815 \t\t Validation loss: 0.547055\n",
            "Training average batch accuracy: 0.750875\n",
            "Validation average batch accuracy: 0.732422\n",
            "Epoch 259: Loss: 0.537561 \t\t Validation loss: 0.544736\n",
            "Training average batch accuracy: 0.733125\n",
            "Validation average batch accuracy: 0.741211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr89-J2fbL_Y",
        "outputId": "01d9d403-bf62-48e1-f6f0-02c47d729de7"
      },
      "source": [
        "best_model['best_score']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7422, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJkeLNqtbL_Y"
      },
      "source": [
        "{          'epoch': 178,\n",
        "}, \"/content/drive/MyDrive/Sapienza/WiC_pos_dim_30.pth\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "Cp4uSrkBbU-c",
        "outputId": "8ee21c06-c4db-4954-e082-325cdaa61efd"
      },
      "source": [
        "plot_hist(hist, window=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpI8esh5pqiA"
      },
      "source": [
        "### Multi-learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfcSXsYLpuj9"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRTn6FwQpuua",
        "outputId": "a7327106-a1e4-4439-bec4-b3a3ac6fcff9"
      },
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, eval_step):\n",
        "    model.eval()\n",
        "    results = []\n",
        "    losses = []\n",
        "    \n",
        "    for i, batch in enumerate(data_loader):\n",
        "        loss, metric = eval_step(model, batch)\n",
        "        losses.append(loss.item())\n",
        "        results.append(metric)\n",
        "\n",
        "    return sum(losses) / len(losses), sum(results) / len(results)\n",
        "\n",
        "model_wic = WiCClassifier(HypParams(), vectors, model_context, \n",
        "                            predict_pos=True\n",
        "                          ).to('cuda')\n",
        "\n",
        "optim_wic = torch.optim.Adam(model_wic.parameters())\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim_wic, factor=0.5, verbose=True)\n",
        "#scheduler=None\n",
        "best_model = {}\n",
        "hist = {}\n",
        "\n",
        "_ = train(train_loader, valid_loader, \n",
        "      model_wic, optim_wic, \n",
        "      train_step_3, \n",
        "      eval_step_3,\n",
        "      260,\n",
        "      scheduler=scheduler, \n",
        "      best_model_mode='accuracy', \n",
        "      best_model=best_model, hist=hist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss: 2.404471 \t\t Validation loss: 1.612491\n",
            "BEST SCORE: tensor(0.5941, device='cuda:0')\n",
            "Training average batch accuracy: 0.527000\n",
            "Validation average batch accuracy: 0.594141\n",
            "Epoch 1: Loss: 1.988850 \t\t Validation loss: 1.614282\n",
            "BEST SCORE: tensor(0.6207, device='cuda:0')\n",
            "Training average batch accuracy: 0.517875\n",
            "Validation average batch accuracy: 0.620703\n",
            "Epoch 2: Loss: 1.939136 \t\t Validation loss: 1.615588\n",
            "Training average batch accuracy: 0.523750\n",
            "Validation average batch accuracy: 0.613281\n",
            "Epoch 3: Loss: 1.907889 \t\t Validation loss: 1.608220\n",
            "BEST SCORE: tensor(0.6387, device='cuda:0')\n",
            "Training average batch accuracy: 0.528500\n",
            "Validation average batch accuracy: 0.638672\n",
            "Epoch 4: Loss: 1.912886 \t\t Validation loss: 1.601080\n",
            "Training average batch accuracy: 0.522250\n",
            "Validation average batch accuracy: 0.606836\n",
            "Epoch 5: Loss: 1.886110 \t\t Validation loss: 1.598670\n",
            "Training average batch accuracy: 0.524125\n",
            "Validation average batch accuracy: 0.617773\n",
            "Epoch 6: Loss: 1.875783 \t\t Validation loss: 1.603372\n",
            "Training average batch accuracy: 0.537375\n",
            "Validation average batch accuracy: 0.634766\n",
            "Epoch 7: Loss: 1.876182 \t\t Validation loss: 1.608583\n",
            "Training average batch accuracy: 0.529875\n",
            "Validation average batch accuracy: 0.612305\n",
            "Epoch 8: Loss: 1.854888 \t\t Validation loss: 1.592721\n",
            "BEST SCORE: tensor(0.6510, device='cuda:0')\n",
            "Training average batch accuracy: 0.539750\n",
            "Validation average batch accuracy: 0.650977\n",
            "Epoch 9: Loss: 1.852423 \t\t Validation loss: 1.602726\n",
            "BEST SCORE: tensor(0.6512, device='cuda:0')\n",
            "Training average batch accuracy: 0.543375\n",
            "Validation average batch accuracy: 0.651172\n",
            "Epoch 10: Loss: 1.840705 \t\t Validation loss: 1.594031\n",
            "BEST SCORE: tensor(0.6557, device='cuda:0')\n",
            "Training average batch accuracy: 0.542125\n",
            "Validation average batch accuracy: 0.655664\n",
            "Epoch 11: Loss: 1.836245 \t\t Validation loss: 1.580210\n",
            "Training average batch accuracy: 0.538125\n",
            "Validation average batch accuracy: 0.650781\n",
            "Epoch 12: Loss: 1.814537 \t\t Validation loss: 1.586097\n",
            "BEST SCORE: tensor(0.6695, device='cuda:0')\n",
            "Training average batch accuracy: 0.548250\n",
            "Validation average batch accuracy: 0.669531\n",
            "Epoch 13: Loss: 1.797841 \t\t Validation loss: 1.579213\n",
            "Training average batch accuracy: 0.544125\n",
            "Validation average batch accuracy: 0.668945\n",
            "Epoch 14: Loss: 1.803687 \t\t Validation loss: 1.580243\n",
            "BEST SCORE: tensor(0.6830, device='cuda:0')\n",
            "Training average batch accuracy: 0.554125\n",
            "Validation average batch accuracy: 0.683008\n",
            "Epoch 15: Loss: 1.792528 \t\t Validation loss: 1.583160\n",
            "Training average batch accuracy: 0.555500\n",
            "Validation average batch accuracy: 0.681836\n",
            "Epoch 16: Loss: 1.777267 \t\t Validation loss: 1.558492\n",
            "Training average batch accuracy: 0.558125\n",
            "Validation average batch accuracy: 0.675391\n",
            "Epoch 17: Loss: 1.792199 \t\t Validation loss: 1.574323\n",
            "Training average batch accuracy: 0.560750\n",
            "Validation average batch accuracy: 0.681445\n",
            "Epoch 18: Loss: 1.768373 \t\t Validation loss: 1.571143\n",
            "Training average batch accuracy: 0.570625\n",
            "Validation average batch accuracy: 0.678906\n",
            "Epoch 19: Loss: 1.768216 \t\t Validation loss: 1.562526\n",
            "Training average batch accuracy: 0.563500\n",
            "Validation average batch accuracy: 0.678516\n",
            "Epoch 20: Loss: 1.753669 \t\t Validation loss: 1.559813\n",
            "Training average batch accuracy: 0.566125\n",
            "Validation average batch accuracy: 0.677930\n",
            "Epoch 21: Loss: 1.737288 \t\t Validation loss: 1.559859\n",
            "BEST SCORE: tensor(0.6904, device='cuda:0')\n",
            "Training average batch accuracy: 0.582250\n",
            "Validation average batch accuracy: 0.690430\n",
            "Epoch 22: Loss: 1.737697 \t\t Validation loss: 1.551860\n",
            "Training average batch accuracy: 0.584000\n",
            "Validation average batch accuracy: 0.659766\n",
            "Epoch 23: Loss: 1.735786 \t\t Validation loss: 1.545250\n",
            "Training average batch accuracy: 0.574000\n",
            "Validation average batch accuracy: 0.683008\n",
            "Epoch 24: Loss: 1.729201 \t\t Validation loss: 1.544375\n",
            "BEST SCORE: tensor(0.6941, device='cuda:0')\n",
            "Training average batch accuracy: 0.582875\n",
            "Validation average batch accuracy: 0.694141\n",
            "Epoch 25: Loss: 1.729965 \t\t Validation loss: 1.553725\n",
            "Training average batch accuracy: 0.579750\n",
            "Validation average batch accuracy: 0.681641\n",
            "Epoch 26: Loss: 1.706488 \t\t Validation loss: 1.546169\n",
            "BEST SCORE: tensor(0.6951, device='cuda:0')\n",
            "Training average batch accuracy: 0.588750\n",
            "Validation average batch accuracy: 0.695117\n",
            "Epoch 27: Loss: 1.715298 \t\t Validation loss: 1.547351\n",
            "BEST SCORE: tensor(0.6986, device='cuda:0')\n",
            "Training average batch accuracy: 0.584000\n",
            "Validation average batch accuracy: 0.698633\n",
            "Epoch 28: Loss: 1.702875 \t\t Validation loss: 1.536162\n",
            "Training average batch accuracy: 0.586250\n",
            "Validation average batch accuracy: 0.698438\n",
            "Epoch 29: Loss: 1.698404 \t\t Validation loss: 1.540057\n",
            "BEST SCORE: tensor(0.7080, device='cuda:0')\n",
            "Training average batch accuracy: 0.589750\n",
            "Validation average batch accuracy: 0.708008\n",
            "Epoch 30: Loss: 1.686398 \t\t Validation loss: 1.527046\n",
            "BEST SCORE: tensor(0.7113, device='cuda:0')\n",
            "Training average batch accuracy: 0.597750\n",
            "Validation average batch accuracy: 0.711328\n",
            "Epoch 31: Loss: 1.694136 \t\t Validation loss: 1.527454\n",
            "Training average batch accuracy: 0.589375\n",
            "Validation average batch accuracy: 0.703906\n",
            "Epoch 32: Loss: 1.668025 \t\t Validation loss: 1.529110\n",
            "Training average batch accuracy: 0.605625\n",
            "Validation average batch accuracy: 0.692187\n",
            "Epoch 33: Loss: 1.671691 \t\t Validation loss: 1.524451\n",
            "BEST SCORE: tensor(0.7119, device='cuda:0')\n",
            "Training average batch accuracy: 0.603500\n",
            "Validation average batch accuracy: 0.711914\n",
            "Epoch 34: Loss: 1.684656 \t\t Validation loss: 1.527783\n",
            "Training average batch accuracy: 0.597750\n",
            "Validation average batch accuracy: 0.698047\n",
            "Epoch 35: Loss: 1.676371 \t\t Validation loss: 1.533033\n",
            "BEST SCORE: tensor(0.7146, device='cuda:0')\n",
            "Training average batch accuracy: 0.598625\n",
            "Validation average batch accuracy: 0.714648\n",
            "Epoch 36: Loss: 1.671673 \t\t Validation loss: 1.527936\n",
            "Training average batch accuracy: 0.608000\n",
            "Validation average batch accuracy: 0.706250\n",
            "Epoch 37: Loss: 1.673481 \t\t Validation loss: 1.526000\n",
            "Training average batch accuracy: 0.597125\n",
            "Validation average batch accuracy: 0.713867\n",
            "Epoch 38: Loss: 1.657765 \t\t Validation loss: 1.517061\n",
            "BEST SCORE: tensor(0.7217, device='cuda:0')\n",
            "Training average batch accuracy: 0.612625\n",
            "Validation average batch accuracy: 0.721680\n",
            "Epoch 39: Loss: 1.650090 \t\t Validation loss: 1.511047\n",
            "Training average batch accuracy: 0.618875\n",
            "Validation average batch accuracy: 0.714258\n",
            "Epoch 40: Loss: 1.653272 \t\t Validation loss: 1.509797\n",
            "Training average batch accuracy: 0.615000\n",
            "Validation average batch accuracy: 0.703320\n",
            "Epoch 41: Loss: 1.650222 \t\t Validation loss: 1.511561\n",
            "Training average batch accuracy: 0.620250\n",
            "Validation average batch accuracy: 0.704883\n",
            "Epoch 42: Loss: 1.650622 \t\t Validation loss: 1.515335\n",
            "Training average batch accuracy: 0.611750\n",
            "Validation average batch accuracy: 0.715234\n",
            "Epoch 43: Loss: 1.643507 \t\t Validation loss: 1.510199\n",
            "Training average batch accuracy: 0.607625\n",
            "Validation average batch accuracy: 0.710156\n",
            "Epoch 44: Loss: 1.646788 \t\t Validation loss: 1.512585\n",
            "Training average batch accuracy: 0.622125\n",
            "Validation average batch accuracy: 0.700391\n",
            "Epoch 45: Loss: 1.640977 \t\t Validation loss: 1.522213\n",
            "Training average batch accuracy: 0.604125\n",
            "Validation average batch accuracy: 0.698438\n",
            "Epoch 46: Loss: 1.634569 \t\t Validation loss: 1.507567\n",
            "Training average batch accuracy: 0.625625\n",
            "Validation average batch accuracy: 0.715430\n",
            "Epoch 47: Loss: 1.631905 \t\t Validation loss: 1.505102\n",
            "Training average batch accuracy: 0.620750\n",
            "Validation average batch accuracy: 0.708789\n",
            "Epoch 48: Loss: 1.627920 \t\t Validation loss: 1.498132\n",
            "Training average batch accuracy: 0.619500\n",
            "Validation average batch accuracy: 0.721680\n",
            "Epoch 49: Loss: 1.623627 \t\t Validation loss: 1.493819\n",
            "BEST SCORE: tensor(0.7227, device='cuda:0')\n",
            "Training average batch accuracy: 0.634750\n",
            "Validation average batch accuracy: 0.722656\n",
            "Epoch 50: Loss: 1.622771 \t\t Validation loss: 1.497089\n",
            "Training average batch accuracy: 0.626000\n",
            "Validation average batch accuracy: 0.709766\n",
            "Epoch 51: Loss: 1.620743 \t\t Validation loss: 1.505743\n",
            "Training average batch accuracy: 0.627250\n",
            "Validation average batch accuracy: 0.722070\n",
            "Epoch 52: Loss: 1.616018 \t\t Validation loss: 1.504389\n",
            "Training average batch accuracy: 0.632125\n",
            "Validation average batch accuracy: 0.719141\n",
            "Epoch 53: Loss: 1.618105 \t\t Validation loss: 1.502481\n",
            "Training average batch accuracy: 0.621000\n",
            "Validation average batch accuracy: 0.716211\n",
            "Epoch 54: Loss: 1.618773 \t\t Validation loss: 1.500785\n",
            "Training average batch accuracy: 0.635625\n",
            "Validation average batch accuracy: 0.712109\n",
            "Epoch 55: Loss: 1.611119 \t\t Validation loss: 1.495652\n",
            "Training average batch accuracy: 0.631750\n",
            "Validation average batch accuracy: 0.717773\n",
            "Epoch 56: Loss: 1.594148 \t\t Validation loss: 1.499908\n",
            "Training average batch accuracy: 0.639250\n",
            "Validation average batch accuracy: 0.719531\n",
            "Epoch 57: Loss: 1.612971 \t\t Validation loss: 1.500939\n",
            "Training average batch accuracy: 0.643125\n",
            "Validation average batch accuracy: 0.710156\n",
            "Epoch 58: Loss: 1.604851 \t\t Validation loss: 1.499630\n",
            "Training average batch accuracy: 0.641250\n",
            "Validation average batch accuracy: 0.718359\n",
            "Epoch 59: Loss: 1.606586 \t\t Validation loss: 1.501268\n",
            "BEST SCORE: tensor(0.7230, device='cuda:0')\n",
            "Training average batch accuracy: 0.635250\n",
            "Validation average batch accuracy: 0.723047\n",
            "Epoch 60: Loss: 1.597436 \t\t Validation loss: 1.492709\n",
            "Training average batch accuracy: 0.635250\n",
            "Validation average batch accuracy: 0.720508\n",
            "Epoch 61: Loss: 1.599691 \t\t Validation loss: 1.497271\n",
            "Training average batch accuracy: 0.638125\n",
            "Validation average batch accuracy: 0.718945\n",
            "Epoch 62: Loss: 1.589872 \t\t Validation loss: 1.499889\n",
            "BEST SCORE: tensor(0.7264, device='cuda:0')\n",
            "Training average batch accuracy: 0.638375\n",
            "Validation average batch accuracy: 0.726367\n",
            "Epoch 63: Loss: 1.600061 \t\t Validation loss: 1.499790\n",
            "Training average batch accuracy: 0.642375\n",
            "Validation average batch accuracy: 0.721484\n",
            "Epoch 64: Loss: 1.597839 \t\t Validation loss: 1.493309\n",
            "Training average batch accuracy: 0.639375\n",
            "Validation average batch accuracy: 0.717578\n",
            "Epoch 65: Loss: 1.589767 \t\t Validation loss: 1.493118\n",
            "BEST SCORE: tensor(0.7279, device='cuda:0')\n",
            "Training average batch accuracy: 0.651625\n",
            "Validation average batch accuracy: 0.727930\n",
            "Epoch 66: Loss: 1.588742 \t\t Validation loss: 1.494638\n",
            "Training average batch accuracy: 0.646875\n",
            "Validation average batch accuracy: 0.723047\n",
            "Epoch 67: Loss: 1.591800 \t\t Validation loss: 1.498602\n",
            "Training average batch accuracy: 0.646000\n",
            "Validation average batch accuracy: 0.722656\n",
            "Epoch 68: Loss: 1.597625 \t\t Validation loss: 1.499778\n",
            "Training average batch accuracy: 0.646000\n",
            "Validation average batch accuracy: 0.727344\n",
            "Epoch 69: Loss: 1.593206 \t\t Validation loss: 1.495416\n",
            "BEST SCORE: tensor(0.7312, device='cuda:0')\n",
            "Training average batch accuracy: 0.646000\n",
            "Validation average batch accuracy: 0.731250\n",
            "Epoch 70: Loss: 1.575356 \t\t Validation loss: 1.491236\n",
            "Training average batch accuracy: 0.646000\n",
            "Validation average batch accuracy: 0.722461\n",
            "Epoch 71: Loss: 1.591549 \t\t Validation loss: 1.493786\n",
            "Training average batch accuracy: 0.641625\n",
            "Validation average batch accuracy: 0.713086\n",
            "Epoch 72: Loss: 1.581612 \t\t Validation loss: 1.496406\n",
            "Training average batch accuracy: 0.646375\n",
            "Validation average batch accuracy: 0.725195\n",
            "Epoch 73: Loss: 1.573841 \t\t Validation loss: 1.491847\n",
            "Training average batch accuracy: 0.648750\n",
            "Validation average batch accuracy: 0.718945\n",
            "Epoch 74: Loss: 1.590658 \t\t Validation loss: 1.495150\n",
            "Training average batch accuracy: 0.647250\n",
            "Validation average batch accuracy: 0.714063\n",
            "Epoch 75: Loss: 1.572539 \t\t Validation loss: 1.494736\n",
            "Training average batch accuracy: 0.651250\n",
            "Validation average batch accuracy: 0.713672\n",
            "Epoch 76: Loss: 1.565522 \t\t Validation loss: 1.493103\n",
            "Training average batch accuracy: 0.646375\n",
            "Validation average batch accuracy: 0.715625\n",
            "Epoch 77: Loss: 1.581221 \t\t Validation loss: 1.489989\n",
            "Training average batch accuracy: 0.646750\n",
            "Validation average batch accuracy: 0.715625\n",
            "Epoch 78: Loss: 1.571044 \t\t Validation loss: 1.493651\n",
            "Training average batch accuracy: 0.651125\n",
            "Validation average batch accuracy: 0.726367\n",
            "Epoch 79: Loss: 1.567083 \t\t Validation loss: 1.495074\n",
            "Training average batch accuracy: 0.650250\n",
            "Validation average batch accuracy: 0.719531\n",
            "Epoch 80: Loss: 1.577205 \t\t Validation loss: 1.488984\n",
            "Training average batch accuracy: 0.647500\n",
            "Validation average batch accuracy: 0.716602\n",
            "Epoch 81: Loss: 1.566197 \t\t Validation loss: 1.489535\n",
            "Training average batch accuracy: 0.654000\n",
            "Validation average batch accuracy: 0.720508\n",
            "Epoch 82: Loss: 1.575200 \t\t Validation loss: 1.489360\n",
            "Training average batch accuracy: 0.657625\n",
            "Validation average batch accuracy: 0.719531\n",
            "Epoch 83: Loss: 1.556198 \t\t Validation loss: 1.492876\n",
            "Training average batch accuracy: 0.651875\n",
            "Validation average batch accuracy: 0.718555\n",
            "Epoch 84: Loss: 1.557021 \t\t Validation loss: 1.486797\n",
            "Training average batch accuracy: 0.655750\n",
            "Validation average batch accuracy: 0.720508\n",
            "Epoch 85: Loss: 1.558569 \t\t Validation loss: 1.488317\n",
            "Training average batch accuracy: 0.650125\n",
            "Validation average batch accuracy: 0.717578\n",
            "Epoch 86: Loss: 1.571104 \t\t Validation loss: 1.494067\n",
            "Training average batch accuracy: 0.650375\n",
            "Validation average batch accuracy: 0.725000\n",
            "Epoch 87: Loss: 1.550165 \t\t Validation loss: 1.487030\n",
            "Training average batch accuracy: 0.656250\n",
            "Validation average batch accuracy: 0.720117\n",
            "Epoch 88: Loss: 1.549418 \t\t Validation loss: 1.489113\n",
            "Training average batch accuracy: 0.661250\n",
            "Validation average batch accuracy: 0.720117\n",
            "Epoch 89: Loss: 1.560901 \t\t Validation loss: 1.493822\n",
            "Training average batch accuracy: 0.655375\n",
            "Validation average batch accuracy: 0.719141\n",
            "Epoch 90: Loss: 1.549879 \t\t Validation loss: 1.487493\n",
            "Training average batch accuracy: 0.651000\n",
            "Validation average batch accuracy: 0.729883\n",
            "Epoch 91: Loss: 1.550173 \t\t Validation loss: 1.483029\n",
            "Training average batch accuracy: 0.659875\n",
            "Validation average batch accuracy: 0.721484\n",
            "Epoch 92: Loss: 1.545706 \t\t Validation loss: 1.483514\n",
            "Training average batch accuracy: 0.655875\n",
            "Validation average batch accuracy: 0.728711\n",
            "Epoch 93: Loss: 1.538347 \t\t Validation loss: 1.484730\n",
            "Training average batch accuracy: 0.662875\n",
            "Validation average batch accuracy: 0.730469\n",
            "Epoch 94: Loss: 1.548880 \t\t Validation loss: 1.485752\n",
            "Training average batch accuracy: 0.662625\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 95: Loss: 1.553565 \t\t Validation loss: 1.487069\n",
            "Training average batch accuracy: 0.661250\n",
            "Validation average batch accuracy: 0.722461\n",
            "Epoch 96: Loss: 1.551956 \t\t Validation loss: 1.481993\n",
            "Training average batch accuracy: 0.667250\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 97: Loss: 1.548059 \t\t Validation loss: 1.485244\n",
            "Training average batch accuracy: 0.660375\n",
            "Validation average batch accuracy: 0.725391\n",
            "Epoch 98: Loss: 1.547644 \t\t Validation loss: 1.489697\n",
            "Training average batch accuracy: 0.658250\n",
            "Validation average batch accuracy: 0.725586\n",
            "Epoch 99: Loss: 1.539768 \t\t Validation loss: 1.480050\n",
            "Training average batch accuracy: 0.666000\n",
            "Validation average batch accuracy: 0.725000\n",
            "Epoch 100: Loss: 1.532288 \t\t Validation loss: 1.480732\n",
            "Training average batch accuracy: 0.655625\n",
            "Validation average batch accuracy: 0.720117\n",
            "Epoch 101: Loss: 1.541885 \t\t Validation loss: 1.483908\n",
            "Training average batch accuracy: 0.659250\n",
            "Validation average batch accuracy: 0.725000\n",
            "Epoch 102: Loss: 1.538839 \t\t Validation loss: 1.484544\n",
            "Training average batch accuracy: 0.665125\n",
            "Validation average batch accuracy: 0.722070\n",
            "Epoch 103: Loss: 1.529984 \t\t Validation loss: 1.484996\n",
            "Training average batch accuracy: 0.659375\n",
            "Validation average batch accuracy: 0.720117\n",
            "Epoch 104: Loss: 1.525773 \t\t Validation loss: 1.482135\n",
            "Training average batch accuracy: 0.667750\n",
            "Validation average batch accuracy: 0.720117\n",
            "Epoch 105: Loss: 1.537719 \t\t Validation loss: 1.484573\n",
            "Training average batch accuracy: 0.660625\n",
            "Validation average batch accuracy: 0.730859\n",
            "Epoch 106: Loss: 1.525317 \t\t Validation loss: 1.488021\n",
            "Training average batch accuracy: 0.660125\n",
            "Validation average batch accuracy: 0.707422\n",
            "Epoch 107: Loss: 1.539089 \t\t Validation loss: 1.485544\n",
            "Training average batch accuracy: 0.667375\n",
            "Validation average batch accuracy: 0.725391\n",
            "Epoch 108: Loss: 1.516546 \t\t Validation loss: 1.480698\n",
            "Training average batch accuracy: 0.674625\n",
            "Validation average batch accuracy: 0.726172\n",
            "Epoch 109: Loss: 1.529147 \t\t Validation loss: 1.476456\n",
            "Training average batch accuracy: 0.664250\n",
            "Validation average batch accuracy: 0.721680\n",
            "Epoch 110: Loss: 1.524580 \t\t Validation loss: 1.481893\n",
            "Training average batch accuracy: 0.667125\n",
            "Validation average batch accuracy: 0.724414\n",
            "Epoch 111: Loss: 1.534558 \t\t Validation loss: 1.483097\n",
            "Training average batch accuracy: 0.661375\n",
            "Validation average batch accuracy: 0.729492\n",
            "Epoch 112: Loss: 1.536806 \t\t Validation loss: 1.488398\n",
            "Training average batch accuracy: 0.657250\n",
            "Validation average batch accuracy: 0.721289\n",
            "Epoch 113: Loss: 1.530927 \t\t Validation loss: 1.480462\n",
            "Training average batch accuracy: 0.664625\n",
            "Validation average batch accuracy: 0.725195\n",
            "Epoch 114: Loss: 1.514969 \t\t Validation loss: 1.484293\n",
            "BEST SCORE: tensor(0.7314, device='cuda:0')\n",
            "Training average batch accuracy: 0.672125\n",
            "Validation average batch accuracy: 0.731445\n",
            "Epoch 115: Loss: 1.526153 \t\t Validation loss: 1.491989\n",
            "Training average batch accuracy: 0.663500\n",
            "Validation average batch accuracy: 0.725195\n",
            "Epoch 116: Loss: 1.519354 \t\t Validation loss: 1.489315\n",
            "Training average batch accuracy: 0.659500\n",
            "Validation average batch accuracy: 0.730859\n",
            "Epoch 117: Loss: 1.529296 \t\t Validation loss: 1.482059\n",
            "Training average batch accuracy: 0.661750\n",
            "Validation average batch accuracy: 0.716992\n",
            "Epoch 118: Loss: 1.528119 \t\t Validation loss: 1.478667\n",
            "BEST SCORE: tensor(0.7338, device='cuda:0')\n",
            "Training average batch accuracy: 0.660000\n",
            "Validation average batch accuracy: 0.733789\n",
            "Epoch 119: Loss: 1.521385 \t\t Validation loss: 1.480173\n",
            "Training average batch accuracy: 0.665250\n",
            "Validation average batch accuracy: 0.722070\n",
            "Epoch 120: Loss: 1.521550 \t\t Validation loss: 1.478889\n",
            "Training average batch accuracy: 0.664375\n",
            "Epoch   121: reducing learning rate of group 0 to 5.0000e-04.\n",
            "Validation average batch accuracy: 0.725391\n",
            "Epoch 121: Loss: 1.510855 \t\t Validation loss: 1.476276\n",
            "Training average batch accuracy: 0.668250\n",
            "Validation average batch accuracy: 0.726953\n",
            "Epoch 122: Loss: 1.495643 \t\t Validation loss: 1.480751\n",
            "Training average batch accuracy: 0.672375\n",
            "Validation average batch accuracy: 0.719531\n",
            "Epoch 123: Loss: 1.509344 \t\t Validation loss: 1.478847\n",
            "Training average batch accuracy: 0.661375\n",
            "Validation average batch accuracy: 0.725977\n",
            "Epoch 124: Loss: 1.493036 \t\t Validation loss: 1.474957\n",
            "Training average batch accuracy: 0.675125\n",
            "Validation average batch accuracy: 0.728906\n",
            "Epoch 125: Loss: 1.491340 \t\t Validation loss: 1.477303\n",
            "Training average batch accuracy: 0.681375\n",
            "Validation average batch accuracy: 0.724023\n",
            "Epoch 126: Loss: 1.485311 \t\t Validation loss: 1.476604\n",
            "Training average batch accuracy: 0.669375\n",
            "Validation average batch accuracy: 0.729883\n",
            "Epoch 127: Loss: 1.471048 \t\t Validation loss: 1.483256\n",
            "Training average batch accuracy: 0.684875\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 128: Loss: 1.484837 \t\t Validation loss: 1.480298\n",
            "Training average batch accuracy: 0.680125\n",
            "Validation average batch accuracy: 0.722461\n",
            "Epoch 129: Loss: 1.489140 \t\t Validation loss: 1.477587\n",
            "Training average batch accuracy: 0.671500\n",
            "Validation average batch accuracy: 0.725586\n",
            "Epoch 130: Loss: 1.468776 \t\t Validation loss: 1.476868\n",
            "Training average batch accuracy: 0.683250\n",
            "Validation average batch accuracy: 0.722070\n",
            "Epoch 131: Loss: 1.471905 \t\t Validation loss: 1.479251\n",
            "Training average batch accuracy: 0.677000\n",
            "Validation average batch accuracy: 0.718164\n",
            "Epoch 132: Loss: 1.479666 \t\t Validation loss: 1.480641\n",
            "Training average batch accuracy: 0.676125\n",
            "Validation average batch accuracy: 0.723633\n",
            "Epoch 133: Loss: 1.484810 \t\t Validation loss: 1.483243\n",
            "Training average batch accuracy: 0.669875\n",
            "Validation average batch accuracy: 0.724609\n",
            "Epoch 134: Loss: 1.471482 \t\t Validation loss: 1.479667\n",
            "Training average batch accuracy: 0.681500\n",
            "Validation average batch accuracy: 0.733398\n",
            "Epoch 135: Loss: 1.468869 \t\t Validation loss: 1.480992\n",
            "Training average batch accuracy: 0.672625\n",
            "Epoch   136: reducing learning rate of group 0 to 2.5000e-04.\n",
            "Validation average batch accuracy: 0.723633\n",
            "Epoch 136: Loss: 1.460833 \t\t Validation loss: 1.483503\n",
            "Training average batch accuracy: 0.685500\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 137: Loss: 1.458774 \t\t Validation loss: 1.479921\n",
            "Training average batch accuracy: 0.691625\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 138: Loss: 1.449056 \t\t Validation loss: 1.482862\n",
            "Training average batch accuracy: 0.691250\n",
            "Validation average batch accuracy: 0.730469\n",
            "Epoch 139: Loss: 1.464801 \t\t Validation loss: 1.480383\n",
            "Training average batch accuracy: 0.680875\n",
            "Validation average batch accuracy: 0.721680\n",
            "Epoch 140: Loss: 1.463455 \t\t Validation loss: 1.482330\n",
            "Training average batch accuracy: 0.678125\n",
            "Validation average batch accuracy: 0.726562\n",
            "Epoch 141: Loss: 1.450088 \t\t Validation loss: 1.484771\n",
            "Training average batch accuracy: 0.688250\n",
            "Validation average batch accuracy: 0.729492\n",
            "Epoch 142: Loss: 1.456818 \t\t Validation loss: 1.482335\n",
            "Training average batch accuracy: 0.686000\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 143: Loss: 1.434900 \t\t Validation loss: 1.481999\n",
            "Training average batch accuracy: 0.692250\n",
            "Validation average batch accuracy: 0.729492\n",
            "Epoch 144: Loss: 1.448290 \t\t Validation loss: 1.482211\n",
            "Training average batch accuracy: 0.691625\n",
            "Validation average batch accuracy: 0.733398\n",
            "Epoch 145: Loss: 1.434225 \t\t Validation loss: 1.481089\n",
            "Training average batch accuracy: 0.693750\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 146: Loss: 1.439993 \t\t Validation loss: 1.482714\n",
            "Training average batch accuracy: 0.692625\n",
            "Epoch   147: reducing learning rate of group 0 to 1.2500e-04.\n",
            "Validation average batch accuracy: 0.733398\n",
            "Epoch 147: Loss: 1.432967 \t\t Validation loss: 1.478545\n",
            "Training average batch accuracy: 0.700000\n",
            "Validation average batch accuracy: 0.731445\n",
            "Epoch 148: Loss: 1.452045 \t\t Validation loss: 1.481187\n",
            "Training average batch accuracy: 0.683875\n",
            "Validation average batch accuracy: 0.725977\n",
            "Epoch 149: Loss: 1.440925 \t\t Validation loss: 1.484497\n",
            "Training average batch accuracy: 0.685625\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 150: Loss: 1.444697 \t\t Validation loss: 1.480696\n",
            "Training average batch accuracy: 0.693750\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 151: Loss: 1.433276 \t\t Validation loss: 1.484674\n",
            "Training average batch accuracy: 0.693375\n",
            "Validation average batch accuracy: 0.725586\n",
            "Epoch 152: Loss: 1.437239 \t\t Validation loss: 1.480671\n",
            "Training average batch accuracy: 0.693375\n",
            "Validation average batch accuracy: 0.723633\n",
            "Epoch 153: Loss: 1.444684 \t\t Validation loss: 1.479521\n",
            "Training average batch accuracy: 0.697125\n",
            "Validation average batch accuracy: 0.724609\n",
            "Epoch 154: Loss: 1.440855 \t\t Validation loss: 1.479502\n",
            "Training average batch accuracy: 0.695000\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 155: Loss: 1.436173 \t\t Validation loss: 1.484130\n",
            "Training average batch accuracy: 0.692000\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 156: Loss: 1.437139 \t\t Validation loss: 1.483854\n",
            "Training average batch accuracy: 0.694500\n",
            "Validation average batch accuracy: 0.730469\n",
            "Epoch 157: Loss: 1.427404 \t\t Validation loss: 1.483517\n",
            "Training average batch accuracy: 0.694750\n",
            "Epoch   158: reducing learning rate of group 0 to 6.2500e-05.\n",
            "Validation average batch accuracy: 0.731445\n",
            "Epoch 158: Loss: 1.440261 \t\t Validation loss: 1.483399\n",
            "Training average batch accuracy: 0.695625\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 159: Loss: 1.426161 \t\t Validation loss: 1.487510\n",
            "Training average batch accuracy: 0.696375\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 160: Loss: 1.422808 \t\t Validation loss: 1.477998\n",
            "Training average batch accuracy: 0.702250\n",
            "Validation average batch accuracy: 0.726562\n",
            "Epoch 161: Loss: 1.427333 \t\t Validation loss: 1.484333\n",
            "Training average batch accuracy: 0.686750\n",
            "Validation average batch accuracy: 0.733398\n",
            "Epoch 162: Loss: 1.430193 \t\t Validation loss: 1.485784\n",
            "Training average batch accuracy: 0.690625\n",
            "Validation average batch accuracy: 0.725000\n",
            "Epoch 163: Loss: 1.434904 \t\t Validation loss: 1.483599\n",
            "Training average batch accuracy: 0.691875\n",
            "Validation average batch accuracy: 0.730469\n",
            "Epoch 164: Loss: 1.428938 \t\t Validation loss: 1.485025\n",
            "Training average batch accuracy: 0.688875\n",
            "Validation average batch accuracy: 0.723633\n",
            "Epoch 165: Loss: 1.419631 \t\t Validation loss: 1.479795\n",
            "Training average batch accuracy: 0.699625\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 166: Loss: 1.422201 \t\t Validation loss: 1.483316\n",
            "Training average batch accuracy: 0.693625\n",
            "Validation average batch accuracy: 0.725586\n",
            "Epoch 167: Loss: 1.427881 \t\t Validation loss: 1.482431\n",
            "Training average batch accuracy: 0.696875\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 168: Loss: 1.426692 \t\t Validation loss: 1.483118\n",
            "Training average batch accuracy: 0.688625\n",
            "Epoch   169: reducing learning rate of group 0 to 3.1250e-05.\n",
            "Validation average batch accuracy: 0.729492\n",
            "Epoch 169: Loss: 1.419070 \t\t Validation loss: 1.480894\n",
            "Training average batch accuracy: 0.690375\n",
            "Validation average batch accuracy: 0.726562\n",
            "Epoch 170: Loss: 1.430896 \t\t Validation loss: 1.485185\n",
            "Training average batch accuracy: 0.691000\n",
            "Validation average batch accuracy: 0.726562\n",
            "Epoch 171: Loss: 1.422347 \t\t Validation loss: 1.484921\n",
            "Training average batch accuracy: 0.692750\n",
            "Validation average batch accuracy: 0.724609\n",
            "Epoch 172: Loss: 1.436027 \t\t Validation loss: 1.483768\n",
            "Training average batch accuracy: 0.690625\n",
            "Validation average batch accuracy: 0.724609\n",
            "Epoch 173: Loss: 1.427263 \t\t Validation loss: 1.482349\n",
            "Training average batch accuracy: 0.704750\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 174: Loss: 1.423483 \t\t Validation loss: 1.486654\n",
            "Training average batch accuracy: 0.688000\n",
            "Validation average batch accuracy: 0.722656\n",
            "Epoch 175: Loss: 1.403108 \t\t Validation loss: 1.483720\n",
            "Training average batch accuracy: 0.699500\n",
            "Validation average batch accuracy: 0.725586\n",
            "Epoch 176: Loss: 1.418702 \t\t Validation loss: 1.480256\n",
            "Training average batch accuracy: 0.696625\n",
            "Validation average batch accuracy: 0.731445\n",
            "Epoch 177: Loss: 1.419648 \t\t Validation loss: 1.485742\n",
            "Training average batch accuracy: 0.691250\n",
            "Validation average batch accuracy: 0.723633\n",
            "Epoch 178: Loss: 1.426520 \t\t Validation loss: 1.482360\n",
            "Training average batch accuracy: 0.688750\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 179: Loss: 1.409766 \t\t Validation loss: 1.485855\n",
            "Training average batch accuracy: 0.693875\n",
            "Epoch   180: reducing learning rate of group 0 to 1.5625e-05.\n",
            "Validation average batch accuracy: 0.729492\n",
            "Epoch 180: Loss: 1.433671 \t\t Validation loss: 1.483365\n",
            "Training average batch accuracy: 0.687125\n",
            "Validation average batch accuracy: 0.731445\n",
            "Epoch 181: Loss: 1.416404 \t\t Validation loss: 1.485159\n",
            "Training average batch accuracy: 0.689875\n",
            "Validation average batch accuracy: 0.726562\n",
            "Epoch 182: Loss: 1.419486 \t\t Validation loss: 1.480722\n",
            "Training average batch accuracy: 0.699250\n",
            "Validation average batch accuracy: 0.730469\n",
            "Epoch 183: Loss: 1.421618 \t\t Validation loss: 1.486726\n",
            "Training average batch accuracy: 0.697375\n",
            "Validation average batch accuracy: 0.724609\n",
            "Epoch 184: Loss: 1.419317 \t\t Validation loss: 1.484688\n",
            "Training average batch accuracy: 0.696500\n",
            "Validation average batch accuracy: 0.729492\n",
            "Epoch 185: Loss: 1.424826 \t\t Validation loss: 1.485320\n",
            "Training average batch accuracy: 0.689625\n",
            "Validation average batch accuracy: 0.723633\n",
            "Epoch 186: Loss: 1.423425 \t\t Validation loss: 1.485069\n",
            "Training average batch accuracy: 0.697625\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 187: Loss: 1.434715 \t\t Validation loss: 1.479721\n",
            "Training average batch accuracy: 0.685250\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 188: Loss: 1.417666 \t\t Validation loss: 1.486766\n",
            "Training average batch accuracy: 0.696625\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 189: Loss: 1.421685 \t\t Validation loss: 1.482973\n",
            "Training average batch accuracy: 0.704250\n",
            "Validation average batch accuracy: 0.731445\n",
            "Epoch 190: Loss: 1.427253 \t\t Validation loss: 1.485655\n",
            "Training average batch accuracy: 0.690875\n",
            "Epoch   191: reducing learning rate of group 0 to 7.8125e-06.\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 191: Loss: 1.421073 \t\t Validation loss: 1.482485\n",
            "Training average batch accuracy: 0.698750\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 192: Loss: 1.430941 \t\t Validation loss: 1.482310\n",
            "Training average batch accuracy: 0.689750\n",
            "Validation average batch accuracy: 0.723633\n",
            "Epoch 193: Loss: 1.413977 \t\t Validation loss: 1.482712\n",
            "Training average batch accuracy: 0.694500\n",
            "Validation average batch accuracy: 0.731445\n",
            "Epoch 194: Loss: 1.428336 \t\t Validation loss: 1.486663\n",
            "Training average batch accuracy: 0.697125\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 195: Loss: 1.422263 \t\t Validation loss: 1.485221\n",
            "Training average batch accuracy: 0.694500\n",
            "Validation average batch accuracy: 0.729492\n",
            "Epoch 196: Loss: 1.416394 \t\t Validation loss: 1.484551\n",
            "Training average batch accuracy: 0.701750\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 197: Loss: 1.432443 \t\t Validation loss: 1.482235\n",
            "Training average batch accuracy: 0.690750\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 198: Loss: 1.420106 \t\t Validation loss: 1.485889\n",
            "Training average batch accuracy: 0.693875\n",
            "Validation average batch accuracy: 0.730469\n",
            "Epoch 199: Loss: 1.417015 \t\t Validation loss: 1.487217\n",
            "Training average batch accuracy: 0.696625\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 200: Loss: 1.416321 \t\t Validation loss: 1.480168\n",
            "Training average batch accuracy: 0.699625\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 201: Loss: 1.418189 \t\t Validation loss: 1.480507\n",
            "Training average batch accuracy: 0.699875\n",
            "Epoch   202: reducing learning rate of group 0 to 3.9063e-06.\n",
            "Validation average batch accuracy: 0.726562\n",
            "Epoch 202: Loss: 1.421941 \t\t Validation loss: 1.487588\n",
            "Training average batch accuracy: 0.694125\n",
            "Validation average batch accuracy: 0.720117\n",
            "Epoch 203: Loss: 1.426222 \t\t Validation loss: 1.482103\n",
            "Training average batch accuracy: 0.687500\n",
            "Validation average batch accuracy: 0.723633\n",
            "Epoch 204: Loss: 1.412815 \t\t Validation loss: 1.484034\n",
            "Training average batch accuracy: 0.695875\n",
            "Validation average batch accuracy: 0.726562\n",
            "Epoch 205: Loss: 1.418994 \t\t Validation loss: 1.485834\n",
            "Training average batch accuracy: 0.701875\n",
            "Validation average batch accuracy: 0.729492\n",
            "Epoch 206: Loss: 1.432609 \t\t Validation loss: 1.479897\n",
            "Training average batch accuracy: 0.693000\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 207: Loss: 1.412330 \t\t Validation loss: 1.485543\n",
            "Training average batch accuracy: 0.703750\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 208: Loss: 1.428035 \t\t Validation loss: 1.489909\n",
            "Training average batch accuracy: 0.688500\n",
            "Validation average batch accuracy: 0.730469\n",
            "Epoch 209: Loss: 1.424833 \t\t Validation loss: 1.484411\n",
            "Training average batch accuracy: 0.688875\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 210: Loss: 1.411260 \t\t Validation loss: 1.483825\n",
            "Training average batch accuracy: 0.698125\n",
            "Validation average batch accuracy: 0.733398\n",
            "Epoch 211: Loss: 1.416709 \t\t Validation loss: 1.482567\n",
            "Training average batch accuracy: 0.693125\n",
            "Validation average batch accuracy: 0.732422\n",
            "Epoch 212: Loss: 1.415031 \t\t Validation loss: 1.480465\n",
            "Training average batch accuracy: 0.688000\n",
            "Epoch   213: reducing learning rate of group 0 to 1.9531e-06.\n",
            "Validation average batch accuracy: 0.730469\n",
            "Epoch 213: Loss: 1.422292 \t\t Validation loss: 1.482373\n",
            "Training average batch accuracy: 0.689250\n",
            "Validation average batch accuracy: 0.729492\n",
            "Epoch 214: Loss: 1.423150 \t\t Validation loss: 1.481758\n",
            "Training average batch accuracy: 0.693000\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 215: Loss: 1.415418 \t\t Validation loss: 1.482682\n",
            "Training average batch accuracy: 0.697000\n",
            "Validation average batch accuracy: 0.725586\n",
            "Epoch 216: Loss: 1.414591 \t\t Validation loss: 1.489501\n",
            "Training average batch accuracy: 0.697750\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 217: Loss: 1.425210 \t\t Validation loss: 1.485456\n",
            "Training average batch accuracy: 0.691750\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 218: Loss: 1.415726 \t\t Validation loss: 1.481751\n",
            "Training average batch accuracy: 0.703375\n",
            "Validation average batch accuracy: 0.724609\n",
            "Epoch 219: Loss: 1.427450 \t\t Validation loss: 1.486516\n",
            "Training average batch accuracy: 0.689875\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 220: Loss: 1.420556 \t\t Validation loss: 1.483051\n",
            "Training average batch accuracy: 0.698500\n",
            "Validation average batch accuracy: 0.725586\n",
            "Epoch 221: Loss: 1.418190 \t\t Validation loss: 1.488465\n",
            "Training average batch accuracy: 0.696250\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 222: Loss: 1.407215 \t\t Validation loss: 1.484839\n",
            "Training average batch accuracy: 0.700625\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 223: Loss: 1.415184 \t\t Validation loss: 1.483512\n",
            "Training average batch accuracy: 0.699875\n",
            "Epoch   224: reducing learning rate of group 0 to 9.7656e-07.\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 224: Loss: 1.428182 \t\t Validation loss: 1.486778\n",
            "Training average batch accuracy: 0.698000\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 225: Loss: 1.421836 \t\t Validation loss: 1.481949\n",
            "Training average batch accuracy: 0.699625\n",
            "Validation average batch accuracy: 0.725586\n",
            "Epoch 226: Loss: 1.416737 \t\t Validation loss: 1.485502\n",
            "Training average batch accuracy: 0.704375\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 227: Loss: 1.414017 \t\t Validation loss: 1.482817\n",
            "Training average batch accuracy: 0.692750\n",
            "Validation average batch accuracy: 0.724609\n",
            "Epoch 228: Loss: 1.415219 \t\t Validation loss: 1.479371\n",
            "Training average batch accuracy: 0.690875\n",
            "Validation average batch accuracy: 0.729492\n",
            "Epoch 229: Loss: 1.424491 \t\t Validation loss: 1.483205\n",
            "Training average batch accuracy: 0.695125\n",
            "Validation average batch accuracy: 0.730469\n",
            "Epoch 230: Loss: 1.426373 \t\t Validation loss: 1.482068\n",
            "Training average batch accuracy: 0.696875\n",
            "Validation average batch accuracy: 0.732422\n",
            "Epoch 231: Loss: 1.413034 \t\t Validation loss: 1.485025\n",
            "Training average batch accuracy: 0.703375\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 232: Loss: 1.432588 \t\t Validation loss: 1.481402\n",
            "Training average batch accuracy: 0.692250\n",
            "Validation average batch accuracy: 0.719141\n",
            "Epoch 233: Loss: 1.421970 \t\t Validation loss: 1.483856\n",
            "Training average batch accuracy: 0.702375\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 234: Loss: 1.407654 \t\t Validation loss: 1.483962\n",
            "Training average batch accuracy: 0.695000\n",
            "Epoch   235: reducing learning rate of group 0 to 4.8828e-07.\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 235: Loss: 1.412056 \t\t Validation loss: 1.482903\n",
            "Training average batch accuracy: 0.701500\n",
            "Validation average batch accuracy: 0.731445\n",
            "Epoch 236: Loss: 1.416636 \t\t Validation loss: 1.482524\n",
            "Training average batch accuracy: 0.694750\n",
            "Validation average batch accuracy: 0.726562\n",
            "Epoch 237: Loss: 1.420863 \t\t Validation loss: 1.481351\n",
            "Training average batch accuracy: 0.696250\n",
            "Validation average batch accuracy: 0.730469\n",
            "Epoch 238: Loss: 1.428800 \t\t Validation loss: 1.486354\n",
            "Training average batch accuracy: 0.692625\n",
            "Validation average batch accuracy: 0.719727\n",
            "Epoch 239: Loss: 1.424937 \t\t Validation loss: 1.483281\n",
            "Training average batch accuracy: 0.694875\n",
            "Validation average batch accuracy: 0.732422\n",
            "Epoch 240: Loss: 1.422030 \t\t Validation loss: 1.482222\n",
            "Training average batch accuracy: 0.697125\n",
            "Validation average batch accuracy: 0.724609\n",
            "Epoch 241: Loss: 1.426337 \t\t Validation loss: 1.484785\n",
            "Training average batch accuracy: 0.686125\n",
            "Validation average batch accuracy: 0.726562\n",
            "Epoch 242: Loss: 1.419332 \t\t Validation loss: 1.483002\n",
            "Training average batch accuracy: 0.692875\n",
            "Validation average batch accuracy: 0.725586\n",
            "Epoch 243: Loss: 1.425734 \t\t Validation loss: 1.479662\n",
            "Training average batch accuracy: 0.695125\n",
            "Validation average batch accuracy: 0.722656\n",
            "Epoch 244: Loss: 1.410241 \t\t Validation loss: 1.478541\n",
            "Training average batch accuracy: 0.704875\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 245: Loss: 1.420369 \t\t Validation loss: 1.482759\n",
            "Training average batch accuracy: 0.700000\n",
            "Epoch   246: reducing learning rate of group 0 to 2.4414e-07.\n",
            "Validation average batch accuracy: 0.732422\n",
            "Epoch 246: Loss: 1.417711 \t\t Validation loss: 1.483326\n",
            "BEST SCORE: tensor(0.7354, device='cuda:0')\n",
            "Training average batch accuracy: 0.691750\n",
            "Validation average batch accuracy: 0.735352\n",
            "Epoch 247: Loss: 1.417427 \t\t Validation loss: 1.483474\n",
            "Training average batch accuracy: 0.706750\n",
            "Validation average batch accuracy: 0.732422\n",
            "Epoch 248: Loss: 1.411403 \t\t Validation loss: 1.482342\n",
            "Training average batch accuracy: 0.697750\n",
            "Validation average batch accuracy: 0.731445\n",
            "Epoch 249: Loss: 1.414979 \t\t Validation loss: 1.483566\n",
            "Training average batch accuracy: 0.692125\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 250: Loss: 1.417537 \t\t Validation loss: 1.484849\n",
            "Training average batch accuracy: 0.694000\n",
            "Validation average batch accuracy: 0.726562\n",
            "Epoch 251: Loss: 1.425687 \t\t Validation loss: 1.479367\n",
            "Training average batch accuracy: 0.693875\n",
            "Validation average batch accuracy: 0.724609\n",
            "Epoch 252: Loss: 1.427197 \t\t Validation loss: 1.479197\n",
            "Training average batch accuracy: 0.693875\n",
            "Validation average batch accuracy: 0.727539\n",
            "Epoch 253: Loss: 1.407045 \t\t Validation loss: 1.485903\n",
            "Training average batch accuracy: 0.696375\n",
            "Validation average batch accuracy: 0.725586\n",
            "Epoch 254: Loss: 1.422688 \t\t Validation loss: 1.488399\n",
            "Training average batch accuracy: 0.691875\n",
            "Validation average batch accuracy: 0.729492\n",
            "Epoch 255: Loss: 1.418464 \t\t Validation loss: 1.485695\n",
            "Training average batch accuracy: 0.687500\n",
            "Validation average batch accuracy: 0.722656\n",
            "Epoch 256: Loss: 1.408173 \t\t Validation loss: 1.479854\n",
            "Training average batch accuracy: 0.696625\n",
            "Epoch   257: reducing learning rate of group 0 to 1.2207e-07.\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 257: Loss: 1.411330 \t\t Validation loss: 1.482465\n",
            "Training average batch accuracy: 0.696750\n",
            "Validation average batch accuracy: 0.724609\n",
            "Epoch 258: Loss: 1.416725 \t\t Validation loss: 1.481382\n",
            "Training average batch accuracy: 0.695000\n",
            "Validation average batch accuracy: 0.728516\n",
            "Epoch 259: Loss: 1.413764 \t\t Validation loss: 1.483808\n",
            "Training average batch accuracy: 0.692625\n",
            "Validation average batch accuracy: 0.729492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVvTKz3mpuub",
        "outputId": "01e5626e-5239-42fa-9ce1-7918d6ae59de"
      },
      "source": [
        "best_model['best_score']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7354, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um1ryPoapuub"
      },
      "source": [
        "#torch.save({\n",
        "            'epoch': 178,\n",
        "            'model_state_dict': best_model['state_dict'],\n",
        "            'optimizer_state_dict': optim_context.state_dict()\n",
        "}, \"/content/drive/MyDrive/Sapienza/WiC_multi_learn.pth\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "gyr6L5VGpvxx",
        "outputId": "e69b79d0-7943-4c94-d1d5-b0865c9f0e02"
      },
      "source": [
        "plot_hist(hist, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WGFSLBWFVoj"
      },
      "source": [
        "### Extra POS tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_7zoKVp6EU0",
        "outputId": "04316de7-8568-4363-ee63-d5ba8c6837ac"
      },
      "source": [
        "model_context.eval()\n",
        "model_no_attn = NoAttention(HypParams(), vectors, model_context, \n",
        "                            predict_pos=False).to('cuda')\n",
        "\n",
        "optim_no_attn = torch.optim.Adam(\n",
        "    model_no_attn.parameters(),\n",
        "    #lr=0.0001\n",
        "    #weight_decay=0.001\n",
        "    )\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim_context, factor=0.5, verbose=True)\n",
        "#scheduler=None\n",
        "best_model = {}\n",
        "hist = {}\n",
        "\n",
        "_ = train(train_loader, valid_loader, \n",
        "      model_no_attn, optim_no_attn, \n",
        "      train_step_3, \n",
        "      eval_step_3,\n",
        "      260,\n",
        "      scheduler=scheduler, \n",
        "      #best_model_mode='accuracy', \n",
        "      best_model=best_model, hist=hist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss: 0.894446 \t\t Validation loss: 0.674677\n",
            "BEST SCORE: 0.6746766678988934\n",
            "Training average batch accuracy: 0.511875\n",
            "Validation average batch accuracy: 0.573438\n",
            "Epoch 1: Loss: 0.772231 \t\t Validation loss: 0.672352\n",
            "BEST SCORE: 0.6723519451916218\n",
            "Training average batch accuracy: 0.519625\n",
            "Validation average batch accuracy: 0.584766\n",
            "Epoch 2: Loss: 0.740102 \t\t Validation loss: 0.677832\n",
            "Training average batch accuracy: 0.527500\n",
            "Validation average batch accuracy: 0.570312\n",
            "Epoch 3: Loss: 0.735435 \t\t Validation loss: 0.659213\n",
            "BEST SCORE: 0.6592127941548824\n",
            "Training average batch accuracy: 0.533000\n",
            "Validation average batch accuracy: 0.632812\n",
            "Epoch 4: Loss: 0.735303 \t\t Validation loss: 0.656390\n",
            "BEST SCORE: 0.6563903763890266\n",
            "Training average batch accuracy: 0.530250\n",
            "Validation average batch accuracy: 0.644922\n",
            "Epoch 5: Loss: 0.728069 \t\t Validation loss: 0.662533\n",
            "Training average batch accuracy: 0.544250\n",
            "Validation average batch accuracy: 0.608594\n",
            "Epoch 6: Loss: 0.727593 \t\t Validation loss: 0.654638\n",
            "BEST SCORE: 0.6546384878456593\n",
            "Training average batch accuracy: 0.543875\n",
            "Validation average batch accuracy: 0.635547\n",
            "Epoch 7: Loss: 0.726233 \t\t Validation loss: 0.656257\n",
            "Training average batch accuracy: 0.537750\n",
            "Validation average batch accuracy: 0.628516\n",
            "Epoch 8: Loss: 0.721570 \t\t Validation loss: 0.647818\n",
            "BEST SCORE: 0.6478178463876247\n",
            "Training average batch accuracy: 0.550500\n",
            "Validation average batch accuracy: 0.655664\n",
            "Epoch 9: Loss: 0.724621 \t\t Validation loss: 0.650735\n",
            "Training average batch accuracy: 0.549375\n",
            "Validation average batch accuracy: 0.626562\n",
            "Epoch 10: Loss: 0.725882 \t\t Validation loss: 0.649873\n",
            "Training average batch accuracy: 0.539000\n",
            "Validation average batch accuracy: 0.640625\n",
            "Epoch 11: Loss: 0.719669 \t\t Validation loss: 0.643472\n",
            "BEST SCORE: 0.6434718109667301\n",
            "Training average batch accuracy: 0.546125\n",
            "Validation average batch accuracy: 0.656445\n",
            "Epoch 12: Loss: 0.717211 \t\t Validation loss: 0.652918\n",
            "Training average batch accuracy: 0.543875\n",
            "Validation average batch accuracy: 0.598242\n",
            "Epoch 13: Loss: 0.711446 \t\t Validation loss: 0.643332\n",
            "BEST SCORE: 0.6433319076895714\n",
            "Training average batch accuracy: 0.552875\n",
            "Validation average batch accuracy: 0.621680\n",
            "Epoch 14: Loss: 0.711337 \t\t Validation loss: 0.637433\n",
            "BEST SCORE: 0.6374325081706047\n",
            "Training average batch accuracy: 0.562250\n",
            "Validation average batch accuracy: 0.653906\n",
            "Epoch 15: Loss: 0.711881 \t\t Validation loss: 0.636239\n",
            "BEST SCORE: 0.6362392790615559\n",
            "Training average batch accuracy: 0.557375\n",
            "Validation average batch accuracy: 0.650000\n",
            "Epoch 16: Loss: 0.698066 \t\t Validation loss: 0.635451\n",
            "BEST SCORE: 0.6354511454701424\n",
            "Training average batch accuracy: 0.570875\n",
            "Validation average batch accuracy: 0.636328\n",
            "Epoch 17: Loss: 0.700745 \t\t Validation loss: 0.628026\n",
            "BEST SCORE: 0.62802554666996\n",
            "Training average batch accuracy: 0.570125\n",
            "Validation average batch accuracy: 0.666992\n",
            "Epoch 18: Loss: 0.700819 \t\t Validation loss: 0.629232\n",
            "Training average batch accuracy: 0.568125\n",
            "Validation average batch accuracy: 0.650000\n",
            "Epoch 19: Loss: 0.694231 \t\t Validation loss: 0.635428\n",
            "Training average batch accuracy: 0.581125\n",
            "Validation average batch accuracy: 0.616797\n",
            "Epoch 20: Loss: 0.702050 \t\t Validation loss: 0.632215\n",
            "Training average batch accuracy: 0.571875\n",
            "Validation average batch accuracy: 0.658398\n",
            "Epoch 21: Loss: 0.688946 \t\t Validation loss: 0.628938\n",
            "Training average batch accuracy: 0.581750\n",
            "Validation average batch accuracy: 0.648047\n",
            "Epoch 22: Loss: 0.689727 \t\t Validation loss: 0.623629\n",
            "BEST SCORE: 0.6236287727952003\n",
            "Training average batch accuracy: 0.583750\n",
            "Validation average batch accuracy: 0.659766\n",
            "Epoch 23: Loss: 0.690194 \t\t Validation loss: 0.621937\n",
            "BEST SCORE: 0.6219368875026703\n",
            "Training average batch accuracy: 0.581500\n",
            "Validation average batch accuracy: 0.669336\n",
            "Epoch 24: Loss: 0.684749 \t\t Validation loss: 0.622162\n",
            "Training average batch accuracy: 0.591750\n",
            "Validation average batch accuracy: 0.651758\n",
            "Epoch 25: Loss: 0.683276 \t\t Validation loss: 0.622937\n",
            "Training average batch accuracy: 0.592125\n",
            "Validation average batch accuracy: 0.651172\n",
            "Epoch 26: Loss: 0.684953 \t\t Validation loss: 0.620536\n",
            "BEST SCORE: 0.620536308735609\n",
            "Training average batch accuracy: 0.586250\n",
            "Validation average batch accuracy: 0.663672\n",
            "Epoch 27: Loss: 0.687268 \t\t Validation loss: 0.621250\n",
            "Training average batch accuracy: 0.585125\n",
            "Validation average batch accuracy: 0.650781\n",
            "Epoch 28: Loss: 0.687274 \t\t Validation loss: 0.624060\n",
            "Training average batch accuracy: 0.585375\n",
            "Validation average batch accuracy: 0.651563\n",
            "Epoch 29: Loss: 0.678746 \t\t Validation loss: 0.621743\n",
            "Training average batch accuracy: 0.593500\n",
            "Validation average batch accuracy: 0.663672\n",
            "Epoch 30: Loss: 0.678593 \t\t Validation loss: 0.618849\n",
            "BEST SCORE: 0.6188486218452454\n",
            "Training average batch accuracy: 0.590250\n",
            "Validation average batch accuracy: 0.658789\n",
            "Epoch 31: Loss: 0.680265 \t\t Validation loss: 0.615155\n",
            "BEST SCORE: 0.6151552796363831\n",
            "Training average batch accuracy: 0.595375\n",
            "Validation average batch accuracy: 0.656445\n",
            "Epoch 32: Loss: 0.674865 \t\t Validation loss: 0.613531\n",
            "BEST SCORE: 0.6135309264063835\n",
            "Training average batch accuracy: 0.597375\n",
            "Validation average batch accuracy: 0.665625\n",
            "Epoch 33: Loss: 0.674760 \t\t Validation loss: 0.611803\n",
            "BEST SCORE: 0.6118031889200211\n",
            "Training average batch accuracy: 0.596875\n",
            "Validation average batch accuracy: 0.665625\n",
            "Epoch 34: Loss: 0.677363 \t\t Validation loss: 0.613630\n",
            "Training average batch accuracy: 0.598125\n",
            "Validation average batch accuracy: 0.657617\n",
            "Epoch 35: Loss: 0.676397 \t\t Validation loss: 0.614013\n",
            "Training average batch accuracy: 0.598500\n",
            "Validation average batch accuracy: 0.664648\n",
            "Epoch 36: Loss: 0.672292 \t\t Validation loss: 0.609557\n",
            "BEST SCORE: 0.6095570735633373\n",
            "Training average batch accuracy: 0.590500\n",
            "Validation average batch accuracy: 0.666016\n",
            "Epoch 37: Loss: 0.670077 \t\t Validation loss: 0.611006\n",
            "Training average batch accuracy: 0.597875\n",
            "Validation average batch accuracy: 0.658594\n",
            "Epoch 38: Loss: 0.667567 \t\t Validation loss: 0.614781\n",
            "Training average batch accuracy: 0.601250\n",
            "Validation average batch accuracy: 0.669727\n",
            "Epoch 39: Loss: 0.667487 \t\t Validation loss: 0.607944\n",
            "BEST SCORE: 0.6079437248408794\n",
            "Training average batch accuracy: 0.599875\n",
            "Validation average batch accuracy: 0.671484\n",
            "Epoch 40: Loss: 0.661363 \t\t Validation loss: 0.610082\n",
            "Training average batch accuracy: 0.608250\n",
            "Validation average batch accuracy: 0.662500\n",
            "Epoch 41: Loss: 0.661827 \t\t Validation loss: 0.607317\n",
            "BEST SCORE: 0.6073173731565475\n",
            "Training average batch accuracy: 0.611375\n",
            "Validation average batch accuracy: 0.669531\n",
            "Epoch 42: Loss: 0.666099 \t\t Validation loss: 0.613826\n",
            "Training average batch accuracy: 0.613375\n",
            "Validation average batch accuracy: 0.650781\n",
            "Epoch 43: Loss: 0.664398 \t\t Validation loss: 0.606125\n",
            "BEST SCORE: 0.6061253324151039\n",
            "Training average batch accuracy: 0.602250\n",
            "Validation average batch accuracy: 0.666602\n",
            "Epoch 44: Loss: 0.667309 \t\t Validation loss: 0.607723\n",
            "Training average batch accuracy: 0.601125\n",
            "Validation average batch accuracy: 0.661719\n",
            "Epoch 45: Loss: 0.659842 \t\t Validation loss: 0.611125\n",
            "Training average batch accuracy: 0.614000\n",
            "Validation average batch accuracy: 0.656836\n",
            "Epoch 46: Loss: 0.658596 \t\t Validation loss: 0.605791\n",
            "BEST SCORE: 0.6057907156646252\n",
            "Training average batch accuracy: 0.606000\n",
            "Validation average batch accuracy: 0.670117\n",
            "Epoch 47: Loss: 0.653721 \t\t Validation loss: 0.607300\n",
            "Training average batch accuracy: 0.617000\n",
            "Validation average batch accuracy: 0.656641\n",
            "Epoch 48: Loss: 0.651292 \t\t Validation loss: 0.601303\n",
            "BEST SCORE: 0.6013033911585808\n",
            "Training average batch accuracy: 0.621500\n",
            "Validation average batch accuracy: 0.673437\n",
            "Epoch 49: Loss: 0.656576 \t\t Validation loss: 0.601007\n",
            "BEST SCORE: 0.6010073646903038\n",
            "Training average batch accuracy: 0.613875\n",
            "Validation average batch accuracy: 0.672656\n",
            "Epoch 50: Loss: 0.654044 \t\t Validation loss: 0.606464\n",
            "Training average batch accuracy: 0.622250\n",
            "Validation average batch accuracy: 0.663672\n",
            "Epoch 51: Loss: 0.657355 \t\t Validation loss: 0.604259\n",
            "Training average batch accuracy: 0.618375\n",
            "Validation average batch accuracy: 0.676367\n",
            "Epoch 52: Loss: 0.644746 \t\t Validation loss: 0.601962\n",
            "Training average batch accuracy: 0.629250\n",
            "Validation average batch accuracy: 0.682422\n",
            "Epoch 53: Loss: 0.648702 \t\t Validation loss: 0.599595\n",
            "BEST SCORE: 0.5995953269302845\n",
            "Training average batch accuracy: 0.624625\n",
            "Validation average batch accuracy: 0.668555\n",
            "Epoch 54: Loss: 0.649768 \t\t Validation loss: 0.599093\n",
            "BEST SCORE: 0.5990934632718563\n",
            "Training average batch accuracy: 0.624625\n",
            "Validation average batch accuracy: 0.669141\n",
            "Epoch 55: Loss: 0.646586 \t\t Validation loss: 0.596338\n",
            "BEST SCORE: 0.59633843973279\n",
            "Training average batch accuracy: 0.624625\n",
            "Validation average batch accuracy: 0.683789\n",
            "Epoch 56: Loss: 0.647346 \t\t Validation loss: 0.600164\n",
            "Training average batch accuracy: 0.625500\n",
            "Validation average batch accuracy: 0.667383\n",
            "Epoch 57: Loss: 0.648668 \t\t Validation loss: 0.597057\n",
            "Training average batch accuracy: 0.628500\n",
            "Validation average batch accuracy: 0.675195\n",
            "Epoch 58: Loss: 0.642918 \t\t Validation loss: 0.596187\n",
            "BEST SCORE: 0.5961866192519665\n",
            "Training average batch accuracy: 0.628500\n",
            "Validation average batch accuracy: 0.677539\n",
            "Epoch 59: Loss: 0.640823 \t\t Validation loss: 0.596427\n",
            "Training average batch accuracy: 0.629000\n",
            "Validation average batch accuracy: 0.669727\n",
            "Epoch 60: Loss: 0.649299 \t\t Validation loss: 0.598909\n",
            "Training average batch accuracy: 0.626375\n",
            "Validation average batch accuracy: 0.670313\n",
            "Epoch 61: Loss: 0.651514 \t\t Validation loss: 0.599411\n",
            "Training average batch accuracy: 0.623000\n",
            "Validation average batch accuracy: 0.659375\n",
            "Epoch 62: Loss: 0.644345 \t\t Validation loss: 0.596437\n",
            "Training average batch accuracy: 0.629125\n",
            "Validation average batch accuracy: 0.672656\n",
            "Epoch 63: Loss: 0.637944 \t\t Validation loss: 0.593185\n",
            "BEST SCORE: 0.5931850112974644\n",
            "Training average batch accuracy: 0.633875\n",
            "Validation average batch accuracy: 0.683594\n",
            "Epoch 64: Loss: 0.634941 \t\t Validation loss: 0.593906\n",
            "Training average batch accuracy: 0.635750\n",
            "Validation average batch accuracy: 0.674805\n",
            "Epoch 65: Loss: 0.636708 \t\t Validation loss: 0.594302\n",
            "Training average batch accuracy: 0.639750\n",
            "Validation average batch accuracy: 0.678125\n",
            "Epoch 66: Loss: 0.632755 \t\t Validation loss: 0.592178\n",
            "BEST SCORE: 0.5921783931553364\n",
            "Training average batch accuracy: 0.634125\n",
            "Validation average batch accuracy: 0.683984\n",
            "Epoch 67: Loss: 0.632039 \t\t Validation loss: 0.593349\n",
            "Training average batch accuracy: 0.638375\n",
            "Validation average batch accuracy: 0.677930\n",
            "Epoch 68: Loss: 0.635938 \t\t Validation loss: 0.591910\n",
            "BEST SCORE: 0.5919103771448135\n",
            "Training average batch accuracy: 0.635000\n",
            "Validation average batch accuracy: 0.671680\n",
            "Epoch 69: Loss: 0.630891 \t\t Validation loss: 0.594611\n",
            "Training average batch accuracy: 0.640250\n",
            "Validation average batch accuracy: 0.667188\n",
            "Epoch 70: Loss: 0.640177 \t\t Validation loss: 0.593899\n",
            "Training average batch accuracy: 0.630625\n",
            "Validation average batch accuracy: 0.673633\n",
            "Epoch 71: Loss: 0.633012 \t\t Validation loss: 0.593377\n",
            "Training average batch accuracy: 0.638875\n",
            "Validation average batch accuracy: 0.673633\n",
            "Epoch 72: Loss: 0.639917 \t\t Validation loss: 0.593056\n",
            "Training average batch accuracy: 0.630875\n",
            "Validation average batch accuracy: 0.675586\n",
            "Epoch 73: Loss: 0.636634 \t\t Validation loss: 0.591923\n",
            "Training average batch accuracy: 0.635875\n",
            "Validation average batch accuracy: 0.679102\n",
            "Epoch 74: Loss: 0.636965 \t\t Validation loss: 0.592458\n",
            "Training average batch accuracy: 0.635500\n",
            "Validation average batch accuracy: 0.676172\n",
            "Epoch 75: Loss: 0.636414 \t\t Validation loss: 0.592191\n",
            "Training average batch accuracy: 0.640000\n",
            "Validation average batch accuracy: 0.675000\n",
            "Epoch 76: Loss: 0.626615 \t\t Validation loss: 0.590494\n",
            "BEST SCORE: 0.5904936790466309\n",
            "Training average batch accuracy: 0.647375\n",
            "Validation average batch accuracy: 0.675977\n",
            "Epoch 77: Loss: 0.630667 \t\t Validation loss: 0.591742\n",
            "Training average batch accuracy: 0.638625\n",
            "Validation average batch accuracy: 0.669141\n",
            "Epoch 78: Loss: 0.628323 \t\t Validation loss: 0.590931\n",
            "Training average batch accuracy: 0.645500\n",
            "Validation average batch accuracy: 0.672070\n",
            "Epoch 79: Loss: 0.623858 \t\t Validation loss: 0.587911\n",
            "BEST SCORE: 0.5879112221300602\n",
            "Training average batch accuracy: 0.640125\n",
            "Validation average batch accuracy: 0.677930\n",
            "Epoch 80: Loss: 0.633169 \t\t Validation loss: 0.588593\n",
            "Training average batch accuracy: 0.640250\n",
            "Validation average batch accuracy: 0.678125\n",
            "Epoch 81: Loss: 0.628355 \t\t Validation loss: 0.587996\n",
            "Training average batch accuracy: 0.643625\n",
            "Validation average batch accuracy: 0.670117\n",
            "Epoch 82: Loss: 0.627530 \t\t Validation loss: 0.588425\n",
            "Training average batch accuracy: 0.649250\n",
            "Validation average batch accuracy: 0.674609\n",
            "Epoch 83: Loss: 0.628214 \t\t Validation loss: 0.588099\n",
            "Training average batch accuracy: 0.644875\n",
            "Validation average batch accuracy: 0.679688\n",
            "Epoch 84: Loss: 0.627470 \t\t Validation loss: 0.588870\n",
            "Training average batch accuracy: 0.649250\n",
            "Validation average batch accuracy: 0.675195\n",
            "Epoch 85: Loss: 0.627609 \t\t Validation loss: 0.587464\n",
            "BEST SCORE: 0.5874641202390194\n",
            "Training average batch accuracy: 0.646375\n",
            "Validation average batch accuracy: 0.685547\n",
            "Epoch 86: Loss: 0.621365 \t\t Validation loss: 0.587125\n",
            "BEST SCORE: 0.5871250778436661\n",
            "Training average batch accuracy: 0.652625\n",
            "Validation average batch accuracy: 0.679297\n",
            "Epoch 87: Loss: 0.624864 \t\t Validation loss: 0.588321\n",
            "Training average batch accuracy: 0.655125\n",
            "Validation average batch accuracy: 0.676367\n",
            "Epoch 88: Loss: 0.621400 \t\t Validation loss: 0.587900\n",
            "Training average batch accuracy: 0.653000\n",
            "Validation average batch accuracy: 0.673828\n",
            "Epoch 89: Loss: 0.625443 \t\t Validation loss: 0.588217\n",
            "Training average batch accuracy: 0.654375\n",
            "Validation average batch accuracy: 0.683594\n",
            "Epoch 90: Loss: 0.617191 \t\t Validation loss: 0.585323\n",
            "BEST SCORE: 0.5853231549263\n",
            "Training average batch accuracy: 0.649250\n",
            "Validation average batch accuracy: 0.687305\n",
            "Epoch 91: Loss: 0.616339 \t\t Validation loss: 0.587637\n",
            "Training average batch accuracy: 0.657875\n",
            "Validation average batch accuracy: 0.679492\n",
            "Epoch 92: Loss: 0.629268 \t\t Validation loss: 0.586013\n",
            "Training average batch accuracy: 0.647375\n",
            "Validation average batch accuracy: 0.681641\n",
            "Epoch 93: Loss: 0.621089 \t\t Validation loss: 0.585587\n",
            "Training average batch accuracy: 0.653000\n",
            "Validation average batch accuracy: 0.701172\n",
            "Epoch 94: Loss: 0.625221 \t\t Validation loss: 0.584488\n",
            "BEST SCORE: 0.5844876952469349\n",
            "Training average batch accuracy: 0.646750\n",
            "Validation average batch accuracy: 0.680469\n",
            "Epoch 95: Loss: 0.624433 \t\t Validation loss: 0.585626\n",
            "Training average batch accuracy: 0.655500\n",
            "Validation average batch accuracy: 0.690234\n",
            "Epoch 96: Loss: 0.613335 \t\t Validation loss: 0.587747\n",
            "Training average batch accuracy: 0.665375\n",
            "Validation average batch accuracy: 0.692773\n",
            "Epoch 97: Loss: 0.621127 \t\t Validation loss: 0.587590\n",
            "Training average batch accuracy: 0.643875\n",
            "Validation average batch accuracy: 0.677539\n",
            "Epoch 98: Loss: 0.614122 \t\t Validation loss: 0.586258\n",
            "Training average batch accuracy: 0.662875\n",
            "Validation average batch accuracy: 0.677344\n",
            "Epoch 99: Loss: 0.617094 \t\t Validation loss: 0.585072\n",
            "Training average batch accuracy: 0.655000\n",
            "Validation average batch accuracy: 0.676172\n",
            "Epoch 100: Loss: 0.614761 \t\t Validation loss: 0.582757\n",
            "BEST SCORE: 0.5827569477260113\n",
            "Training average batch accuracy: 0.658000\n",
            "Validation average batch accuracy: 0.677539\n",
            "Epoch 101: Loss: 0.621962 \t\t Validation loss: 0.583404\n",
            "Training average batch accuracy: 0.654125\n",
            "Validation average batch accuracy: 0.684766\n",
            "Epoch 102: Loss: 0.616604 \t\t Validation loss: 0.584331\n",
            "Training average batch accuracy: 0.658875\n",
            "Validation average batch accuracy: 0.686133\n",
            "Epoch 103: Loss: 0.608023 \t\t Validation loss: 0.584912\n",
            "Training average batch accuracy: 0.663750\n",
            "Validation average batch accuracy: 0.674805\n",
            "Epoch 104: Loss: 0.618946 \t\t Validation loss: 0.583922\n",
            "Training average batch accuracy: 0.655375\n",
            "Validation average batch accuracy: 0.676758\n",
            "Epoch 105: Loss: 0.608898 \t\t Validation loss: 0.584109\n",
            "Training average batch accuracy: 0.666000\n",
            "Validation average batch accuracy: 0.678711\n",
            "Epoch 106: Loss: 0.608687 \t\t Validation loss: 0.585056\n",
            "Training average batch accuracy: 0.664375\n",
            "Validation average batch accuracy: 0.678125\n",
            "Epoch 107: Loss: 0.612779 \t\t Validation loss: 0.583603\n",
            "Training average batch accuracy: 0.660375\n",
            "Validation average batch accuracy: 0.687500\n",
            "Epoch 108: Loss: 0.614131 \t\t Validation loss: 0.583879\n",
            "Training average batch accuracy: 0.666000\n",
            "Validation average batch accuracy: 0.686914\n",
            "Epoch 109: Loss: 0.609698 \t\t Validation loss: 0.583206\n",
            "Training average batch accuracy: 0.665875\n",
            "Validation average batch accuracy: 0.683008\n",
            "Epoch 110: Loss: 0.608952 \t\t Validation loss: 0.582230\n",
            "BEST SCORE: 0.582229845225811\n",
            "Training average batch accuracy: 0.670000\n",
            "Validation average batch accuracy: 0.684961\n",
            "Epoch 111: Loss: 0.603480 \t\t Validation loss: 0.581485\n",
            "BEST SCORE: 0.5814846865832806\n",
            "Training average batch accuracy: 0.680375\n",
            "Validation average batch accuracy: 0.681445\n",
            "Epoch 112: Loss: 0.609311 \t\t Validation loss: 0.583037\n",
            "Training average batch accuracy: 0.672250\n",
            "Validation average batch accuracy: 0.679688\n",
            "Epoch 113: Loss: 0.610334 \t\t Validation loss: 0.583105\n",
            "Training average batch accuracy: 0.656875\n",
            "Validation average batch accuracy: 0.676367\n",
            "Epoch 114: Loss: 0.612078 \t\t Validation loss: 0.582513\n",
            "Training average batch accuracy: 0.666000\n",
            "Validation average batch accuracy: 0.682422\n",
            "Epoch 115: Loss: 0.607353 \t\t Validation loss: 0.580553\n",
            "BEST SCORE: 0.5805531926453114\n",
            "Training average batch accuracy: 0.672000\n",
            "Validation average batch accuracy: 0.672656\n",
            "Epoch 116: Loss: 0.612009 \t\t Validation loss: 0.581244\n",
            "Training average batch accuracy: 0.666750\n",
            "Validation average batch accuracy: 0.680078\n",
            "Epoch 117: Loss: 0.605554 \t\t Validation loss: 0.581299\n",
            "Training average batch accuracy: 0.667500\n",
            "Validation average batch accuracy: 0.684375\n",
            "Epoch 118: Loss: 0.605581 \t\t Validation loss: 0.579738\n",
            "BEST SCORE: 0.5797380693256855\n",
            "Training average batch accuracy: 0.671750\n",
            "Validation average batch accuracy: 0.693164\n",
            "Epoch 119: Loss: 0.601549 \t\t Validation loss: 0.579449\n",
            "BEST SCORE: 0.5794494822621346\n",
            "Training average batch accuracy: 0.673625\n",
            "Validation average batch accuracy: 0.682422\n",
            "Epoch 120: Loss: 0.599259 \t\t Validation loss: 0.580571\n",
            "Training average batch accuracy: 0.675500\n",
            "Validation average batch accuracy: 0.681445\n",
            "Epoch 121: Loss: 0.602603 \t\t Validation loss: 0.580423\n",
            "Training average batch accuracy: 0.667500\n",
            "Validation average batch accuracy: 0.681641\n",
            "Epoch 122: Loss: 0.607779 \t\t Validation loss: 0.579704\n",
            "Training average batch accuracy: 0.671625\n",
            "Validation average batch accuracy: 0.681445\n",
            "Epoch 123: Loss: 0.607033 \t\t Validation loss: 0.580116\n",
            "Training average batch accuracy: 0.670500\n",
            "Validation average batch accuracy: 0.680078\n",
            "Epoch 124: Loss: 0.603490 \t\t Validation loss: 0.579686\n",
            "Training average batch accuracy: 0.672750\n",
            "Validation average batch accuracy: 0.680469\n",
            "Epoch 125: Loss: 0.604728 \t\t Validation loss: 0.579866\n",
            "Training average batch accuracy: 0.675000\n",
            "Validation average batch accuracy: 0.682617\n",
            "Epoch 126: Loss: 0.605723 \t\t Validation loss: 0.580955\n",
            "Training average batch accuracy: 0.667750\n",
            "Validation average batch accuracy: 0.675781\n",
            "Epoch 127: Loss: 0.612944 \t\t Validation loss: 0.581093\n",
            "Training average batch accuracy: 0.660000\n",
            "Validation average batch accuracy: 0.684570\n",
            "Epoch 128: Loss: 0.603619 \t\t Validation loss: 0.580315\n",
            "Training average batch accuracy: 0.670125\n",
            "Validation average batch accuracy: 0.688477\n",
            "Epoch 129: Loss: 0.601191 \t\t Validation loss: 0.580909\n",
            "Training average batch accuracy: 0.673000\n",
            "Validation average batch accuracy: 0.688281\n",
            "Epoch 130: Loss: 0.604271 \t\t Validation loss: 0.580492\n",
            "Training average batch accuracy: 0.670625\n",
            "Epoch   131: reducing learning rate of group 0 to 2.1523e-05.\n",
            "Validation average batch accuracy: 0.686328\n",
            "Epoch 131: Loss: 0.602968 \t\t Validation loss: 0.579640\n",
            "Training average batch accuracy: 0.669875\n",
            "Validation average batch accuracy: 0.684961\n",
            "Epoch 132: Loss: 0.598288 \t\t Validation loss: 0.579705\n",
            "Training average batch accuracy: 0.666125\n",
            "Validation average batch accuracy: 0.687500\n",
            "Epoch 133: Loss: 0.592794 \t\t Validation loss: 0.578695\n",
            "BEST SCORE: 0.5786954835057259\n",
            "Training average batch accuracy: 0.686250\n",
            "Validation average batch accuracy: 0.692383\n",
            "Epoch 134: Loss: 0.600780 \t\t Validation loss: 0.579122\n",
            "Training average batch accuracy: 0.672500\n",
            "Validation average batch accuracy: 0.681641\n",
            "Epoch 135: Loss: 0.600570 \t\t Validation loss: 0.579315\n",
            "Training average batch accuracy: 0.673625\n",
            "Validation average batch accuracy: 0.679297\n",
            "Epoch 136: Loss: 0.596510 \t\t Validation loss: 0.579804\n",
            "Training average batch accuracy: 0.678625\n",
            "Validation average batch accuracy: 0.685938\n",
            "Epoch 137: Loss: 0.604602 \t\t Validation loss: 0.580626\n",
            "Training average batch accuracy: 0.678500\n",
            "Validation average batch accuracy: 0.681445\n",
            "Epoch 138: Loss: 0.601599 \t\t Validation loss: 0.579812\n",
            "Training average batch accuracy: 0.679125\n",
            "Validation average batch accuracy: 0.681055\n",
            "Epoch 139: Loss: 0.595008 \t\t Validation loss: 0.580419\n",
            "Training average batch accuracy: 0.682125\n",
            "Validation average batch accuracy: 0.681055\n",
            "Epoch 140: Loss: 0.594097 \t\t Validation loss: 0.579436\n",
            "Training average batch accuracy: 0.675875\n",
            "Validation average batch accuracy: 0.685547\n",
            "Epoch 141: Loss: 0.595616 \t\t Validation loss: 0.579539\n",
            "Training average batch accuracy: 0.676000\n",
            "Validation average batch accuracy: 0.686523\n",
            "Epoch 142: Loss: 0.598640 \t\t Validation loss: 0.578912\n",
            "Training average batch accuracy: 0.678125\n",
            "Validation average batch accuracy: 0.688477\n",
            "Epoch 143: Loss: 0.605992 \t\t Validation loss: 0.580624\n",
            "Training average batch accuracy: 0.676000\n",
            "Validation average batch accuracy: 0.675586\n",
            "Epoch 144: Loss: 0.597358 \t\t Validation loss: 0.582229\n",
            "Training average batch accuracy: 0.675750\n",
            "Epoch   145: reducing learning rate of group 0 to 1.0762e-05.\n",
            "Validation average batch accuracy: 0.671680\n",
            "Epoch 145: Loss: 0.595483 \t\t Validation loss: 0.580014\n",
            "Training average batch accuracy: 0.684875\n",
            "Validation average batch accuracy: 0.682617\n",
            "Epoch 146: Loss: 0.593862 \t\t Validation loss: 0.580464\n",
            "Training average batch accuracy: 0.680125\n",
            "Validation average batch accuracy: 0.681641\n",
            "Epoch 147: Loss: 0.594712 \t\t Validation loss: 0.578136\n",
            "BEST SCORE: 0.5781355798244476\n",
            "Training average batch accuracy: 0.676875\n",
            "Validation average batch accuracy: 0.689453\n",
            "Epoch 148: Loss: 0.597640 \t\t Validation loss: 0.580158\n",
            "Training average batch accuracy: 0.674250\n",
            "Validation average batch accuracy: 0.684375\n",
            "Epoch 149: Loss: 0.600157 \t\t Validation loss: 0.580599\n",
            "Training average batch accuracy: 0.671750\n",
            "Validation average batch accuracy: 0.686523\n",
            "Epoch 150: Loss: 0.595001 \t\t Validation loss: 0.580028\n",
            "Training average batch accuracy: 0.672500\n",
            "Validation average batch accuracy: 0.692383\n",
            "Epoch 151: Loss: 0.593145 \t\t Validation loss: 0.577271\n",
            "BEST SCORE: 0.5772710703313351\n",
            "Training average batch accuracy: 0.678250\n",
            "Validation average batch accuracy: 0.693359\n",
            "Epoch 152: Loss: 0.594790 \t\t Validation loss: 0.578583\n",
            "Training average batch accuracy: 0.675750\n",
            "Validation average batch accuracy: 0.679102\n",
            "Epoch 153: Loss: 0.592364 \t\t Validation loss: 0.577184\n",
            "BEST SCORE: 0.5771840251982212\n",
            "Training average batch accuracy: 0.684000\n",
            "Validation average batch accuracy: 0.685547\n",
            "Epoch 154: Loss: 0.599096 \t\t Validation loss: 0.579250\n",
            "Training average batch accuracy: 0.678750\n",
            "Validation average batch accuracy: 0.681055\n",
            "Epoch 155: Loss: 0.588747 \t\t Validation loss: 0.578945\n",
            "Training average batch accuracy: 0.693125\n",
            "Validation average batch accuracy: 0.677539\n",
            "Epoch 156: Loss: 0.592986 \t\t Validation loss: 0.577261\n",
            "Training average batch accuracy: 0.677875\n",
            "Validation average batch accuracy: 0.675195\n",
            "Epoch 157: Loss: 0.590459 \t\t Validation loss: 0.577431\n",
            "Training average batch accuracy: 0.685500\n",
            "Validation average batch accuracy: 0.680664\n",
            "Epoch 158: Loss: 0.586728 \t\t Validation loss: 0.575805\n",
            "BEST SCORE: 0.5758053660392761\n",
            "Training average batch accuracy: 0.684500\n",
            "Validation average batch accuracy: 0.690430\n",
            "Epoch 159: Loss: 0.588121 \t\t Validation loss: 0.574416\n",
            "BEST SCORE: 0.5744163319468498\n",
            "Training average batch accuracy: 0.679250\n",
            "Validation average batch accuracy: 0.688477\n",
            "Epoch 160: Loss: 0.595242 \t\t Validation loss: 0.573986\n",
            "BEST SCORE: 0.5739860013127327\n",
            "Training average batch accuracy: 0.676875\n",
            "Validation average batch accuracy: 0.690430\n",
            "Epoch 161: Loss: 0.589536 \t\t Validation loss: 0.574746\n",
            "Training average batch accuracy: 0.682250\n",
            "Validation average batch accuracy: 0.692383\n",
            "Epoch 162: Loss: 0.596201 \t\t Validation loss: 0.574076\n",
            "Training average batch accuracy: 0.679125\n",
            "Validation average batch accuracy: 0.685547\n",
            "Epoch 163: Loss: 0.591310 \t\t Validation loss: 0.575072\n",
            "Training average batch accuracy: 0.678250\n",
            "Validation average batch accuracy: 0.683398\n",
            "Epoch 164: Loss: 0.585138 \t\t Validation loss: 0.574423\n",
            "Training average batch accuracy: 0.690625\n",
            "Validation average batch accuracy: 0.690234\n",
            "Epoch 165: Loss: 0.587333 \t\t Validation loss: 0.575731\n",
            "Training average batch accuracy: 0.686000\n",
            "Validation average batch accuracy: 0.691406\n",
            "Epoch 166: Loss: 0.593081 \t\t Validation loss: 0.576214\n",
            "Training average batch accuracy: 0.678875\n",
            "Validation average batch accuracy: 0.688867\n",
            "Epoch 167: Loss: 0.591080 \t\t Validation loss: 0.576675\n",
            "Training average batch accuracy: 0.687500\n",
            "Validation average batch accuracy: 0.685938\n",
            "Epoch 168: Loss: 0.598519 \t\t Validation loss: 0.575693\n",
            "Training average batch accuracy: 0.683125\n",
            "Validation average batch accuracy: 0.683594\n",
            "Epoch 169: Loss: 0.584566 \t\t Validation loss: 0.576084\n",
            "Training average batch accuracy: 0.689250\n",
            "Validation average batch accuracy: 0.691406\n",
            "Epoch 170: Loss: 0.594286 \t\t Validation loss: 0.575855\n",
            "Training average batch accuracy: 0.679875\n",
            "Validation average batch accuracy: 0.688477\n",
            "Epoch 171: Loss: 0.586536 \t\t Validation loss: 0.576152\n",
            "Training average batch accuracy: 0.687625\n",
            "Epoch   172: reducing learning rate of group 0 to 5.3808e-06.\n",
            "Validation average batch accuracy: 0.688867\n",
            "Epoch 172: Loss: 0.586562 \t\t Validation loss: 0.574353\n",
            "Training average batch accuracy: 0.684875\n",
            "Validation average batch accuracy: 0.686133\n",
            "Epoch 173: Loss: 0.587572 \t\t Validation loss: 0.573928\n",
            "BEST SCORE: 0.5739275775849819\n",
            "Training average batch accuracy: 0.686500\n",
            "Validation average batch accuracy: 0.689453\n",
            "Epoch 174: Loss: 0.587649 \t\t Validation loss: 0.574918\n",
            "Training average batch accuracy: 0.686375\n",
            "Validation average batch accuracy: 0.688867\n",
            "Epoch 175: Loss: 0.588908 \t\t Validation loss: 0.575637\n",
            "Training average batch accuracy: 0.686000\n",
            "Validation average batch accuracy: 0.681445\n",
            "Epoch 176: Loss: 0.587356 \t\t Validation loss: 0.575601\n",
            "Training average batch accuracy: 0.680000\n",
            "Validation average batch accuracy: 0.682031\n",
            "Epoch 177: Loss: 0.588702 \t\t Validation loss: 0.576422\n",
            "Training average batch accuracy: 0.686875\n",
            "Validation average batch accuracy: 0.685938\n",
            "Epoch 178: Loss: 0.586365 \t\t Validation loss: 0.576009\n",
            "Training average batch accuracy: 0.686750\n",
            "Validation average batch accuracy: 0.687109\n",
            "Epoch 179: Loss: 0.585751 \t\t Validation loss: 0.574312\n",
            "Training average batch accuracy: 0.688125\n",
            "Validation average batch accuracy: 0.682422\n",
            "Epoch 180: Loss: 0.588320 \t\t Validation loss: 0.572899\n",
            "BEST SCORE: 0.5728992410004139\n",
            "Training average batch accuracy: 0.683000\n",
            "Validation average batch accuracy: 0.700195\n",
            "Epoch 181: Loss: 0.591964 \t\t Validation loss: 0.574041\n",
            "Training average batch accuracy: 0.682250\n",
            "Validation average batch accuracy: 0.692187\n",
            "Epoch 182: Loss: 0.588989 \t\t Validation loss: 0.572248\n",
            "BEST SCORE: 0.5722479000687599\n",
            "Training average batch accuracy: 0.684000\n",
            "Validation average batch accuracy: 0.687695\n",
            "Epoch 183: Loss: 0.582018 \t\t Validation loss: 0.572537\n",
            "Training average batch accuracy: 0.688500\n",
            "Validation average batch accuracy: 0.687305\n",
            "Epoch 184: Loss: 0.580854 \t\t Validation loss: 0.575346\n",
            "Training average batch accuracy: 0.693625\n",
            "Validation average batch accuracy: 0.681445\n",
            "Epoch 185: Loss: 0.583267 \t\t Validation loss: 0.576206\n",
            "Training average batch accuracy: 0.690875\n",
            "Validation average batch accuracy: 0.684766\n",
            "Epoch 186: Loss: 0.590459 \t\t Validation loss: 0.573722\n",
            "Training average batch accuracy: 0.677750\n",
            "Validation average batch accuracy: 0.696680\n",
            "Epoch 187: Loss: 0.588267 \t\t Validation loss: 0.574960\n",
            "Training average batch accuracy: 0.687875\n",
            "Validation average batch accuracy: 0.697656\n",
            "Epoch 188: Loss: 0.583256 \t\t Validation loss: 0.575530\n",
            "Training average batch accuracy: 0.680500\n",
            "Validation average batch accuracy: 0.691211\n",
            "Epoch 189: Loss: 0.589199 \t\t Validation loss: 0.575863\n",
            "Training average batch accuracy: 0.683500\n",
            "Validation average batch accuracy: 0.696680\n",
            "Epoch 190: Loss: 0.580815 \t\t Validation loss: 0.575070\n",
            "Training average batch accuracy: 0.695250\n",
            "Validation average batch accuracy: 0.688281\n",
            "Epoch 191: Loss: 0.585971 \t\t Validation loss: 0.575274\n",
            "Training average batch accuracy: 0.682500\n",
            "Validation average batch accuracy: 0.696094\n",
            "Epoch 192: Loss: 0.583650 \t\t Validation loss: 0.574956\n",
            "Training average batch accuracy: 0.693125\n",
            "Validation average batch accuracy: 0.695703\n",
            "Epoch 193: Loss: 0.582590 \t\t Validation loss: 0.575468\n",
            "Training average batch accuracy: 0.686625\n",
            "Epoch   194: reducing learning rate of group 0 to 2.6904e-06.\n",
            "Validation average batch accuracy: 0.692773\n",
            "Epoch 194: Loss: 0.585875 \t\t Validation loss: 0.576373\n",
            "Training average batch accuracy: 0.688750\n",
            "Validation average batch accuracy: 0.693750\n",
            "Epoch 195: Loss: 0.579496 \t\t Validation loss: 0.576720\n",
            "Training average batch accuracy: 0.694250\n",
            "Validation average batch accuracy: 0.687891\n",
            "Epoch 196: Loss: 0.579916 \t\t Validation loss: 0.574650\n",
            "Training average batch accuracy: 0.686125\n",
            "Validation average batch accuracy: 0.694727\n",
            "Epoch 197: Loss: 0.580048 \t\t Validation loss: 0.574668\n",
            "Training average batch accuracy: 0.695750\n",
            "Validation average batch accuracy: 0.687891\n",
            "Epoch 198: Loss: 0.583946 \t\t Validation loss: 0.572774\n",
            "Training average batch accuracy: 0.687750\n",
            "Validation average batch accuracy: 0.692773\n",
            "Epoch 199: Loss: 0.577326 \t\t Validation loss: 0.574218\n",
            "Training average batch accuracy: 0.697375\n",
            "Validation average batch accuracy: 0.695703\n",
            "Epoch 200: Loss: 0.584900 \t\t Validation loss: 0.576857\n",
            "Training average batch accuracy: 0.687375\n",
            "Validation average batch accuracy: 0.693750\n",
            "Epoch 201: Loss: 0.584765 \t\t Validation loss: 0.575712\n",
            "Training average batch accuracy: 0.688500\n",
            "Validation average batch accuracy: 0.694727\n",
            "Epoch 202: Loss: 0.581089 \t\t Validation loss: 0.574339\n",
            "Training average batch accuracy: 0.697250\n",
            "Validation average batch accuracy: 0.694727\n",
            "Epoch 203: Loss: 0.583682 \t\t Validation loss: 0.574886\n",
            "Training average batch accuracy: 0.695000\n",
            "Validation average batch accuracy: 0.693750\n",
            "Epoch 204: Loss: 0.585348 \t\t Validation loss: 0.573038\n",
            "Training average batch accuracy: 0.697250\n",
            "Epoch   205: reducing learning rate of group 0 to 1.3452e-06.\n",
            "Validation average batch accuracy: 0.690820\n",
            "Epoch 205: Loss: 0.583107 \t\t Validation loss: 0.575203\n",
            "Training average batch accuracy: 0.688875\n",
            "Validation average batch accuracy: 0.696094\n",
            "Epoch 206: Loss: 0.573294 \t\t Validation loss: 0.574907\n",
            "Training average batch accuracy: 0.689250\n",
            "Validation average batch accuracy: 0.697656\n",
            "Epoch 207: Loss: 0.575556 \t\t Validation loss: 0.574835\n",
            "Training average batch accuracy: 0.692250\n",
            "Validation average batch accuracy: 0.698828\n",
            "Epoch 208: Loss: 0.579159 \t\t Validation loss: 0.572721\n",
            "Training average batch accuracy: 0.695000\n",
            "Validation average batch accuracy: 0.698242\n",
            "Epoch 209: Loss: 0.579755 \t\t Validation loss: 0.574423\n",
            "Training average batch accuracy: 0.694000\n",
            "Validation average batch accuracy: 0.696680\n",
            "Epoch 210: Loss: 0.571062 \t\t Validation loss: 0.575010\n",
            "Training average batch accuracy: 0.698750\n",
            "Validation average batch accuracy: 0.697656\n",
            "Epoch 211: Loss: 0.571182 \t\t Validation loss: 0.575695\n",
            "Training average batch accuracy: 0.697625\n",
            "Validation average batch accuracy: 0.690234\n",
            "Epoch 212: Loss: 0.577665 \t\t Validation loss: 0.575987\n",
            "Training average batch accuracy: 0.695375\n",
            "Validation average batch accuracy: 0.692773\n",
            "Epoch 213: Loss: 0.583990 \t\t Validation loss: 0.575084\n",
            "Training average batch accuracy: 0.693500\n",
            "Validation average batch accuracy: 0.696680\n",
            "Epoch 214: Loss: 0.578814 \t\t Validation loss: 0.575941\n",
            "Training average batch accuracy: 0.686500\n",
            "Validation average batch accuracy: 0.694727\n",
            "Epoch 215: Loss: 0.584924 \t\t Validation loss: 0.576220\n",
            "Training average batch accuracy: 0.683625\n",
            "Epoch   216: reducing learning rate of group 0 to 6.7261e-07.\n",
            "Validation average batch accuracy: 0.699609\n",
            "Epoch 216: Loss: 0.584038 \t\t Validation loss: 0.577439\n",
            "Training average batch accuracy: 0.692625\n",
            "Validation average batch accuracy: 0.697656\n",
            "Epoch 217: Loss: 0.576026 \t\t Validation loss: 0.575808\n",
            "Training average batch accuracy: 0.695250\n",
            "Validation average batch accuracy: 0.701563\n",
            "Epoch 218: Loss: 0.573807 \t\t Validation loss: 0.577580\n",
            "Training average batch accuracy: 0.697875\n",
            "Validation average batch accuracy: 0.701172\n",
            "Epoch 219: Loss: 0.573702 \t\t Validation loss: 0.575383\n",
            "Training average batch accuracy: 0.689125\n",
            "Validation average batch accuracy: 0.688867\n",
            "Epoch 220: Loss: 0.570474 \t\t Validation loss: 0.575066\n",
            "Training average batch accuracy: 0.696250\n",
            "Validation average batch accuracy: 0.685352\n",
            "Epoch 221: Loss: 0.585569 \t\t Validation loss: 0.575654\n",
            "Training average batch accuracy: 0.685750\n",
            "Validation average batch accuracy: 0.688477\n",
            "Epoch 222: Loss: 0.571824 \t\t Validation loss: 0.574233\n",
            "Training average batch accuracy: 0.694250\n",
            "Validation average batch accuracy: 0.686914\n",
            "Epoch 223: Loss: 0.567200 \t\t Validation loss: 0.574791\n",
            "Training average batch accuracy: 0.704250\n",
            "Validation average batch accuracy: 0.684766\n",
            "Epoch 224: Loss: 0.573192 \t\t Validation loss: 0.575295\n",
            "Training average batch accuracy: 0.695000\n",
            "Validation average batch accuracy: 0.699609\n",
            "Epoch 225: Loss: 0.570541 \t\t Validation loss: 0.576496\n",
            "Training average batch accuracy: 0.698875\n",
            "Validation average batch accuracy: 0.692187\n",
            "Epoch 226: Loss: 0.574279 \t\t Validation loss: 0.577275\n",
            "Training average batch accuracy: 0.709875\n",
            "Epoch   227: reducing learning rate of group 0 to 3.3630e-07.\n",
            "Validation average batch accuracy: 0.688867\n",
            "Epoch 227: Loss: 0.579455 \t\t Validation loss: 0.575925\n",
            "Training average batch accuracy: 0.689000\n",
            "Validation average batch accuracy: 0.690234\n",
            "Epoch 228: Loss: 0.573697 \t\t Validation loss: 0.577003\n",
            "Training average batch accuracy: 0.695500\n",
            "Validation average batch accuracy: 0.696094\n",
            "Epoch 229: Loss: 0.578587 \t\t Validation loss: 0.578821\n",
            "Training average batch accuracy: 0.693875\n",
            "Validation average batch accuracy: 0.691797\n",
            "Epoch 230: Loss: 0.572334 \t\t Validation loss: 0.577056\n",
            "Training average batch accuracy: 0.696375\n",
            "Validation average batch accuracy: 0.698242\n",
            "Epoch 231: Loss: 0.580505 \t\t Validation loss: 0.577887\n",
            "Training average batch accuracy: 0.692500\n",
            "Validation average batch accuracy: 0.691797\n",
            "Epoch 232: Loss: 0.573744 \t\t Validation loss: 0.576442\n",
            "Training average batch accuracy: 0.696500\n",
            "Validation average batch accuracy: 0.690820\n",
            "Epoch 233: Loss: 0.579433 \t\t Validation loss: 0.578200\n",
            "Training average batch accuracy: 0.693000\n",
            "Validation average batch accuracy: 0.684961\n",
            "Epoch 234: Loss: 0.571313 \t\t Validation loss: 0.575739\n",
            "Training average batch accuracy: 0.696000\n",
            "Validation average batch accuracy: 0.682422\n",
            "Epoch 235: Loss: 0.572839 \t\t Validation loss: 0.574336\n",
            "Training average batch accuracy: 0.700625\n",
            "Validation average batch accuracy: 0.684375\n",
            "Epoch 236: Loss: 0.566220 \t\t Validation loss: 0.571921\n",
            "BEST SCORE: 0.5719214603304863\n",
            "Training average batch accuracy: 0.704750\n",
            "Validation average batch accuracy: 0.690234\n",
            "Epoch 237: Loss: 0.566271 \t\t Validation loss: 0.572289\n",
            "Training average batch accuracy: 0.702250\n",
            "Validation average batch accuracy: 0.692773\n",
            "Epoch 238: Loss: 0.572885 \t\t Validation loss: 0.574126\n",
            "Training average batch accuracy: 0.696875\n",
            "Validation average batch accuracy: 0.696094\n",
            "Epoch 239: Loss: 0.572596 \t\t Validation loss: 0.575234\n",
            "Training average batch accuracy: 0.695125\n",
            "Validation average batch accuracy: 0.685352\n",
            "Epoch 240: Loss: 0.569123 \t\t Validation loss: 0.574959\n",
            "Training average batch accuracy: 0.696750\n",
            "Validation average batch accuracy: 0.691797\n",
            "Epoch 241: Loss: 0.571133 \t\t Validation loss: 0.576989\n",
            "Training average batch accuracy: 0.702625\n",
            "Validation average batch accuracy: 0.683008\n",
            "Epoch 242: Loss: 0.573171 \t\t Validation loss: 0.576288\n",
            "Training average batch accuracy: 0.698250\n",
            "Validation average batch accuracy: 0.684570\n",
            "Epoch 243: Loss: 0.570936 \t\t Validation loss: 0.574981\n",
            "Training average batch accuracy: 0.698000\n",
            "Validation average batch accuracy: 0.683398\n",
            "Epoch 244: Loss: 0.571818 \t\t Validation loss: 0.575270\n",
            "Training average batch accuracy: 0.701875\n",
            "Validation average batch accuracy: 0.689258\n",
            "Epoch 245: Loss: 0.566161 \t\t Validation loss: 0.574786\n",
            "Training average batch accuracy: 0.701000\n",
            "Validation average batch accuracy: 0.683984\n",
            "Epoch 246: Loss: 0.572697 \t\t Validation loss: 0.576056\n",
            "Training average batch accuracy: 0.700875\n",
            "Validation average batch accuracy: 0.683984\n",
            "Epoch 247: Loss: 0.562592 \t\t Validation loss: 0.575568\n",
            "Training average batch accuracy: 0.708375\n",
            "Epoch   248: reducing learning rate of group 0 to 1.6815e-07.\n",
            "Validation average batch accuracy: 0.694727\n",
            "Epoch 248: Loss: 0.567347 \t\t Validation loss: 0.576400\n",
            "Training average batch accuracy: 0.706750\n",
            "Validation average batch accuracy: 0.689258\n",
            "Epoch 249: Loss: 0.572188 \t\t Validation loss: 0.575873\n",
            "Training average batch accuracy: 0.696875\n",
            "Validation average batch accuracy: 0.684375\n",
            "Epoch 250: Loss: 0.571791 \t\t Validation loss: 0.576022\n",
            "Training average batch accuracy: 0.698875\n",
            "Validation average batch accuracy: 0.680469\n",
            "Epoch 251: Loss: 0.567934 \t\t Validation loss: 0.574695\n",
            "Training average batch accuracy: 0.702750\n",
            "Validation average batch accuracy: 0.687500\n",
            "Epoch 252: Loss: 0.567807 \t\t Validation loss: 0.574836\n",
            "Training average batch accuracy: 0.704000\n",
            "Validation average batch accuracy: 0.691211\n",
            "Epoch 253: Loss: 0.568074 \t\t Validation loss: 0.577261\n",
            "Training average batch accuracy: 0.696500\n",
            "Validation average batch accuracy: 0.691797\n",
            "Epoch 254: Loss: 0.563545 \t\t Validation loss: 0.577159\n",
            "Training average batch accuracy: 0.711625\n",
            "Validation average batch accuracy: 0.685352\n",
            "Epoch 255: Loss: 0.573778 \t\t Validation loss: 0.576449\n",
            "Training average batch accuracy: 0.694375\n",
            "Validation average batch accuracy: 0.682031\n",
            "Epoch 256: Loss: 0.567088 \t\t Validation loss: 0.576842\n",
            "Training average batch accuracy: 0.701375\n",
            "Validation average batch accuracy: 0.689258\n",
            "Epoch 257: Loss: 0.562656 \t\t Validation loss: 0.577507\n",
            "Training average batch accuracy: 0.696625\n",
            "Validation average batch accuracy: 0.683398\n",
            "Epoch 258: Loss: 0.558038 \t\t Validation loss: 0.578680\n",
            "Training average batch accuracy: 0.710125\n",
            "Epoch   259: reducing learning rate of group 0 to 8.4076e-08.\n",
            "Validation average batch accuracy: 0.682422\n",
            "Epoch 259: Loss: 0.576850 \t\t Validation loss: 0.578800\n",
            "Training average batch accuracy: 0.702500\n",
            "Validation average batch accuracy: 0.691211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'best_score': 0.5719214603304863,\n",
              "  'state_dict': OrderedDict([('context_model.word_embeddings.weight',\n",
              "                tensor([[ 0.0466,  0.2132, -0.0074,  ...,  0.0091, -0.2099,  0.0539],\n",
              "                        [-0.2554, -0.2572,  0.1317,  ..., -0.2329, -0.1223,  0.3550],\n",
              "                        [-0.1256,  0.0136,  0.1031,  ..., -0.3422, -0.0224,  0.1368],\n",
              "                        ...,\n",
              "                        [ 0.0466,  0.2132, -0.0074,  ...,  0.0091, -0.2099,  0.0539],\n",
              "                        [ 0.5117,  0.4524,  0.7137,  ...,  0.3651,  0.9864,  0.8735],\n",
              "                        [ 0.7196,  0.4748,  0.8272,  ...,  0.4776,  0.4018,  0.3012]],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn.weight_ih_l0',\n",
              "                tensor([[ 0.0025, -0.0666, -0.0697,  ...,  0.0351,  0.0023, -0.0385],\n",
              "                        [ 0.0069, -0.0936,  0.0338,  ...,  0.0266, -0.0367,  0.0062],\n",
              "                        [-0.0181, -0.0112, -0.0264,  ...,  0.0434, -0.0105, -0.0173],\n",
              "                        ...,\n",
              "                        [-0.0457, -0.0098, -0.0578,  ..., -0.0951, -0.0263,  0.0095],\n",
              "                        [-0.0474,  0.0270, -0.0790,  ...,  0.0216, -0.0553, -0.0172],\n",
              "                        [-0.0432,  0.0454, -0.0444,  ..., -0.0308,  0.0104,  0.0200]],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn.weight_hh_l0',\n",
              "                tensor([[-0.0511,  0.0031, -0.0150,  ..., -0.0546,  0.0108,  0.1092],\n",
              "                        [-0.0197,  0.0893, -0.0104,  ...,  0.0843, -0.0077,  0.0228],\n",
              "                        [-0.0065,  0.0103,  0.0039,  ...,  0.0496,  0.0368, -0.0162],\n",
              "                        ...,\n",
              "                        [-0.0475, -0.0677, -0.0407,  ..., -0.0732,  0.0143,  0.0570],\n",
              "                        [ 0.0661,  0.0207,  0.0010,  ..., -0.0206, -0.0078,  0.0266],\n",
              "                        [ 0.0876,  0.1058,  0.0674,  ...,  0.0521,  0.0264,  0.0003]],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn.bias_ih_l0',\n",
              "                tensor([ 0.0381,  0.0256,  0.0155,  ...,  0.0165,  0.0609, -0.0132],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn.bias_hh_l0',\n",
              "                tensor([ 0.0035,  0.0301, -0.0562,  ...,  0.0374, -0.0102, -0.0013],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn.weight_ih_l0_reverse',\n",
              "                tensor([[-1.5570e-02,  5.2251e-03, -1.9032e-03,  ...,  2.7098e-02,\n",
              "                         -2.7343e-02, -7.9142e-04],\n",
              "                        [-9.2803e-03,  4.8424e-03,  5.0055e-02,  ..., -2.1368e-02,\n",
              "                          1.9891e-02,  1.1112e-02],\n",
              "                        [-2.8042e-02, -3.9160e-02,  1.9621e-02,  ...,  8.6004e-02,\n",
              "                         -2.8913e-02,  1.4376e-02],\n",
              "                        ...,\n",
              "                        [-1.1051e-02,  8.1402e-05, -6.3656e-02,  ...,  1.3122e-02,\n",
              "                         -6.2195e-03, -7.9039e-03],\n",
              "                        [ 7.6289e-02, -2.5747e-02,  3.3095e-02,  ...,  4.9592e-02,\n",
              "                          9.7890e-03,  2.5369e-02],\n",
              "                        [-2.6159e-02,  2.0232e-02,  3.9944e-03,  ...,  9.3728e-03,\n",
              "                          2.9428e-03, -4.1860e-02]], device='cuda:0')),\n",
              "               ('context_model.rnn.weight_hh_l0_reverse',\n",
              "                tensor([[ 0.0068, -0.0264,  0.0130,  ..., -0.0011,  0.0069, -0.0203],\n",
              "                        [-0.0428, -0.0662, -0.0306,  ...,  0.0073, -0.0575, -0.0163],\n",
              "                        [ 0.0189,  0.1508,  0.0731,  ...,  0.0485,  0.0273,  0.0388],\n",
              "                        ...,\n",
              "                        [ 0.0037,  0.0361,  0.0337,  ...,  0.0753, -0.0013,  0.0152],\n",
              "                        [-0.0042, -0.0450, -0.0389,  ...,  0.0346, -0.0610, -0.0227],\n",
              "                        [-0.0227,  0.0067,  0.0012,  ..., -0.0475, -0.0026,  0.0269]],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn.bias_ih_l0_reverse',\n",
              "                tensor([ 0.0212,  0.0152,  0.0017,  ...,  0.0244,  0.0160, -0.0062],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn.bias_hh_l0_reverse',\n",
              "                tensor([-0.0051,  0.0127, -0.0208,  ...,  0.0040, -0.0533, -0.0033],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn.weight_ih_l1',\n",
              "                tensor([[ 0.0231,  0.0219,  0.0159,  ...,  0.0333,  0.0330,  0.0080],\n",
              "                        [-0.0291,  0.0487,  0.0274,  ..., -0.0394, -0.0608,  0.0049],\n",
              "                        [-0.0207,  0.0095, -0.0013,  ...,  0.0072,  0.0086,  0.0149],\n",
              "                        ...,\n",
              "                        [-0.0660, -0.0104,  0.0212,  ...,  0.0477, -0.0238, -0.0222],\n",
              "                        [-0.0315, -0.0201,  0.0245,  ..., -0.0581,  0.0007,  0.0167],\n",
              "                        [ 0.0573,  0.0145,  0.0119,  ...,  0.0413,  0.0089,  0.0704]],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn.weight_hh_l1',\n",
              "                tensor([[ 0.0312,  0.0167,  0.0812,  ...,  0.0401, -0.0563,  0.0370],\n",
              "                        [ 0.0476, -0.0028, -0.0227,  ..., -0.0480, -0.0885, -0.0175],\n",
              "                        [ 0.0273,  0.0397,  0.0867,  ..., -0.0522, -0.0288,  0.0105],\n",
              "                        ...,\n",
              "                        [ 0.0076,  0.0482,  0.0181,  ..., -0.0574,  0.0238, -0.0053],\n",
              "                        [ 0.0380,  0.0265,  0.0036,  ...,  0.0093,  0.0074,  0.0393],\n",
              "                        [ 0.0693, -0.0139,  0.0156,  ..., -0.0787,  0.0193,  0.0032]],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn.bias_ih_l1',\n",
              "                tensor([-0.0225,  0.0023, -0.0298,  ..., -0.0242, -0.0293,  0.0003],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn.bias_hh_l1',\n",
              "                tensor([-0.0174, -0.0760, -0.0204,  ..., -0.0084, -0.0732, -0.0650],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn.weight_ih_l1_reverse',\n",
              "                tensor([[-0.0187, -0.0019, -0.0159,  ..., -0.0018,  0.0358, -0.0180],\n",
              "                        [ 0.0109,  0.0319, -0.0019,  ..., -0.0223, -0.0393,  0.0804],\n",
              "                        [-0.0220,  0.0212, -0.0475,  ..., -0.0176, -0.0443, -0.0068],\n",
              "                        ...,\n",
              "                        [-0.0245, -0.0242, -0.0210,  ...,  0.0011,  0.0117,  0.0116],\n",
              "                        [ 0.0379,  0.0601, -0.0107,  ...,  0.0598, -0.0438,  0.0776],\n",
              "                        [ 0.0117,  0.0277,  0.0083,  ...,  0.0265,  0.0028,  0.0263]],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn.weight_hh_l1_reverse',\n",
              "                tensor([[-0.0716, -0.0292,  0.0360,  ...,  0.0269,  0.0246,  0.0502],\n",
              "                        [ 0.0495, -0.0398,  0.0385,  ...,  0.0179,  0.0440,  0.0467],\n",
              "                        [-0.0541, -0.0023, -0.0387,  ..., -0.1124,  0.0116, -0.0427],\n",
              "                        ...,\n",
              "                        [-0.0261,  0.0286, -0.0515,  ...,  0.0126, -0.0242,  0.0103],\n",
              "                        [ 0.0267,  0.0493, -0.0407,  ..., -0.0731,  0.0017,  0.0303],\n",
              "                        [-0.0165, -0.0472, -0.0086,  ...,  0.0276, -0.0313,  0.0414]],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn.bias_ih_l1_reverse',\n",
              "                tensor([-0.0565, -0.0689, -0.0347,  ..., -0.0650, -0.0638, -0.0314],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn.bias_hh_l1_reverse',\n",
              "                tensor([-0.0025, -0.0724,  0.0086,  ..., -0.0163, -0.0660, -0.0144],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn_2.weight_ih_l0',\n",
              "                tensor([[-0.0449, -0.0178,  0.0704,  ..., -0.0173,  0.0352,  0.0564],\n",
              "                        [-0.0289,  0.0003, -0.0115,  ..., -0.0477,  0.0231,  0.0501],\n",
              "                        [ 0.0255, -0.0083,  0.0029,  ...,  0.0079, -0.0246, -0.0103],\n",
              "                        ...,\n",
              "                        [-0.0670,  0.0267,  0.0135,  ..., -0.0655,  0.0313, -0.0345],\n",
              "                        [ 0.0002,  0.0198, -0.0447,  ...,  0.0002,  0.0160,  0.0293],\n",
              "                        [-0.0270, -0.0342, -0.0164,  ..., -0.0271, -0.0254,  0.0743]],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn_2.weight_hh_l0',\n",
              "                tensor([[-0.0092,  0.0250,  0.0058,  ..., -0.0197, -0.0319, -0.0346],\n",
              "                        [-0.0445, -0.0374, -0.0146,  ...,  0.0003, -0.0037, -0.0642],\n",
              "                        [-0.0582, -0.0429,  0.0205,  ..., -0.0327, -0.0399,  0.0289],\n",
              "                        ...,\n",
              "                        [ 0.0176,  0.0279, -0.0491,  ..., -0.0090,  0.0184,  0.0074],\n",
              "                        [-0.0197,  0.0131, -0.0136,  ...,  0.0034, -0.0212, -0.0392],\n",
              "                        [ 0.0429,  0.0287, -0.0155,  ...,  0.0236,  0.0495,  0.0512]],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn_2.bias_ih_l0',\n",
              "                tensor([-0.0453, -0.0152, -0.0476,  ..., -0.0599, -0.0005, -0.0722],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn_2.bias_hh_l0',\n",
              "                tensor([-0.0707, -0.0115, -0.0044,  ..., -0.0563, -0.0276, -0.0323],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn_2.weight_ih_l0_reverse',\n",
              "                tensor([[ 0.0067, -0.0669, -0.0097,  ..., -0.0274, -0.0051,  0.0234],\n",
              "                        [ 0.0581, -0.0010,  0.0240,  ..., -0.0074,  0.0125,  0.0314],\n",
              "                        [ 0.0748,  0.0441,  0.0304,  ..., -0.0057,  0.0224, -0.0471],\n",
              "                        ...,\n",
              "                        [-0.0025,  0.0101,  0.0550,  ...,  0.0266, -0.0170,  0.0230],\n",
              "                        [-0.0002, -0.0223, -0.0316,  ..., -0.0087, -0.0059,  0.0121],\n",
              "                        [-0.0712,  0.0022, -0.0093,  ...,  0.0078, -0.0271, -0.0258]],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn_2.weight_hh_l0_reverse',\n",
              "                tensor([[ 0.0304, -0.0298, -0.0382,  ...,  0.0192, -0.0143,  0.0259],\n",
              "                        [-0.0087,  0.0008, -0.0216,  ...,  0.0452, -0.0453, -0.0509],\n",
              "                        [-0.0213, -0.0224,  0.0237,  ..., -0.0350, -0.0258, -0.0395],\n",
              "                        ...,\n",
              "                        [-0.0562,  0.0125,  0.0299,  ...,  0.0314, -0.0190,  0.0435],\n",
              "                        [-0.0071,  0.0120,  0.0257,  ..., -0.0169, -0.0296, -0.0188],\n",
              "                        [ 0.0561,  0.0281, -0.0178,  ...,  0.0271, -0.0533,  0.0187]],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn_2.bias_ih_l0_reverse',\n",
              "                tensor([-0.0571,  0.0173, -0.0209,  ..., -0.0041, -0.0495, -0.0297],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn_2.bias_hh_l0_reverse',\n",
              "                tensor([-0.0664, -0.0223, -0.0599,  ..., -0.0640, -0.0723, -0.0340],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn_2.weight_ih_l1',\n",
              "                tensor([[-0.0458,  0.0079, -0.0094,  ...,  0.0159,  0.0414, -0.0404],\n",
              "                        [-0.0817, -0.0705,  0.0286,  ...,  0.0193, -0.0167,  0.0201],\n",
              "                        [-0.0044, -0.0108, -0.0216,  ..., -0.0076,  0.0405, -0.0351],\n",
              "                        ...,\n",
              "                        [-0.0413, -0.0077, -0.0136,  ..., -0.0103, -0.0045, -0.0270],\n",
              "                        [ 0.0099, -0.0159,  0.0050,  ...,  0.0466, -0.0320, -0.0346],\n",
              "                        [ 0.0054, -0.0646,  0.0086,  ...,  0.0014,  0.0240,  0.0061]],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn_2.weight_hh_l1',\n",
              "                tensor([[-0.0123,  0.0211, -0.0126,  ..., -0.0594, -0.0469, -0.0269],\n",
              "                        [-0.0539, -0.0133,  0.0125,  ..., -0.0578, -0.0865,  0.0001],\n",
              "                        [ 0.0012, -0.0011,  0.0344,  ..., -0.0535, -0.0204, -0.0454],\n",
              "                        ...,\n",
              "                        [-0.0684, -0.0131,  0.0305,  ..., -0.0967, -0.0613, -0.0236],\n",
              "                        [ 0.0256, -0.0062,  0.0130,  ..., -0.0028, -0.0911, -0.0230],\n",
              "                        [-0.0314, -0.0202,  0.0354,  ..., -0.0167, -0.0614, -0.0529]],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn_2.bias_ih_l1',\n",
              "                tensor([-0.0072, -0.0827, -0.1155,  ..., -0.0377, -0.0449, -0.0417],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn_2.bias_hh_l1',\n",
              "                tensor([-0.0380, -0.0396, -0.0862,  ...,  0.0098, -0.0781, -0.0289],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn_2.weight_ih_l1_reverse',\n",
              "                tensor([[ 2.2797e-02, -5.4147e-02, -3.8009e-02,  ...,  3.3794e-02,\n",
              "                          2.8753e-02,  1.7921e-02],\n",
              "                        [ 3.6617e-03,  6.1278e-02,  2.3883e-02,  ..., -4.4653e-02,\n",
              "                         -5.7775e-02,  3.5399e-02],\n",
              "                        [-1.8780e-02, -5.2244e-03, -7.9804e-03,  ...,  2.6165e-03,\n",
              "                         -2.7595e-04,  1.4259e-02],\n",
              "                        ...,\n",
              "                        [-5.9452e-02, -2.0924e-05,  2.3878e-02,  ..., -1.2238e-02,\n",
              "                         -2.1452e-02, -3.8871e-02],\n",
              "                        [-1.6843e-02,  4.5683e-03,  1.0333e-02,  ..., -1.2612e-02,\n",
              "                         -1.3093e-02, -6.4838e-02],\n",
              "                        [ 2.5042e-02,  1.9181e-02, -1.4181e-02,  ...,  6.0954e-02,\n",
              "                         -7.2556e-03, -2.1324e-02]], device='cuda:0')),\n",
              "               ('context_model.rnn_2.weight_hh_l1_reverse',\n",
              "                tensor([[-0.0461, -0.0043, -0.0405,  ...,  0.0009, -0.0505,  0.0686],\n",
              "                        [-0.0211,  0.0253, -0.0464,  ...,  0.0333, -0.0003,  0.0274],\n",
              "                        [ 0.0007, -0.0056, -0.0372,  ...,  0.0103,  0.0105,  0.0249],\n",
              "                        ...,\n",
              "                        [ 0.0216,  0.0054,  0.0194,  ..., -0.0023, -0.0138, -0.0193],\n",
              "                        [-0.0314,  0.0038, -0.0070,  ...,  0.0437, -0.0960,  0.0305],\n",
              "                        [ 0.0154,  0.0143, -0.0682,  ...,  0.0436, -0.0540,  0.0311]],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn_2.bias_ih_l1_reverse',\n",
              "                tensor([-0.0521, -0.0560, -0.0594,  ..., -0.0819, -0.1209, -0.0774],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.rnn_2.bias_hh_l1_reverse',\n",
              "                tensor([-0.0625, -0.0314, -0.0804,  ..., -0.0918, -0.0942, -0.0692],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.classifier.0.weight',\n",
              "                tensor([[-0.0041, -0.0187,  0.0336,  ...,  0.0077, -0.0164, -0.0066],\n",
              "                        [ 0.0455, -0.0056,  0.0295,  ..., -0.0293,  0.0025,  0.0194],\n",
              "                        [ 0.0216, -0.0187,  0.0238,  ..., -0.0178, -0.0212,  0.0321],\n",
              "                        ...,\n",
              "                        [ 0.0323,  0.0059,  0.0335,  ...,  0.0133,  0.0007, -0.0124],\n",
              "                        [ 0.0205, -0.0233,  0.0134,  ..., -0.0100, -0.0385,  0.0030],\n",
              "                        [-0.0330, -0.0040, -0.0193,  ..., -0.0042,  0.0218,  0.0010]],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.classifier.0.bias',\n",
              "                tensor([-0.0116, -0.0066,  0.0154,  ...,  0.0248, -0.0247, -0.0072],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.classifier.1.weight',\n",
              "                tensor([0.9752, 0.9682, 0.9811,  ..., 0.9557, 0.9796, 0.9711], device='cuda:0')),\n",
              "               ('context_model.classifier.1.bias',\n",
              "                tensor([-0.1625, -0.0567, -0.0935,  ..., -0.0521, -0.1344, -0.1062],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.classifier.1.running_mean',\n",
              "                tensor([-0.0508, -0.1992,  0.1845,  ...,  0.2325, -0.0505,  0.0996],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.classifier.1.running_var',\n",
              "                tensor([0.0668, 0.1032, 0.1357,  ..., 0.1067, 0.0889, 0.0856], device='cuda:0')),\n",
              "               ('context_model.classifier.1.num_batches_tracked',\n",
              "                tensor(74888, device='cuda:0')),\n",
              "               ('context_model.classifier.4.weight',\n",
              "                tensor([[-0.0123,  0.0072,  0.0076,  ...,  0.0014, -0.0063,  0.0147]],\n",
              "                       device='cuda:0')),\n",
              "               ('context_model.classifier.4.bias',\n",
              "                tensor([0.1000], device='cuda:0')),\n",
              "               ('context_model.pos_embeddings.weight',\n",
              "                tensor([[ 1.1629, -1.1378, -0.8094,  ..., -0.7575, -2.8298, -1.5016],\n",
              "                        [ 1.4508,  0.7958,  1.6008,  ..., -1.3490,  0.8413, -0.5012],\n",
              "                        [ 0.7994,  0.1609,  1.2163,  ...,  0.4876,  0.4416, -0.0677],\n",
              "                        ...,\n",
              "                        [ 0.1108, -0.1831,  0.8456,  ...,  0.5014,  0.3250, -0.0144],\n",
              "                        [-0.5322,  0.8601,  0.4092,  ...,  0.0562, -0.0999,  0.7101],\n",
              "                        [ 0.0966, -1.0956,  0.4149,  ..., -1.1318,  1.3556,  1.9544]],\n",
              "                       device='cuda:0')),\n",
              "               ('word_embeddings.weight',\n",
              "                tensor([[ 0.0466,  0.2132, -0.0074,  ...,  0.0091, -0.2099,  0.0539],\n",
              "                        [-0.2554, -0.2572,  0.1317,  ..., -0.2329, -0.1223,  0.3550],\n",
              "                        [-0.1256,  0.0136,  0.1031,  ..., -0.3422, -0.0224,  0.1368],\n",
              "                        ...,\n",
              "                        [ 0.0466,  0.2132, -0.0074,  ...,  0.0091, -0.2099,  0.0539],\n",
              "                        [ 0.5117,  0.4524,  0.7137,  ...,  0.3651,  0.9864,  0.8735],\n",
              "                        [ 0.7196,  0.4748,  0.8272,  ...,  0.4776,  0.4018,  0.3012]],\n",
              "                       device='cuda:0')),\n",
              "               ('classifier.0.weight',\n",
              "                tensor([[-0.0952,  0.1888, -0.2657,  ...,  0.1300, -0.1747, -0.1037],\n",
              "                        [ 0.2000, -0.1066,  0.1797,  ..., -0.1447, -0.2201,  0.1524],\n",
              "                        [ 0.1721, -0.2448, -0.1912,  ...,  0.0469,  0.1756,  0.0477],\n",
              "                        ...,\n",
              "                        [ 0.0997,  0.4569, -0.3400,  ...,  0.2016, -0.0970,  0.0834],\n",
              "                        [ 0.0857, -0.2530,  0.0626,  ...,  0.0316,  0.2170,  0.1171],\n",
              "                        [ 0.1335, -0.0587, -0.3436,  ...,  0.0342, -0.0336, -0.0351]],\n",
              "                       device='cuda:0')),\n",
              "               ('classifier.0.bias',\n",
              "                tensor([ 0.0053, -0.0077, -0.0126,  ...,  0.0121,  0.0243,  0.0039],\n",
              "                       device='cuda:0')),\n",
              "               ('classifier.1.weight',\n",
              "                tensor([0.4389, 0.3795, 0.4772,  ..., 0.3974, 0.6592, 0.3955], device='cuda:0')),\n",
              "               ('classifier.1.bias',\n",
              "                tensor([-0.5427, -0.3796, -0.6314,  ..., -0.6795, -0.5725, -0.6713],\n",
              "                       device='cuda:0')),\n",
              "               ('classifier.1.running_mean',\n",
              "                tensor([-0.8395,  1.9701,  1.6946,  ...,  0.0676, -0.9336, -0.0819],\n",
              "                       device='cuda:0')),\n",
              "               ('classifier.1.running_var',\n",
              "                tensor([5.4702, 2.5014, 2.1928,  ..., 4.3807, 1.9137, 2.5974], device='cuda:0')),\n",
              "               ('classifier.1.num_batches_tracked',\n",
              "                tensor(29625, device='cuda:0')),\n",
              "               ('classifier.4.weight',\n",
              "                tensor([[ 0.0572, -0.0427, -0.0813,  ...,  0.1428, -0.0656,  0.0673]],\n",
              "                       device='cuda:0')),\n",
              "               ('classifier.4.bias', tensor([0.0451], device='cuda:0')),\n",
              "               ('pos_classifier.0.weight',\n",
              "                tensor([[-0.0069, -0.0009,  0.0083,  ...,  0.0019,  0.0263, -0.0104],\n",
              "                        [ 0.0158, -0.0089, -0.0156,  ..., -0.0092,  0.0252, -0.0258],\n",
              "                        [-0.0247,  0.0030, -0.0159,  ..., -0.0144, -0.0041, -0.0218],\n",
              "                        [-0.0042, -0.0162, -0.0065,  ...,  0.0182,  0.0115, -0.0267]],\n",
              "                       device='cuda:0')),\n",
              "               ('pos_classifier.0.bias',\n",
              "                tensor([-1.2028e-02, -5.5910e-05,  2.2542e-02, -3.3916e-03], device='cuda:0'))])},\n",
              " NoAttention(\n",
              "   (context_model): ContextEncoder(\n",
              "     (word_embeddings): Embedding(400004, 300)\n",
              "     (rnn): LSTM(400, 600, num_layers=2, batch_first=True, dropout=0.7, bidirectional=True)\n",
              "     (rnn_2): LSTM(1200, 600, num_layers=2, batch_first=True, dropout=0.7, bidirectional=True)\n",
              "     (classifier): Sequential(\n",
              "       (0): Linear(in_features=1500, out_features=4800, bias=True)\n",
              "       (1): BatchNorm1d(4800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "       (2): ReLU()\n",
              "       (3): Dropout(p=0.7, inplace=False)\n",
              "       (4): Linear(in_features=4800, out_features=1, bias=True)\n",
              "     )\n",
              "     (loss): BCELoss()\n",
              "     (pos_embeddings): Embedding(37, 100)\n",
              "   )\n",
              "   (word_embeddings): Embedding(400004, 300)\n",
              "   (classifier): Sequential(\n",
              "     (0): Linear(in_features=2400, out_features=1200, bias=True)\n",
              "     (1): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (2): ReLU()\n",
              "     (3): Dropout(p=0.95, inplace=False)\n",
              "     (4): Linear(in_features=1200, out_features=1, bias=True)\n",
              "   )\n",
              "   (pos_classifier): Sequential(\n",
              "     (0): Linear(in_features=1200, out_features=4, bias=True)\n",
              "   )\n",
              "   (pos_loss): CrossEntropyLoss()\n",
              "   (loss): BCELoss()\n",
              " ))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    }
  ]
}